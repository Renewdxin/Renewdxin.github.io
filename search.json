[{"title":"redis 入门","path":"/middleware/redis/","content":"NoSql概述NoSql年代 问题：数据量过大、数据索引过大（B+Tree），机器内存不够、访问量（读写混合），服务器承受不了 缓存 Memcached + MySQL+垂直拆分（读写分离）网站80%的情况下在读取，用MySQL太过繁琐；希望减轻数据库的压力，可以使用缓存保证效率 发展过程：优化数据结构和索引-&gt;文件缓存（IO）-&gt;Memcached（当时最热门技术） 分库分表+水平拆分+Mysql集群 本质：数据库的读和写 早些年MyISAM：表锁，（读写时，所在的表被锁，十分影响并发性） Innodb：行锁 最近MySQL关系型数据库不够用，数据多且变化快 用：图型；JSON MySQL有的使用他来存储较大文件，数据库很大，效率变低，如果有专门数据库负责，压力就会变小 目前一个基本的互联网项目 为什么要用用户的个人信息、地理位置，用户自己产生的数据、用户日志爆炸式增长，nosql能很好的处理以上问题 NoSqlNoSql &#x3D; Not Only Sql（不仅仅是Sql） 关系型数据库：表格，行，列 泛指非关系型数据库，传统关系型数据库很难对付web2.0时代，尤其是超大规模的高并发的社区。NoSql在当今大数据环境下发展十分迅速，Redis是发展最快的，而且是我们当下必须要掌握的一个技术！ 很多的数据类型用户的个人信息，社交网络，地理位置。这些数据类型存储不需要一个固定的格式，不需要多余的操作就可以横向扩展！使用键值对来存放。 NoSql特点—解耦 1、方便扩展（数据之间没有关系，很好扩展） 2、大数据量高性能（NoSql的缓存记录级，是一种细粒度的缓存，性能会比较高，redis一秒写8万次读11万次） 3、数据类型是多样型（不需要设计数据库，随取随用） 4、传统的RDBMS和NoSql 传统的 RDBMS（关系型数据库） 结构化组织 SQL 数据和关系都存在单独的表中 操作语言，定义语言 严格的一致性 … Nosql 不仅仅是数据 没有固定的查询语言 键值对存储，文档存储，图形数据库（社交关系） 最终一致性 CAP定理和BASE （异地多活） 高性能，高可用，高可扩 … 了解：3V+3高 大数据时代的3V：主要是描述问题的 1、海量Volume 2、多样Variety 3、实时Velocity 互联网需求的3高：主要是对程序的要求 1、高并发（Java JUC） 2、高可拓（随时水平拆分，机器不够了，扩展机器来解决） 3、高性能（保证用户体验和性能） NoSql+RDBMS-&gt;《阿里巴巴的架构演进》 NoSql的四大分类KV键值对 新浪：Redis 美团：Redis+Tair 阿里、百度：Redis+MemCache 文档型数据库：（bson格式和json一样） MongoDB mongodb基于分布式文件存储的数据库，C++编写，主要用来处理大量的文档 MongoDB是一个介于关系型数据库和非关系型数据库中间的产品，MongoDB是非关系型数据库中功能最丰富，最想关系型数据库的。 ConthDB 列存储数据库 HBase 分布式文件系统 图关系数据库 不是存图形，放的是关系，比如朋友圈社交网络 neo4j InfoGrid redisgraph RedisRedis是什么？ Redis（&#x3D;&#x3D;Re&#x3D;&#x3D;mote&#x3D;&#x3D;Di&#x3D;&#x3D;ctionary&#x3D;&#x3D;S&#x3D;&#x3D;erve），即远程字典服务 Redis能干嘛？ 1、内存存储，持久化，内存中是断电即失，所以说持久化很重要（rdb、aof） 2、效率高，可以用于高速缓存 3、发布订阅系统 4、地图信息分析 5、计时器、计数器（浏览量！ ） 特性 1、多样的数据类型 2、持久化 3、集群 4、事物 测试性能 简单测试 12# 测试：100个并发连接 100000请求redis-benchmark -h localhost -p 6379 -c 100 -n 100000 测试图 redis默认有16个数据库，默认使用第0个 1234567891011121314151617181920212223242526272829127.0.0.1:6379&gt; config get databases # 命令行查看数据库数量databases1) &quot;databases&quot;2) &quot;16&quot;127.0.0.1:6379&gt; select 8 # 切换数据库 DB 8OK127.0.0.1:6379[8]&gt; dbsize # 查看数据库大小(integer) 0# 不同数据库之间 数据是不能互通的，并且dbsize 是根据库中key的个数。127.0.0.1:6379&gt; set name sakura OK127.0.0.1:6379&gt; SELECT 8OK127.0.0.1:6379[8]&gt; get name # db8中并不能获取db0中的键值对。(nil)127.0.0.1:6379[8]&gt; DBSIZE(integer) 0127.0.0.1:6379[8]&gt; SELECT 0OK127.0.0.1:6379&gt; keys *1) &quot;counter:__rand_int__&quot;2) &quot;mylist&quot;3) &quot;name&quot;4) &quot;key:__rand_int__&quot;5) &quot;myset:__rand_int__&quot;127.0.0.1:6379&gt; DBSIZE # size和key个数相关(integer) 5 keys * ：查看当前数据库中所有的key。 flushdb：清空当前数据库中的键值对。 flushall：清空所有数据库的键值对。 Redis是单线程的，Redis是基于内存操作的。所以Redis的性能瓶颈不是CPU,而是机器内存和网络带宽。 那么为什么Redis的速度如此快呢，性能这么高呢？QPS达到10W+ Redis为什么单线程还这么快？ 误区1：高性能的服务器一定是多线程的？误区2：多线程（CPU上下文会切换！）一定比单线程效率高！核心：Redis是将所有的数据放在内存中的，所以说使用单线程去操作效率就是最高的，多线程（CPU上下文会切换：耗时的操作！），对于内存系统来说，如果没有上下文切换效率就是最高的，多次读写都是在一个CPU上的，在内存存储数据情况下，单线程就是最佳的方案。 五大数据类型Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 key在redis中无论什么数据类型，在数据库中都是以key-value形式保存，通过进行对Redis-key的操作，来完成对数据库中数据的操作。 exists key：判断键是否存在del key：删除键值对move key db：将键值对移动到指定数据库expire key second：设置键值对的过期时间type key：查看value的数据类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344127.0.0.1:6379&gt; keys * # 查看当前数据库所有key(empty list or set)127.0.0.1:6379&gt; set name qinjiang # set keyOK127.0.0.1:6379&gt; set age 20OK127.0.0.1:6379&gt; keys *1) &quot;age&quot;2) &quot;name&quot;127.0.0.1:6379&gt; move age 1 # 将键值对移动到指定数据库(integer) 1127.0.0.1:6379&gt; EXISTS age # 判断键是否存在(integer) 0 # 不存在127.0.0.1:6379&gt; EXISTS name(integer) 1 # 存在127.0.0.1:6379&gt; SELECT 1OK127.0.0.1:6379[1]&gt; keys *1) &quot;age&quot;127.0.0.1:6379[1]&gt; del age # 删除键值对(integer) 1 # 删除个数127.0.0.1:6379&gt; set age 20OK127.0.0.1:6379&gt; EXPIRE age 15 # 设置键值对的过期时间(integer) 1 # 设置成功 开始计数127.0.0.1:6379&gt; ttl age # 查看key的过期剩余时间(integer) 13127.0.0.1:6379&gt; ttl age(integer) 11127.0.0.1:6379&gt; ttl age(integer) 9127.0.0.1:6379&gt; ttl age(integer) -2 # -2 表示key过期，-1表示key未设置过期时间127.0.0.1:6379&gt; get age # 过期的key 会被自动delete(nil)127.0.0.1:6379&gt; keys *1) &quot;name&quot;127.0.0.1:6379&gt; type name # 查看value的数据类型string 关于TTL命令 Redis的key，通过TTL命令返回key的过期时间，一般来说有3种： 当前key没有设置过期时间，所以会返回-1.当前key有设置过期时间，而且key已经过期，所以会返回-2.当前key有设置过期时间，且key还没有过期，故会返回key的正常剩余时间.关于重命名RENAME和RENAMENX RENAME key newkey修改 key 的名称RENAMENX key newkey仅当 newkey 不存在时，将 key 改名为 newkey 。更多命令学习：https://www.redis.net.cn/order/ String 123456789101112131415161718127.0.0.1:6379&gt; set views 0 #初始浏览量为0 OK127.0.0.1:6379&gt; get views&quot;0&quot;127.0.0.1:6379&gt; incr views #自增1，浏览量变为1(integer) 1127.0.0.1:6379&gt; incr views(integer) 2127.0.0.1:6379&gt; get views&quot;2&quot;127.0.0.1:6379&gt; decr views #自减1(integer) 1127.0.0.1:6379&gt; incrby views 10 #自增10(integer) 11127.0.0.1:6379&gt; incrby views 10(integer) 21127.0.0.1:6379&gt; decrby views 5 #自减5(integer) 16 截取字符串getrange 1234567891011127.0.0.1:6379&gt; keys *(empty array)127.0.0.1:6379&gt; set key1 &quot;fang&quot;OK127.0.0.1:6379&gt; get key1&quot;fang&quot;127.0.0.1:6379&gt; getrange key1 0 2 #截取012字符串&quot;fan&quot;127.0.0.1:6379&gt; getrange key1 0 -1 #获取全部字符串&quot;fang&quot;127.0.0.1:6379&gt; 替换setrange 123456789127.0.0.1:6379&gt; set key2 abcdefgOK127.0.0.1:6379&gt; get key2&quot;abcdefg&quot;127.0.0.1:6379&gt; setrange key2 1 xx(integer) 7127.0.0.1:6379&gt; get key2&quot;axxdefg&quot;127.0.0.1:6379&gt; setex：设置过期时间setnx ：不存在在设置（在分布式锁中常常使用）** 12345678910111213141516127.0.0.1:6379&gt; setex key3 30 &quot;hello&quot;OK127.0.0.1:6379&gt; ttl key3(integer) 17127.0.0.1:6379&gt; setnx mykey &quot;redsi&quot; #如果mykey存在，则创建失败。(integer) 1127.0.0.1:6379&gt; keys *1) &quot;mykey&quot;2) &quot;key2&quot;3) &quot;key1&quot;127.0.0.1:6379&gt; ttl key3(integer) -2127.0.0.1:6379&gt; setnx mykey &quot;MongDB&quot;(integer) 0127.0.0.1:6379&gt; get mykey&quot;redsi&quot; 一次性获取，设置多个值：mset，mget 1234567891011121314151617127.0.0.1:6379&gt; keys *(empty array)127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3 #同时设置多个值OK127.0.0.1:6379&gt; keys *1) &quot;k3&quot;2) &quot;k2&quot;3) &quot;k1&quot;127.0.0.1:6379&gt; mget k1 k2 k3 #同时获取多个值1) &quot;v1&quot;2) &quot;v2&quot;3) &quot;v3&quot;127.0.0.1:6379&gt; msetnx k1 v1 k4 v4 #msetnx是一个原子性操作，要么成功要么失败(integer) 0127.0.0.1:6379&gt; get k4(nil)127.0.0.1:6379&gt; 对象 1mset user：1&#123;name：zhangsan，age：3&#125; #设置一个user：1对象 值为json字符来保存一个对象 这里的key设计：user:&#123;id&#125;:&#123;field&#125; 123456127.0.0.1:6379&gt; mset user:1:name fang user:1:age 2OK127.0.0.1:6379&gt; mget user:1:name user:1:age1) &quot;fang&quot;2) &quot;2&quot;127.0.0.1:6379&gt; 先get在set——-getset 12345678127.0.0.1:6379&gt; getset db redis #没有值则返回nil(nil)127.0.0.1:6379&gt; get db&quot;redis&quot;127.0.0.1:6379&gt; getset db mongodb #先获取原来的值再设置新的值&quot;redis&quot;127.0.0.1:6379&gt; get db&quot;mongodb&quot; string类型的使用场景：value除了字符串还可以是数字 计数器 统计多单位数量 粉丝数 对象缓存存储 Setredis里面可以把list完成栈，队列，阻塞队列！所有的list命令以l开头 12345678910111213127.0.0.1:6379&gt; lpush list one #将一个或多个值插入列表头部（左）尾部添加值为Rpush(integer) 1127.0.0.1:6379&gt; lpush list two(integer) 2127.0.0.1:6379&gt; lpush list three(integer) 3127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; lrange list 0 11) &quot;three&quot;2) &quot;two&quot; 移除元素 12345678127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; LPOP list #移除list第一个元素&quot;three&quot;127.0.0.1:6379&gt; RPOP list #移除list最后一个元素&quot;one&quot; lindex 通过下标获得值 1234127.0.0.1:6379&gt; lindex list 1&quot;one&quot;127.0.0.1:6379&gt; lindex list 0&quot;two&quot; llen返回列表长度 12345...127.0.0.1:6379&gt; lpush list three(integer) 3127.0.0.1:6379&gt; llen list #返回列表长度(integer) 3 移除指定值lrem 12345678910111213127.0.0.1:6379&gt; LPUSH list three one four(integer) 4127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;four&quot;2) &quot;one&quot;3) &quot;three&quot;4) &quot;two&quot;127.0.0.1:6379&gt; LREM list 2 one #移除list中指定个数的value，2个one(integer) 1127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;four&quot;2) &quot;three&quot;3) &quot;two&quot; trim 修剪list 123456789101112127.0.0.1:6379&gt; LRANGE LIST 0 -11) &quot;four&quot;2) &quot;one&quot;3) &quot;three&quot;4) &quot;two&quot;5) &quot;five&quot;127.0.0.1:6379&gt; LTRIM LIST 1 3 #通过下标截取指定长度， LIST已被改变OK127.0.0.1:6379&gt; LRANGE LIST 0 -11) &quot;one&quot;2) &quot;three&quot;3) &quot;two&quot; rpop lpush,将列表右边元素移到另一个列表的左边 12345678910...127.0.0.1:6379&gt; rpush mylist &quot;2&quot;(integer) 3127.0.0.1:6379&gt; rpoplpush mylist myother #移除列表中最后一个元素，将他add到新列表中&quot;2&quot;127.0.0.1:6379&gt; lrange mylist 0 -11) &quot;0&quot;2) &quot;1&quot;127.0.0.1:6379&gt; lrange myother 0 -11) &quot;2&quot; lset list 0 item将下标为0的元素替换为item 123456789101112127.0.0.1:6379&gt; exists list #判断列表是否存在(integer) 0127.0.0.1:6379&gt; lset list 0 item #如果不存在列表。则会报错(error) ERR no such key127.0.0.1:6379&gt; lpush list value1(integer) 1127.0.0.1:6379&gt; lrange list 0 01) &quot;value1&quot;127.0.0.1:6379&gt; lset list 0 item #存在则更新下标OK127.0.0.1:6379&gt; LSET list 1 other(error) ERR index out of range linsert 在指定值的前面或者后面插入具体值 1234567891011121314151617127.0.0.1:6379&gt; LPUSH list one(integer) 1127.0.0.1:6379&gt; LPUSH list two(integer) 2127.0.0.1:6379&gt; LINSERT list before two three(integer) 3127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; LINSERT list AFTER two five(integer) 4127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;five&quot;4) &quot;one&quot; 小结：1.实际上是一个双向链表2.key不存在，创建新链表3.移除所有元素，相当于空链表，代表不存在4.在两边插入或者改动值，效率高，中间元素，相对效率低可以做消息队列 Hashredis hash是一个String类型的field和value映射表，hash特别适合用来存储对象 set是一个简化的hash，只变动key，而value使用默认值填充，可以将一个Hash表作为一个对象存储，表中存放对象的信息 命令 作用 HSET key field value 将哈希表key的字段field的值设为value，重复设置则被覆盖，返回0 HMSET key field1 value1[field2 value2]… 同时将多个键值对设置到哈希表key中 HSETNX key field value 当字段不存在时，设置字段值 HEXISTS key field 查看哈希表key中field是否存在 HGET key field value 获取存储在field中的值 HMGET key field1 [field2..] 获取所有给定field的值 HGETALL key 获取在哈希表key的所有字段和值 HKEYS key 获取哈希表key中的所有field HLEN key 获取哈希表中字段的数量 HVALS key 获取所有的值 HDEL key field1 [field2..] 删除哈希表key中的一个或多个field HINCRBY key field n 为key中的指定field整数值加上增量n，并返回增量后结果一样只适用于整数型字段 HINCRBYFLOAT key field n 为key的指定字段的浮点数值加上增量n HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对 Zset有序集合，每一个元素都会关联一个double类型的分数，redis通过分数来为集合中的成员进行从小到大的排序。socre相同，按字典顺序排序 有序集合成员是唯一的，但分数是可以重复的 应用案例： set排序 存储班级成绩表 工资表排序！ 普通消息，1.重要消息 2.带权重进行判断 排行榜应用实现，取Top N测试 三种特殊数据类型geospatial 地理位置Geo 底层的索引结构是 sorted set 在redis 3.2版本推出；这个功能可以推算地理位置的信息，两地之间的距离 只有6个命令 有效的经度介于 -180 度至 180 度之间。 有效的纬度介于 -85.05112878 度至 85.05112878 度之间。 当用户尝试输入一个超出范围的经度或者纬度时，GEOADD命令将返回一个错误。 说明: 没有 GEODEL 命令，因为可以使用 ZREM来删除元素。Geo 底层的索引结构是 sorted set 。 12345#添加地理位置#规则：两级无法直接添加，一般下载城市数据，通过程序一次性导入#纬度 经度 名称127.0.0.1:6379&gt; GEOADD China:city 114.13 22.54 Shenzhen(integer) 1 GEOPOS用于从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil; 命令接受可变数量的位置元素作为输入， 所以即使用户只给定了一个位置元素， 命令也会返回数组回复 12345127.0.0.1:6379&gt; GEOPOS China:city Beijing Chongqing1) 1) &quot;116.39999896287918091&quot; 2) &quot;39.90000009167092543&quot;2) 1) &quot;106.49999767541885376&quot; 2) &quot;29.52999957900659211&quot; GEODIST 命令用于返回两个给定位置之间的直线距离。 如果两个位置之间的其中一个不存在， 那么命令返回空值。 距离单位参数说明： m ：米，默认单位。 km ：千米。 mi ：英里。 ft ：英尺。 12127.0.0.1:6379&gt; GEODIST China:city Beijing Shanghai km&quot;1068.3949&quot; GEODIST命令以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素 命令会返回额外的信息： WITHDIST ： 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。 距离的单位和用户给定的范围单位保持一致。 WITHCOORD ： 将位置元素的经度和维度也一并返回 WITHHASH ： 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。 命令默认返回未排序的位置元素。 通过以下两个参数， 用户可以指定被返回位置元素的排序方式： ASC ： 根据中心的位置， 按照从近到远的方式返回位置元素。 DESC ： 根据中心的位置， 按照从远到近的方式返回位置元素。 在默认情况下，命令会返回所有匹配的位置元素。 虽然用户可以使用 COUNT &lt;count&gt; 选项去获取前 N 个匹配元素， 但是因为命令在内部可能会需要对所有被匹配的元素进行处理， 所以在对一个非常大的区域进行搜索时， 即使只使用 COUNT 选项去获取少量元素， 命令的执行速度也可能会非常慢。 但是从另一方面来说， 使用 COUNT 选项去减少需要返回的元素数量， 对于减少带宽来说仍然是非常有用的 12345127.0.0.1:6379&gt; GEORADIUS China:city 110 30 500 km withdist1) 1) &quot;Chongqing&quot; 2) &quot;341.9374&quot;2) 1) &quot;Xian&quot; 2) &quot;483.8340&quot; 用于返回一个或多个位置元素的 Geohash 表示。Redis GEO 使用 geohash 来保存地理位置的坐标。 一个数组， 数组的每个项都是一个 geohash 。 命令返回的 geohash 的位置与用户给定的位置元素的位置一一对应。 123127.0.0.1:6379&gt; GEOHASH China:city Shanghai Hangzhou1) &quot;wtw3s57v8j0&quot;2) &quot;wtmkq069cc0&quot; Hyperloglog 基数统计基数：不重复元素 redis 2.8.9版本更新了该数据结构 优点：占用的内存是固定的，2^64不同的元素的技术，只需要12kb的内存，从内存角度看，该数据结构为首选 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 其底层使用string数据类型 应用场景 网页的访问量（UV），用户访问多次，只能算作一个人 传统实现，存储用户的id，然后每次进行比较。当用户变多之后这种方式及其浪费空间，而我们的目的只是计数，Hyperloglog就能帮助我们利用最小的空间完成。 1234567891011121314151617----------PFADD--PFCOUNT---------------------127.0.0.1:6379&gt; PFADD myelemx a b c d e f g h i j k # 添加元素(integer) 1127.0.0.1:6379&gt; type myelemx # hyperloglog底层使用Stringstring127.0.0.1:6379&gt; PFCOUNT myelemx # 估算myelemx的基数(integer) 11127.0.0.1:6379&gt; PFADD myelemy i j k z m c b v p q s(integer) 1127.0.0.1:6379&gt; PFCOUNT myelemy(integer) 11----------------PFMERGE-----------------------127.0.0.1:6379&gt; PFMERGE myelemz myelemx myelemy # 合并myelemx和myelemy 成为myelemzOK127.0.0.1:6379&gt; PFCOUNT myelemz # 估算基数(integer) 17 如果允许容错，那么一定可以使用Hyperloglog ! 如果不允许容错，就使用set或者自己的数据类型即可 ！ Bitmaps使用位存储；是一串连续的二进制数字，每一位所在的位置为偏移；非常的省内存 应用场景：只有是和否的统计，类似于打卡 12345678910111213141516171819202122------------setbit--getbit--------------127.0.0.1:6379&gt; setbit sign 0 1 # 设置sign的第0位为 1 (integer) 0127.0.0.1:6379&gt; setbit sign 2 1 # 设置sign的第2位为 1 不设置默认是0(integer) 0127.0.0.1:6379&gt; setbit sign 3 1(integer) 0127.0.0.1:6379&gt; setbit sign 5 1(integer) 0127.0.0.1:6379&gt; type signstring127.0.0.1:6379&gt; getbit sign 2 # 获取第2位的数值(integer) 1127.0.0.1:6379&gt; getbit sign 3(integer) 1127.0.0.1:6379&gt; getbit sign 4 # 未设置默认是0(integer) 0-----------bitcount----------------------------127.0.0.1:6379&gt; BITCOUNT sign # 统计sign中为1的位数(integer) 4 事务基本操作本质：一组命令的集合，一个事务中的所有命令都会被序列化，在事务执行过程中，会按照顺序执行 一次性，顺序性，排他性！执行一些列的命令 redis事务没有隔离级别的概念 所有命令在事务中并未直接执行，只有发起执行命令的时候才会执行 redis单条命令是保存原子性的，但是事务不保证原子性 redis的事务 开启事务 12127.0.0.1:6379&gt; multiOK 命令入队 12345678127.0.0.1:6379&gt; SET k1 v1QUEUED127.0.0.1:6379&gt; SET k2 v2QUEUED127.0.0.1:6379&gt; GET k2QUEUED127.0.0.1:6379&gt; SET k3 v3QUEUED 执行事务，执行完之后，事务就不再开启了，需要则需重新开启 12345127.0.0.1:6379&gt; exec1) OK2) OK3) &quot;v2&quot;4) OK 放弃事务，事务队列中的命令都不会被执行 1127.0.0.1:6379&gt; DISCARD 编译时异常：代码有问题、命令有错。事务中所有的命令都不会被执行 1234567891011121314127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; error k1 # 这是一条语法错误命令(error) ERR unknown command `error`, with args beginning with: `k1`, # 会报错但是不影响后续命令入队 127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. # 执行报错127.0.0.1:6379&gt; get k1 (nil) # 其他命令并没有被执行 运行时异常：事务队列中存在语法性错误，那么其他命令可以正常执行错误命令抛出异常 123456789101112131415161718127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; INCR k1 # 这条命令逻辑错误（对字符串进行增量）QUEUED127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; exec1) OK2) OK3) (error) ERR value is not an integer or out of range # 运行时报错4) &quot;v2&quot; # 其他命令正常执行# 虽然中间有一条命令报错了，但是后面的指令依旧正常执行成功了。# 所以说Redis单条指令保证原子性，但是Redis事务不能保证原子性。 悲观锁很悲观，什么时候都会出问题，无论做什么都会加锁，很影响性能 乐观锁认为什么都不会出问题，所以不会上锁，更新数据的时候判断一下，在此期间是否有人修改过这个数据 获取version 更新的时候比较version redis监视测试 123456789101112131415127.0.0.1:6379&gt; set money 100 # 设置余额:100OK127.0.0.1:6379&gt; set use 0 # 支出使用:0OK127.0.0.1:6379&gt; watch money # 监视money (上锁)OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY use 20QUEUED127.0.0.1:6379&gt; exec # 监视值没有被中途修改，事务正常执行1) (integer) 802) (integer) 20 测试多线程修改值，使用watch可以当作redis的乐观锁操作 我们启动另外一个客户端模拟插队线程。 线程1： 123456789127.0.0.1:6379&gt; watch money # money上锁OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY use 20QUEUED127.0.0.1:6379&gt; # 此时事务并没有执行 模拟线程插队，线程2： 12127.0.0.1:6379&gt; INCRBY money 500 # 修改了线程一中监视的money(integer) 600 回到线程1，执行事务： 123456127.0.0.1:6379&gt; EXEC # 执行之前，另一个线程修改了我们的值，这个时候就会导致事务执行失败(nil) # 没有结果，说明事务执行失败127.0.0.1:6379&gt; get money # 线程2 修改生效&quot;600&quot;127.0.0.1:6379&gt; get use # 线程1事务执行失败，数值没有被修改&quot;0&quot; 解锁获取最新值，然后再加锁进行事务。 解锁获取最新值，然后再加锁进行事务。 如果发现事务执行失败，先unwatch进行解锁。 注意：每次提交执行exec后都会自动释放锁，不管是否成功 持久化redis是内存数据库，如果不讲内存中的数据库保存到磁盘，一旦服务器进程结束，数据库状态也会消失 RDB（Redis Database） 会在指定的时间内将内存中的数据集快照写入磁盘，恢复时将snapshot文件直接读入内存中 redis会单独fork一个子进程来进行持久化，会先将数据都写入一个一个临时文件，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程不进行任何IO操作，进而确保了较高性能； 如果需要进行大规模数据的恢复且对于数据恢复的完整性不是很敏感，那么RDB更高效； 缺点：最后一次持久化的数据可能丢失 默认的是RDB模式，一般情况下不需要修改 在生产环境下，有时候会对其进行备份 RDB保存的文件：dump.rdb 触发情况（如果没有文件，会自动生成） 满足save规则 执行flushall命令 退出redis 使用save命令，会立刻对当前内存中的数据进行持久化，但是会阻塞，save是同步命令，会占用redis的主进程，若redis数据非常多，则命令执行会很慢 bgsave是异步进行，进行持久化操作时候还可以继续响应客户端请求 两者对比 恢复rdb：将rdb文件放在redis的启动目录下，redis在启动时会自动检查并恢复其中的数据 查看需要存在的位置 1config get dir 优点： 适合大规模的数据恢复 如果对数据完整性要求不高 缺点： 需要一定的时间间隔，如果redis意外宕机，最后一次修改的数据就没了 fork进程的时候，会占用一定的内存空间 AOF（Append Only File） 将我们所有的命令都记录下来，类似history，恢复的时候，将所有操作再执行 以日志的形式记录每个写操作，将redis执行过的命令记录下来（读操作除外），只许追加文件而不可以改写文件。redis启动之初会读取该文件重新构建数据。换言之redis重启时会根据日志内容将写指令从前到后的执行一次 文件：appendonly.aof 默认是不开启，需要手动进行配置，之后重启redis就可以生效 如果aof文件有错误，则无法启动redis，需要修复文件 redis提供工具 1redis-check-aof --fix 配置 123456appendonly yes # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分的情况下，rdb完全够用appendfilename &quot;appendonly.aof&quot;# appendfsync always # 每次修改都会sync 消耗性能appendfsync everysec # 每秒执行一次 sync 可能会丢失这一秒的数据# appendfsync no # 不执行 sync ,这时候操作系统自己同步数据，速度最快 优点 每一次修改都同步，提高文件完整性 每秒同步一次，可能会丢失一秒的数据 从不同步，效率最高 缺点 数据文件AOF远远大于RDB，修复速度比rdb慢 AOF运行效率也要比RDB慢，所以redis默认的配置是RDB 重写规则 aof默认是文件的无限追加，所以文件会很大 拓展 RDB 持久化方式能够在指定的时间间隔内对你的数据进行快照存储 AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以Redis 协议追加保存每次写的操作到文件末尾，Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。 只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化 同时开启两种持久化方式 在这种情况下，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 RDB 的数据不实时，同时使用两者时服务器重启也只会找AOF文件，那要不要只使用AOF呢？作者建议不要，因为RDB更适合用于备份数据库（AOF在不断变化不好备份），快速重启，而且不会有AOF可能潜在的Bug，留着作为一个万一的手段。 性能建议 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留 save 900 1 这条规则。 如果Enable AOF ，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了，代价一是带来了持续的IO，二是AOF rewrite 的最后将 rewrite 过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上，默认超过原大小100%大小重写可以改到适当的数值。 如果不Enable AOF ，仅靠 Master-Slave Repllcation 实现高可用性也可以，能省掉一大笔IO，也减少了rewrite时带来的系统波动。代价是如果Master&#x2F;Slave 同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个 Master&#x2F;Slave 中的 RDB文件，载入较新的那个，微博就是这种架构。 Redis发布订阅发布订阅是一种消息通信模式，发送者发送消息，订阅者接收消息 redis客户端可订阅任意数量的频道 订阅&#x2F;发布消息图： 下图展示了频道channel1和订阅这个频道的三个客户端 client2、client5和client1之间的关系： 当有新消息通过publish命令发送给频道channel1时，这个消息会被发送给订阅她的三个客户端 命令123456PSUBSCRIBE pattern [pattern..] #订阅一个或多个符合给定模式的频道。PUNSUBSCRIBE pattern [pattern..] #退订一个或多个符合给定模式的频道。PUBSUB subcommand [argument[argument]] #查看订阅与发布系统状态。PUBLISH channel message #向指定频道发布消息SUBSCRIBE channel [channel..] #订阅给定的一个或多个频道。UNSUBSCRIBE channel [channel..] #退订一个或多个频道 示例 1234567891011121314151617181920212223242526272829303132333435#------------订阅端----------------------127.0.0.1:6379&gt; SUBSCRIBE sakura # 订阅sakura频道Reading messages... (press Ctrl-C to quit) # 等待接收消息1) &quot;subscribe&quot; # 订阅成功的消息2) &quot;sakura&quot;3) (integer) 11) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello world&quot;2) &quot;sakura&quot;3) &quot;hello world&quot;1) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello i am sakura&quot;2) &quot;sakura&quot;3) &quot;hello i am sakura&quot;#--------------消息发布端-------------------127.0.0.1:6379&gt; PUBLISH sakura &quot;hello world&quot; # 发布消息到sakura频道(integer) 1127.0.0.1:6379&gt; PUBLISH sakura &quot;hello i am sakura&quot; # 发布消息(integer) 1#-----------------查看活跃的频道------------127.0.0.1:6379&gt; PUBSUB channels&quot;sakura&quot; 原理Redis是使用C实现的，通过分析 Redis 源码里的 pubsub.c 文件，了解发布和订阅机制的底层实现，籍此加深对 Redis 的理解。 Redis 通过 PUBLISH 、SUBSCRIBE 和 PSUBSCRIBE 等命令实现发布和订阅功能。 每个 Redis 服务器进程都维持着一个表示服务器状态的 redis.h&#x2F;redisServer 结构， 结构的 pubsub_channels 属性是一个字典， 这个字典就用于保存订阅频道的信息，其中，字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。发送消息则相当于遍历列表发送。 也可以设定对某一个key值发布消息，消息发布后所有被订阅的客户端都会收到消息，用法：实时聊天系统 客户端订阅，就被链接到对应频道的链表的尾部，退订则就是将客户端节点从链表中移除 缺点 如果一个客户端订阅了频道，但自己读取消息的速度却不够快的话，那么不断积压的消息会使redis输出缓冲区的体积变得越来越大，这可能使得redis本身的速度变慢，甚至直接崩溃。 这和数据传输可靠性有关，如果在订阅方断线，那么他将会丢失所有在短线期间发布者发布的消息。 应用 消息订阅：公众号订阅，微博关注等等（起始更多是使用消息队列来进行实现） 多人在线聊天室。 稍微复杂的场景，我们就会使用消息中间件MQ处理。 redis主从复制概念主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点（Master&#x2F;Leader）,后者称为从节点（Slave&#x2F;Follower）， 数据的复制是单向的！只能由主节点复制到从节点（主节点以写为主、从节点以读为主）。 默认情况下，每台Redis服务器都是主节点，一个主节点可以有0个或者多个从节点，但每个从节点只能由一个主节点。 作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余的方式。 故障恢复：当主节点故障时，从节点可以暂时替代主节点提供服务，是一种服务冗余的方式 负载均衡：在主从复制的基础上，配合读写分离，由主节点进行写操作，从节点进行读操作，分担服务器的负载；尤其是在多读少写的场景下，通过多个从节点分担负载，提高并发量。 高可用基石：主从复制还是哨兵和集群能够实施的基础。 为什么使用集群一般来说，要将Redis运用于工程项目中，只使用一台Redis是万万不能的（宕机），原因如下： 1、从结构上，单个Redis服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较大； 2、从容量上，单个Redis服务器内存容量有限，就算一台Redis服务器内存容量为256G，也不能将所有内存用作Redis存储内存，一般来说，单台Redis最大使用内存不应该超过20G。 电商网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是”多读少写”。 对于这种场景，我们可以使如下这种架构： 主从复制，读写分离！ 80% 的情况下都是在进行读操作！减缓服务器的压力！架构中经常使用！ 一主二从！ 只要在公司中，主从复制就是必须要使用的，因为在真实的项目中不可能单机使用Redis！ 总结 单台服务器难以负载大量的请求 单台服务器故障率高，系统崩坏概率大 单台服务器内存容量有限。 环境配置只配置从库，不用配置主库！ 123456789101112127.0.0.1:6379&gt; info replication# Replicationrole:master # 角色connected_slaves:0 # 从机数量master_replid:3b54deef5b7b7b7f7dd8acefa23be48879b4fcffmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 复制3个配置文件，然后修改对应的信息 端口 pid名字 log文件名 dump.rdb名字 启动单机多服务集群，可通过进程信息查看： 1ps -ef|grep redis 一主二从配置默认情况下，每台Redis服务器都是主节点； 一般情况下只用配置从机就好了 认老大！一主（79）二从（80，81） 使用此命令就可以为从机配置主机： 1SLAVEOF 127.0.0.1 [PORT] 真实的从主配置应该在配置文件中配置，这样的话是永久的，我们这里使用的是命令，暂时的！ 使用规则1.从机只能读，不能写，主机可读可写但是多用于写。 12345678910111213141516127.0.0.1:6381&gt; set name sakura # 从机6381写入失败(error) READONLY You can&#x27;t write against a read only replica.127.0.0.1:6380&gt; set name sakura # 从机6380写入失败(error) READONLY You can&#x27;t write against a read only replica.127.0.0.1:6379&gt; set name sakuraOK127.0.0.1:6379&gt; get name&quot;sakura&quot; 2.当主机断电宕机后，默认情况下从机的角色不会发生变化 ，集群中只是失去了写操作，当主机恢复以后，又会连接上从机恢复原状。 3.当从机断电宕机后，若不是使用配置文件配置的从机，再次启动后作为主机是无法获取之前主机的数据的，若此时重新配置称为从机，又可以获取到主机的所有数据。这里就要提到一个同步原理。 4.第二条中提到，默认情况下，主机故障后，不会出现新的主机，有两种方式可以产生新的主机： 从机手动执行命令slaveof no one,这样执行以后从机会独立出来成为一个主机 使用哨兵模式（自动选举） 如果没有老大了，这个时候能不能选择出来一个老大呢？手动！ 如果主机断开了连接，我们可以使用SLAVEOF no one让自己变成主机！其他的节点就可以手动连接到最新的主节点（手动）！如果这个时候老大修复了，那么就重新连接！ 复制原理Slave 启动成功连接到 master 后会发送一个sync同步命令 Master 接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，并完成一次完全同步。 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：Master 继续将新的所有收集到的修改命令依次传给slave，完成同步 但是只要是重新连接master，一次完全同步（全量复制）将被自动执行！ 我们的数据一定可以在从机中看到！ 层层链路 上一个M连接下一个S 这时候也可以完成主从复制 哨兵模式（自动选举老大的模式） 概述主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。Redis从2.8开始正式提供了Sentinel（哨兵） 架构来解决这个问题。能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。 哨兵的作用： 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover[故障转移]操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。 测试配置哨兵配置文件 sentinel.conf 12# sentinel monitor 被监控的名称 host port 1sentinel monitor myredis 127.0.0.1 6379 1 后面的这个数字1，代表主机挂了，slave投票看让谁接替成为主机，票数最多的，就会成为主机！ 哨兵模式优缺点优点： 哨兵集群，基于主从复制模式，所有主从复制的优点，它都有 主从可以切换，故障可以转移，系统的可用性更好 哨兵模式是主从模式的升级，手动到自动，更加健壮 缺点： Redis不好在线扩容，集群容量一旦达到上限，在线扩容就十分麻烦 实现哨兵模式的配置其实是很麻烦的，里面有很多配置项 哨兵模式的全部配置完整的哨兵模式配置文件 sentinel.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# Example sentinel.conf# 哨兵sentinel实例运行的端口 默认26379port 26379# 哨兵sentinel的工作目录dir /tmp# 哨兵sentinel监控的redis主节点的 ip port# master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。# quorum 配置多少个sentinel哨兵统一认为master主节点失联 那么这时客观上认为主节点失联了# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel monitor mymaster 127.0.0.1 6379 2# 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码# 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster MySUPER--secret-0123passw0rd# 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;sentinel down-after-milliseconds mymaster 30000# 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步，这个数字越小，完成failover所需的时间就越长，但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。# sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;sentinel parallel-syncs mymaster 1# 故障转移的超时时间 failover-timeout 可以用在以下这些方面：#1. 同一个sentinel对同一个master两次failover之间的间隔时间。#2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。#3.当想要取消一个正在进行的failover所需要的时间。#4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了# 默认三分钟# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;sentinel failover-timeout mymaster 180000# SCRIPTS EXECUTION#配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。#对于脚本的运行结果有以下规则：#若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10#若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。#如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。#一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。#通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，一个是事件的类型，一个是事件的描述。如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。#通知脚本# shell编程# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;sentinel notification-script mymaster /var/redis/notify.sh# 客户端重新配置主节点参数脚本# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。# 以下参数将会在调用脚本时传给脚本:# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;# 目前&lt;state&gt;总是“failover”,# &lt;role&gt;是“leader”或者“observer”中的一个。# 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的# 这个脚本应该是通用的，能被多次调用，不是针对性的。# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;sentinel client-reconfig-script mymaster /var/redis/reconfig.sh # 一般都是由运维来配","tags":["note","middleware"],"categories":["middleware"]},{"title":"golang中的interface","path":"/golang/basis/interface/","content":"Interface整理 接口是一种契约，实现类型必须满足它，它描述了类型的行为，规定类型可以做什么。接口彻底将类型能做什么，以及如何做分离开来，使得相同接口的变量在不同的时刻表现出不同的行为，这就是多态的本质。 编写参数是接口变量的函数，这使得它们更具有一般性。 使用接口使代码更具有普适性。 最近在学Go当中的接口，学的有点云里雾里 ，这个interface和Java的也太不像了，我们先来看看Java当中的接口是怎么用的： 首先我们先定义一个接口： 123public interface Study &#123; //使用interface表示这是一个接口 void study(); //接口中只能定义访问权限为public抽象方法，其中public和abstract关键字可以省略&#125; 之后我们用关键字继承： 1234567891011121314151617181920public class Student extends Person implements Study &#123; //使用implements关键字来实现接口 public Student(String name, int age, String sex) &#123; super(name, age, sex, &quot;学生&quot;); &#125; @Override public void study() &#123; //实现接口时，同样需要将接口中所有的抽象方法全部实现 System.out.println(&quot;我会学习！&quot;); &#125;&#125;public class Teacher extends Person implements Study &#123; protected Teacher(String name, int age, String sex) &#123; super(name, age, sex, &quot;教师&quot;); &#125; @Override public void study() &#123; System.out.println(&quot;我会加倍学习！&quot;); &#125; 这样一个显示继承的方式非常清晰明了，接下来看看Go里面的接口： 12345type Namer interface &#123; Method1(param_list) return_type Method2(param_list) return_type ...&#125; 这样一看没有什么很大的区别，都需要先声明一个接口但是不使用，接下来看看接口的实现： 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;type Shaper interface &#123;\tArea() float32&#125;type Square struct &#123;\tside float32&#125;func (sq *Square) Area() float32 &#123;\treturn sq.side * sq.side&#125;func main() &#123;\tsq1 := new(Square)\tsq1.side = 5\tvar areaIntf Shaper\tareaIntf = sq1\t// shorter,without separate declaration:\t// areaIntf := Shaper(sq1)\t// or even:\t// areaIntf := sq1\tfmt.Printf(&quot;The square has area: %f &quot;, areaIntf.Area())&#125; 这样就会发现如下几个区别： 并没有显式继承 接口能声明变量，并通过该变量指向方法 实现方法中的参数为自定义的结构体 一个接口类型的变量或一个 接口值 ： 首先我们来看第一点，关于为什么不显示继承，这一点我在网上搜过，观点基本是Go强调的是组合而非继承，并没有一个很确切的理论，那暂且不议 第二点：areaIntf是一个多字（multiword）数据结构，它的值是 nil。接口变量里包含了接收者实例的值和指向对应方法表的指针。 在Go中，我们自定义的结构体就像Java中的类一样，可以实现接口中的方法。我们可以同一个接口被实现多次。当时就有了点疑问：不是不允许函数重载吗？后来发现方法和函数是完全不同的概念： Go中不允许函数（function）重载是为了提高效率，而方法（method）的可多次实现则体现了Go的多态，也就是根据场景选择。 接下来，我们看一些进阶功能： 接口嵌套接口在Java 和go当中，我们都倡导一个接口的简洁明了。比如说先定义一个结构体为综测，综测又是由考试成绩、竞赛、体育等等组成，考试成绩里面又有不同科，体育里面也有不同科，这个时候我们就应该分开定义，之后进行嵌套。我个人的理解的理解就是类似于树一样的存在，而一个结构体就是一个父节点。这里还是放一个实例： 123456789101112type ReadSeeker interface &#123;\tReader\tSeeker&#125;type Reader interface &#123;\tRead(p []byte) (n int, err error)&#125;type Seeker interface &#123;\tSeek(offset int64, whence int) (int64, error)&#125; 类型断言我们通常会想知道一个接口变量里面是什么类型，这个时候我们就会用到类型断言，通用格式为： 1typeA := var1.(T) var1为接口变量，T是想知道的类型。如果转换合法，typeA 是 var1转换到类型 T 的值 如果在判断式中使用，则是这样的： 123if t, ok := areaIntf.(*Square); ok &#123; fmt.Printf(&quot;The type of areaIntf is: %T &quot;, t)&#125; 如果转换合法，t 是 转换到类型的值，ok 会是 true；否则 t是类型的零值，ok 是 false，也没有运行时错误发生。 注意：如果忽略 areaIntf.(*Square) 中的 * 号，会导致编译错误：impossible type assertion: Square does not implement Shaper (Area method has pointer receiver)。 同理，我们也可以判断他是否属于该接口： 1234567type Stringer interface &#123; String() string&#125;if sv, ok := v.(Stringer); ok &#123; fmt.Printf(&quot;v implements String(): %s &quot;, sv.String()) // note: sv, not v&#125; 类型判断 type-switch个人认为如果说类型断言是只想知道值是不是某个类型，那么此语句则是想知道究竟是哪个重要的类型或者不需要知道的类型，常见用法如下： 123456789101112131415161718func classifier(items ...interface&#123;&#125;) &#123;\tfor i, x := range items &#123; switch x.(type) &#123; case bool: fmt.Printf(&quot;Param #%d is a bool &quot;, i) case float64: fmt.Printf(&quot;Param #%d is a float64 &quot;, i) case int, int64: fmt.Printf(&quot;Param #%d is a int &quot;, i) case nil: fmt.Printf(&quot;Param #%d is a nil &quot;, i) case string: fmt.Printf(&quot;Param #%d is a string &quot;, i) default: fmt.Printf(&quot;Param #%d is unknown &quot;, i) &#125;\t&#125;&#125; 可以用 type-switch 进行运行时类型分析，但是在 type-switch 不允许有 fallthrough 。 使用方法集与接口作用于变量上的方法实际上是不区分变量到底是指针还是值的。当碰到接口类型值时，这会变得有点复杂，原因是接口变量中存储的具体值是不可寻址的， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport (\t&quot;fmt&quot;)type List []intfunc (l List) Len() int &#123;\treturn len(l)&#125;func (l *List) Append(val int) &#123;\t*l = append(*l, val)&#125;type Appender interface &#123;\tAppend(int)&#125;func CountInto(a Appender, start, end int) &#123;\tfor i := start; i &lt;= end; i++ &#123; a.Append(i)\t&#125;&#125;type Lener interface &#123;\tLen() int&#125;func LongEnough(l Lener) bool &#123;\treturn l.Len()*10 &gt; 42&#125;func main() &#123;\t// A bare value\tvar lst List\t// compiler error:\t// cannot use lst (type List) as type Appender in argument to CountInto:\t// List does not implement Appender (Append method has pointer receiver) CountInto(lst, 1, 10) //错误代码 if LongEnough(lst) &#123; // VALID: Identical receiver type fmt.Printf(&quot;- lst is long enough &quot;)\t&#125;\t// A pointer value\tplst := new(List)\tCountInto(plst, 1, 10) // VALID: Identical receiver type\tif LongEnough(plst) &#123; // VALID: a *List can be dereferenced for the receiver fmt.Printf(&quot;- plst is long enough &quot;)\t&#125;&#125; 输出 讨论 在 lst 上调用 CountInto 时会导致一个编译器错误，因为 CountInto 需要一个 Appender，而它的方法 Append 只定义在指针上。 在 lst 上调用 LongEnough 是可以的，因为 Len 定义在值上。 在 plst 上调用 CountInto 是可以的，因为 CountInto 需要一个 Appender，并且它的方法 Append 定义在指针上。 在 plst 上调用 LongEnough 也是可以的，因为指针会被自动解引用。 总结 在接口上调用方法时，必须有和方法定义时相同的接收者类型或者是可以根据具体类型 P 直接辨识的： 指针方法可以通过指针调用 值方法可以通过值调用 接收者是值的方法可以通过指针调用，因为指针会首先被解引用 接收者是指针的方法不可以通过值调用，因为存储在接口中的值没有地址 将一个值赋值给一个接口时，编译器会确保所有可能的接口方法都可以在此值上被调用，因此不正确的赋值在编译期就会失败。 译注 Go 语言规范定义了接口方法集的调用规则： 类型 T 的可调用方法集包含接受者为 T或 T 的所有方法集 类型 T 的可调用方法集包含接受者为 T的所有方法 类型 T 的可调用方法集不包含接受者为 T 的方法 接下来我们讨论下空接口 空接口定义：不包含任何方法，对实现没有要求 空接口类似 Java/C# 中所有类的基类： Object 类，二者的目标也很相近。 可以给一个空接口类型的变量 var val interface &#123;&#125; 赋任何类型的值 每个 interface &#123;&#125; 变量在内存中占据两个字长：一个用来存储它包含的类型，另一个用来存储它包含的数据或者指向数据的指针。 这样光看似乎觉得没什么大不了的，我们举个例子，比如说创建树或者其他数据结构，如果我们要根据每个数据类型来定义不同的方法，那无疑是很浪费时间的，这时候就可以用到空接口，实现一键通用： 12345678910111213141516171819202122232425262728293031package mainimport (\t&quot;fmt&quot;)type Node struct &#123;\tle *Node\tdata interface&#123;&#125;\trl *Node&#125;func NewNode(left, right *Node) *Node &#123;\treturn &amp;Node&#123;left, nil, right&#125;&#125;func (n *Node) setData(data interface&#123;&#125;) &#123;\tn.data = data&#125;func main() &#123;\troot := NewNode(nil, nil)\troot.setData(&quot;root node&quot;)\ta := NewNode(nil, nil)\ta.setData(&quot;left node&quot;)\tb := NewNode(nil, nil)\tb.setData(1)\troot.le = a\troot.rl = b\tfmt.Printf(&quot;%v &quot;, root)&#125; 接口赋值给接口一个接口的值可以赋值给另一个接口变量，前提是底层类型实现了必要的方法，此转换是在运行时检查的，转换失败的时候会导致一个运行时错误，这也是GO的动态的一点 比如此代码 1234567891011121314151617181920212223242526272829package mainimport &quot;fmt&quot;type Shaper interface &#123; Area() float64&#125;type Square struct &#123; side float64&#125;func (s Square) Area() float64 &#123; return s.side * s.side&#125;type Circle struct &#123; radius float64&#125;func main() &#123; var s Shaper c := Circle&#123;radius: 5.0&#125; // 错误的示例：将接口 Shaper 赋值给接口 Shaper，但底层类型 Circle 并没有实现 Area() 方法 s = c fmt.Printf(&quot;Area of the shape: %f &quot;, s.Area())&#125; 错误显示： 实例我们来看一些实际应用，在GORM框架中，我们创建对象可以使用map的数据结构导入，但是我们无法保证数据都是一个类型，所以就需要一个空接口来帮我们接住所有类型： 1234db.Model(&amp;User&#123;&#125;).Create([]map[string]interface&#123;&#125;&#123; &#123;&quot;Name&quot;: &quot;jinzhu_1&quot;, &quot;Age&quot;: 18&#125;, &#123;&quot;Name&quot;: &quot;jinzhu_2&quot;, &quot;Age&quot;: 20&#125;,&#125;)","tags":["note","golang"],"categories":["golang","basis"]},{"title":"关于阿里云服务器Ubuntu系统安装jdk8中遇到的坑及解决方案","path":"/Java/JVM/Ubuntu-install-jdk8/","content":"关于阿里云服务器Ubuntu系统安装jdk8中遇到的坑及解决方案关于阿里云服务器无法登录的问题基本反馈是这样的： 如果你添加了ip之后仍然登不进去，有一种方法是直接从第三个选项进去登录之后修改文件 然后输入命令： 1vim /etc/ssh/sshd_config 再在最底部修改PasswordAuthentication的参数为yes，输入:wq之后输入命令（直接重启也行）： 1service sshd restart 安装旧版gcc先安装一些基本的依赖： 1sudo apt install build-essential libxrender-dev xorg-dev libasound2-dev libcups2-dev gawk zip libxtst-dev libxi-dev libxt-dev gobjc 接着我们先将JDK的编译环境配置好，首先是安装gcc和g++的4.8版本，但是最新的源没有这个版本了，我们先导入旧版软件源： 1sudo vim /etc/apt/sources.list 在最下方添加旧版源地址并保存： 12deb http://archive.ubuntu.com/ubuntu xenial maindeb http://archive.ubuntu.com/ubuntu xenial universe 接着更新一下apt源信息，并安装gcc和g++： 12sudo apt updatesudo apt install gcc-4.8 g++-4.8 于是在这里就碰见问题了，他说找不到 1Can not run configure command: &quot;No such file or directory&quot; 于是网上提供了两种方案 第一种解决了gcc的安装问题 1sudo apt-get install gcc-4.8 g++-4.8 第二种，则解决了所有问题 12345678910wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-4.8/g++-4.8_4.8.5-4ubuntu8_amd64.deb wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-4.8/libstdc++-4.8-dev_4.8.5-4ubuntu8_amd64.deb wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-4.8/gcc-4.8-base_4.8.5-4ubuntu8_amd64.deb wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-4.8/gcc-4.8_4.8.5-4ubuntu8_amd64.deb wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-4.8/libgcc-4.8-dev_4.8.5-4ubuntu8_amd64.deb wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-4.8/cpp-4.8_4.8.5-4ubuntu8_amd64.deb wget http://mirrors.kernel.org/ubuntu/pool/universe/g/gcc-4.8/libasan0_4.8.5-4ubuntu8_amd64.deb sudo apt install ./gcc-4.8_4.8.5-4ubuntu8_amd64.deb ./gcc-4.8-base_4.8.5-4ubuntu8_amd64.deb ./libstdc++-4.8-dev_4.8.5-4ubuntu8_amd64.deb ./cpp-4.8_4.8.5-4ubuntu8_amd64.deb ./libgcc-4.8-dev_4.8.5-4ubuntu8_amd64.deb ./libasan0_4.8.5-4ubuntu8_amd64.deb ./g++-4.8_4.8.5-4ubuntu8_amd64.debsudo apt updatesudo apt-get install gcc-4.8 g++-4.8 接着配置： 12sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 100sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.8 100 最后查看版本是否为4.8版本： 1234567891011nagocoler@ubuntu-server:~$ gcc --versiongcc (Ubuntu 4.8.5-4ubuntu2) 4.8.5Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.nagocoler@ubuntu-server:~$ g++ --versiong++ (Ubuntu 4.8.5-4ubuntu2) 4.8.5Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 接着安装make 3.81版本，需要从官方下载： 1wget https://ftp.gnu.org/gnu/make/make-3.81.tar.gz 下载好之后进行解压，并进入目录： 12tar -zxvf make-3.81.tar.gz cd make-3.81/ 接着我们修改一下代码，打开glob/glob.c文件： 12345678...#ifdef HAVE_CONFIG_H# include &lt;config.h&gt;#endif#define __alloca alloca &lt;- 添加这一句/* Enable GNU extensions ... 接着进行配置并完成编译和安装： 12bash configuresudo make install 安装完成后，将make已经变成3.81版本了： 123456nagocoler@ubuntu-server:~/make-3.81$ make -verisonGNU Make 3.81Copyright (C) 2006 Free Software Foundation, Inc.This is free software; see the source for copying conditions.There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR APARTICULAR PURPOSE. 安装jdk8源码OpenJDK源码 于JDK中某些代码是Java编写的，所以我们还需要安装一个启动JDK，启动JDK可以是当前版本或低一版本，比如我们要编译JDK8的源码，那么就可以使用JDK7、JDK8作为启动JDK，对源码中的一些java文件进行编译。这里我们选择安装OpenJDK8作为启动JDK： 1sudo apt install openjdk-8-jdk 这样，我们的系统环境就准备完成了，接着我们需要下载OpenJDK8的源码（已经放在网盘了）解压： 1unzip jdk-jdk8-b120.zip 接着我们需要安装JetBrains Gateway在我们的服务器上导入项目，这里我们使用CLion后端，等待下载远程后端，这样我们的Linux服务器上虽然没有图形化界面，但是依然可以使用IDEA、CLion等工具，只是服务器上只有后端程序，而界面由我们电脑上的前端程序提供（目前此功能还在Beta阶段，暂不支持arm架构的Linux服务器）整个过程根据服务器配置决定可能需要5-20分钟。 完成之后，我们操作起来就很方便了，界面和IDEA其实差不多，我们打开终端，开始进行配置： 1bash configure --with-debug-level=slowdebug --enable-debug-symbols ZIP_DEBUGINFO_FIELS=0 配置完成后，再次确认是否和教程中的配置信息一致： 12345678910111213141516171819Configuration summary:* Debug level: slowdebug* JDK variant: normal* JVM variants: server* OpenJDK target: OS: linux, CPU architecture: x86, address length: 64Tools summary:* Boot JDK: openjdk version &quot;1.8.0_312&quot; OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07) OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode) (at /usr/lib/jvm/java-8-openjdk-amd64)* C Compiler: gcc-4.8 (Ubuntu 4.8.5-4ubuntu2) version 4.8.5 (at /usr/bin/gcc-4.8)* C++ Compiler: g++-4.8 (Ubuntu 4.8.5-4ubuntu2) version 4.8.5 (at /usr/bin/g++-4.8)Build performance summary:* Cores to use: 3* Memory limit: 3824 MB* ccache status: not installed (consider installing)WARNING: The result of this configuration has overridden an olderconfiguration. You *should* run &#x27;make clean&#x27; to make sure you get aproper build. Failure to do so might result in strange build problems. 接着我们需要修改几个文件，不然一会会编译失败，首先是hotspot/make/linux/Makefile文件： 12原有的 SUPPORTED_OS_VERSION = 2.4% 2.5% 2.6% 3%修改为 SUPPORTED_OS_VERSION = 2.4% 2.5% 2.6% 3% 4% 5% 接着是hotspot/make/linux/makefiles/gcc.make文件： 12原有的 WARNINGS_ARE_ERRORS = -Werror修改为 #WARNINGS_ARE_ERRORS = -Werror 接着是nashorn/make/BuildNashorn.gmk文件： 12345 $(CP) -R -p $(NASHORN_OUTPUTDIR)/nashorn_classes/* $(@D)/ $(FIXPATH) $(JAVA) \\原有的 -cp &quot;$(NASHORN_OUTPUTDIR)/nasgen_classes$(PATH_SEP)$(NASHORN_OUTPUTDIR)/nashorn_classes&quot; \\修改为 -Xbootclasspath/p:&quot;$(NASHORN_OUTPUTDIR)/nasgen_classes$(PATH_SEP)$(NASHORN_OUTPUTDIR)/nashorn_classes&quot; \\ jdk.nashorn.internal.tools.nasgen.Main $(@D) jdk.nashorn.internal.objects $(@D) 开始编译： 1make all 这里又遇到了问题 1gmake[5]: *** [/root/jdk-jdk8-b120/hotspot/make/linux/makefiles/top.make:91: ad_stuff] Error 2 后来发现最主要应该是看前面的内容 1sys/sysctl.h: No such file or directory #include &lt;sys/sysctl.h&gt; 后来在网上查了才知道是Ubuntu的版本已经取消了这个头文件，我的版本： 所以我们需要做的就是按照他所说的文件报错然后把该文件里的该头文件删掉 12vim build/linux-x86_64-normal-server-slowdebug/jdk/objs/libnet/PlainSocketImpl.ovim jdk/src/solaris/native/java/net/PlainDatagramSocketImpl.c 注释 1// #include &lt;sys/sysctl.h&gt; 最后弄了两三天的东西终于好了","tags":["经验总结","JVM"],"categories":["Java","JVM"]},{"title":"SpringBoot邮件发送","path":"/Java/SpringBoot/springboot-email/","content":"springboot邮件篇要在Internet上提供电子邮件功能，必须有专门的电子邮件服务器。例如现在Internet很多提供邮件服务的厂商：新浪、搜狐、163、QQ邮箱等，他们都有自己的邮件服务器。这些服务器类似于现实生活中的邮局，它主要负责接收用户投递过来的邮件，并把邮件投递到邮件接收者的电子邮箱中。 所有的用户都可以在电子邮件服务器上申请一个账号用于邮件发送和接收，那么邮件是以什么样的格式发送的呢？实际上和Http一样，邮件发送也有自己的协议，也就是约定邮件数据以及如何通信。 比较常用的协议有两种： SMTP协议（主要用于发送邮件 Simple Mail Transfer Protocol） POP3协议（主要用于接收邮件 Post Office Protocol 3） 整个发送&#x2F;接收流程大致如下： 实际上每个邮箱服务器都有一个smtp发送服务器和pop3接收服务器，比如要从QQ邮箱发送邮件到163邮箱，那么我们只需要通过QQ邮箱客户端告知QQ邮箱的smtp服务器我们需要发送邮件，以及邮件的相关信息，然后QQ邮箱的smtp服务器就会帮助我们发送到163邮箱的pop3服务器上，163邮箱会通过163邮箱客户端告知对应用户收到一封新邮件。 如果想要实现给别人发送邮件，那么就需要连接到对应电子邮箱的smtp服务器上，并告知其要发送邮件。而SpringBoot已经帮助我们将最基本的底层通信全部实现了，我们只需要关心smtp服务器的地址以及我们要发送的邮件长啥样即可。 这里以163邮箱 https://mail.163.com 为例，我们需要在配置文件中告诉SpringBootMail我们的smtp服务器的地址以及你的邮箱账号和密码，首先我们要去设置中开启smtp&#x2F;pop3服务才可以，开启后会得到一个随机生成的密钥，这个就是我们的密码。 发送邮件导入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 获取password，邮箱中点开设置，打开smtp服务，获取密钥 设置yml文件 1234mail: host: smtp.163.com username: @163.com password: 代码生成 12345678910111213141516@SpringBootTestclass Demo8ApplicationTests &#123; @Resource JavaMailSender sender; @Test void contextLoads() &#123; SimpleMailMessage message = new SimpleMailMessage(); message.setSubject(&quot;[西安邮电大学教务处]关于近期学校决定对您进行军训的通知&quot;); //设置邮件标题 message.setText(&quot;xxx同学你好，经学校体育部决定，您很有参加军训的必要，请明天上午7点务必到操场集合，学校为您准备了一对一服务&quot;); //设置邮件内容 message.setTo(&quot;your@icloud.com&quot;); message.setFrom(&quot;your@163.com&quot;); sender.send(message); &#125;&#125; 最后点击发送 验证码的发送注册网站的时候通常要接收验证码，且验证码有有效期 发送验证码与之前没什么很大的区别，引用一个Random类就行 此处给验证过程代码 1234567891011121314151617@PostMapping(&quot;/register&quot;)public String register(@RequestParam String username, @RequestParam String email, @RequestParam String code, @RequestParam String password, HttpSession session) &#123; String sessionCode = (String) session.getAttribute(&quot;code&quot;); String sessionEmail = (String) session.getAttribute(&quot;email&quot;); if(sessionCode == null) &#123; return &quot;请先获取验证码&quot;; &#125; if(!sessionCode.equals(code)) &#123; return &quot;验证码不正确&quot;; &#125; mapper.createUser(username,email,password); return &quot;注册成功&quot;;&#125;","tags":["SpringBoot"],"categories":["Java","SpringBoot"]},{"title":"git日常操作个人总结","path":"/tools/Git/","content":"Git项目简单克隆git在本人日常中最重要的功能还是下载，所以先从下载开始讲起 首先，创建一个文件，用来存放等会clone下来的项目，然后点击GitBash进行命令行操作 之后 在git上找到你中意的项目，如图操作，复制链接 1git clone https://github.com/newbee-ltd/newbee-mall.git 之后就会看到他在clone你的项目到本地文件夹，当然你也可以直接Download zip然后解压： 通用操作之后讲通用的，先配置用户名 12git config --global user.name “ ”git config --global user.email “ ” 然后创建本地仓库 1git init 打开此选项，查看隐藏的文件夹： 发现 这个目录是一个隐藏目录，而当前目录就是我们的工作目录。 创建成功后，我们可以查看一下当前的一个状态，输入： 1git status 如果已经成功配置为Git本地仓库，那么输入后可以看到： 添加和提交接着我们来看看，如何使用git来管理我们文档的版本，我们创建一个文本文档，随便写入一点内容，接着查看状态： Untracked files是未追踪文件的意思，也就是说，如果一个文件处于未追踪状态，那么git不会记录它的变化，始终将其当做一个新创建的文件，这里我们将其添加到暂存区，那么它会自动变为被追踪状态： 12git add hello.txt #也可以 add . 一次性添加目录下所有的再次查看当前状态： 现在文件名称的颜色变成了绿色，并且是处于Changes to be committed下面，因此，我们的hello.txt现在已经被添加到暂存区了。 接着我们来尝试将其提交到Git本地仓库中，注意需要输入提交的描述以便后续查看，比如你这次提交修改了或是新增了哪些内容： 1git commit -m &#x27;Hello World&#x27; 接着我们可以查看我们的提交记录： 12git loggit log --graph 我们还可以查看最近一次变更的详细内容： 1git show [也可以加上commit ID查看指定的提交记录] 接着我们可以尝试修改一下我们的文本文档，由于当前文件已经是被追踪状态，那么git会去跟踪它的变化，如果说文件发生了修改，那么我们再次查看状态会得到下面的结果： 也就是说现在此文件是处于已修改状态，我们如果修改好了，就可以提交我们的新版本到本地仓库中： 12git add .git commit -m &#x27;Modify Text&#x27; 接着我们来查询一下提交记录，可以看到一共有两次提交记录。 我们可以创建一个.gitignore文件来确定一个文件忽略列表，如果忽略列表中的文件存在且不是被追踪状态，那么git不会对其进行任何检查 回滚当我们想要回退到过去的版本时，就可以执行回滚操作，执行后，可以将工作空间的内容恢复到指定提交的状态： 1git reset --hard commitID 执行后，会直接重置为那个时候的状态。再次查看提交日志，我们发现之后的日志全部消失了。 那么要是现在我又想回去呢？我们可以通过查看所有分支的所有操作记录： 1git reflog 这样就能找到之前的commitID，再次重置即可。 分支分支就像我们树上的一个树枝一样，它们可能一开始的时候是同一根树枝，但是长着长着就开始分道扬镳了，这就是分支。我们的代码也是这样，可能一开始写基础功能的时候使用的是单个分支，但是某一天我们希望基于这些基础的功能，把我们的项目做成两个不同方向的项目，比如一个方向做Web网站，另一个方向做游戏服务端。 因此，我们可以在一个主干上分出N个分支，分别对多个分支的代码进行维护。 创建分支我们可以通过以下命令来查看当前仓库中存在的分支： 1git branch 我们发现，默认情况下是有一个master分支的，并且我们使用的也是master分支，一般情况下master分支都是正式版本的更新，而其他分支一般是开发中才频繁更新的。我们接着来基于当前分支创建一个新的分支： 1git branch test 删除分支 1git branch -d test1 现在我们修改一下文件，提交，再查看一下提交日志： 1git commit -a -m &#x27;branch master commit&#x27; 通过添加-a来自动将未放入暂存区的已修改文件放入暂存区并执行提交操作。查看日志，我们发现现在我们的提交只生效于master分支，而新创建的分支并没有发生修改。 将分支切换到另一个分支： 1git checkout test 我们会发现，文件变成了此分支创建的时的状态，也就是说，在不同分支下我们的文件内容是相互隔离的。 我们现在再来提交一次变更，会发现它只生效在yyds分支上。我们可以看看当前的分支状态： 1git log --all --graph 合并分支我们也可以将两个分支更新的内容最终合并到同一个分支上，我们先切换回主分支： 1git checkout test1 接着使用分支合并命令： 1git merge test 会得到如下提示： 在合并过程中产生了冲突，因为两个分支都对hello.txt文件进行了修改，那么现在要合并在一起，到底保留谁的hello文件呢？ 我们可以查看一下是哪里发生了冲突： 1git diff 因此，现在我们将master分支的版本回退到修改hello.txt之前或是直接修改为最新版本的内容，这样就不会有冲突了，接着再执行一次合并操作，现在两个分支成功合并为同一个分支。 变基分支除了直接合并分支以外，我们还可以进行变基操作，它跟合并不同，合并是分支回到主干的过程，而变基是直接修改分支开始的位置，比如我们希望将yyds变基到master上，那么yyds会将分支起点移动到master最后一次提交位置： 1git rebase master 变基后，yyds分支相当于同步了此前master分支的全部提交。 优选我们还可以选择其将他分支上的提交作用于当前分支上，这种操作称为cherrypick： 1git cherry-pick &lt;commit id&gt;:单独合并一个提交 这里我们在master分支上创建一个新的文件，提交此次更新，接着通过cherry-pick的方式将此次更新作用于test分支上。 远程项目推送首先我们需要一个认证 12ssh-keygen -t rsacat ~/.ssh/github.pub 打开所在目录，复制 .pub文件中的所有内容，之后添加ssh key 1234git commit -a -m &#x27;Modify files&#x27;git log --all --oneline --graphgit push origin master git log --all --oneline --graph 推送成功 主页也看到了 也可以远端绑定分支 12git push --set-upstream origin master:mastergit push origin 抓取、拉取和冲突解决我们接着来看，如果这个时候，出现多个本地仓库对应一个远程仓库的情况下，比如一个团队里面，N个人都在使用同一个远程仓库，但是他们各自只负责编写和推送自己业务部分的代码，也就是我们常说的协同工作，那么这个时候，我们就需要协调。 比如程序员A完成了他的模块，那么他就可以提交代码并推送到远程仓库，这时程序员B也要开始写代码了，由于远程仓库有其他程序员的提交记录，因此程序员B的本地仓库和远程仓库不一致，这时就需要有先进行pull操作，获取远程仓库中最新的提交： 12git fetch 远程仓库 #抓取：只获取但不合并远端分支，后面需要我们手动合并才能提交git pull 远程仓库 #拉取：获取+合并 之后可能会出现冲突，例如： 12345678To https://github.com/xx/xxx.git ! [rejected] master -&gt; master (fetch first)error: failed to push some refs to &#x27;https://github.com/xx/xxx.git&#x27;hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., &#x27;git pull ...&#x27;) before pushing again.hint: See the &#x27;Note about fast-forwards&#x27; in &#x27;git push --help&#x27; for details. 一旦一个本地仓库推送了代码，那么另一个本地仓库的推送会被拒绝，原因是当前文件已经被其他的推送给修改了，我们这边相当于是另一个版本，和之前两个分支合并一样，产生了冲突，因此我们只能去解决冲突问题。 如果远程仓库中的提交和本地仓库中的提交没有去编写同一个文件，那么就可以直接拉取： 1git pull 远程仓库 拉取后会自动进行合并，合并完成之后我们再提交即可。 但是如果两次提交都修改了同一个文件，那么就会遇到和多分支合并一样的情况，在合并时会产生冲突，这时就需要我们自己去解决冲突了。 IEDA类软件连接以下使用GoLand作为范例，IDEA也大差不差 之后登陆账户 之后就可以提交了，命令都大差不差","tags":["git","经验总结"],"categories":["tools"]},{"title":"SpringSecurity总结","path":"/Java/SpringSecurity/SpringSecurity/","content":"SpringSecurity[TOC] SpringSecurity是一个基于Spring开发的非常强大的权限验证框架，其核心功能包括： 认证 （用户登录） 授权 （此用户能够做哪些事情） 攻击防护 （防止伪造身份攻击） CSRF跨站请求伪造攻击我们时常会在QQ上收到别人发送的钓鱼网站链接，只要你在上面登陆了你的QQ账号，那么不出意外，你的号已经在别人手中了。实际上这一类网站都属于恶意网站，专门用于盗取他人信息，执行非法操作，甚至获取他人账户中的财产，非法转账等。而这里，我们需要了解一种比较容易发生的恶意操作，从不法分子的角度去了解整个流程。 在一开始的时候，服务端会给浏览器一个名为JSESSION的Cookie信息作为会话的唯一凭据，只要用户携带此Cookie访问我们的网站，那么我们就可以认定此会话属于哪个浏览器。因此，只要此会话的用户执行了登录操作，那么就可以随意访问个人信息等内容 比如现在，服务器新增了一个转账的接口，用户登录之后，只需要使用POST请求携带需要转账的金额和转账人访问此接口就可以进行转账操作： 1234567891011121314151617181920212223242526272829303132333435363738394041@Controllerpublic class HelloController &#123; @PostMapping(&quot;/login&quot;) public String login(@RequestParam String username, @RequestParam String password, HttpSession session, Model model) &#123; if(&quot;test&quot;.equals(username) &amp;&amp; &quot;123456&quot;.equals(password)) &#123; session.setAttribute(&quot;login&quot;,true); return &quot;redirect:/&quot;; &#125;else &#123; model.addAttribute(&quot;status&quot;, true); return &quot;login&quot;; &#125; &#125; @ResponseBody @PostMapping(&quot;/pay&quot;) public JSONObject pay(@RequestParam String account, HttpSession session) &#123; JSONObject object = new JSONObject(); if(session.getAttribute(&quot;login&quot;) != null) &#123; System.out.println(&quot;to&quot; + account + &quot;success&quot;); object.put(&quot;success&quot;, true); &#125; else &#123; System.out.println(&quot;failed&quot;); object.put(&quot;success&quot;, false); &#125; return object; &#125; @GetMapping(&quot;/&quot;) public String index(HttpSession session) &#123; if(session.getAttribute(&quot;login&quot;) != null) &#123; return &quot;index&quot;; &#125; else &#123; return &quot;login&quot;; &#125; &#125;&#125; 我们一不小心访问了一个恶意网站，而此网站携带了这样一段内容： 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Your favorite&lt;/title&gt; &lt;script src=&quot;https://unpkg.com/axios@1.1.2/dist/axios.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;iframe name=&quot;hiddenIframe&quot; hidden&gt;&lt;/iframe&gt;&lt;form action=&quot;http://localhost:8080/mvc/pay&quot; method=&quot;post&quot; target=&quot;hiddenIframe&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;account&quot; value=&quot;hacker&quot; hidden&gt; &lt;button type=&quot;submit&quot;&gt;Click to download&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 注意这个页面并不是我们官方提供的页面，而是不法分子搭建的恶意网站。我们发现此页面中有一个表单，但是表单中的两个输入框被隐藏了，而我们看到的只有一个按钮，我们不知道这是一个表单，也不知道表单会提交给那个地址，这时整个页面就非常有迷惑性了。如果我们点击此按钮，那么整个表单的数据会以POST的形式发送给我们的服务端（会携带之前登陆我们网站的Cookie信息），但是这里很明显是另一个网站跳转，通过这样的方式，恶意网站就成功地在我们毫不知情的情况下引导我们执行了转账操作，当你发现上当受骗时，钱已经被转走了。 而这种构建恶意页面，引导用户访问对应网站执行操作的方式称为：跨站请求伪造（CSRF，Cross Site Request Forgery） SFA会话固定攻击利用Cookie中的JSESSIONID进行攻击，是一种针对Web应用程序的安全漏洞攻击，攻击者利用此漏洞，将有效的会话ID分配给用户，诱使用户在该会话中进行操作，攻击者可以利用会话ID获取用户的权限，或者以此进行其他攻击 攻击者通常使用以下几种方式进行会话固定攻击： 会话传递：用户通过URL参数，表单隐藏字段、cookie等方式将会话ID传递给用户 会话劫持：攻击者利用劫持用户与服务器之间的通信流量获取用户会话ID，利用此冒充登录 会话劫持：事先获取会话ID，将其分配给用户之后通过其他方式欺骗用户登录该会话，这样攻击者可以利用会话ID获取用户权限 流程 攻击者Attacker以一个合法的用户身份登录www.website.com。 服务器与攻击者Attacker建立了一个会话，sessionid为1234567（这里只是一个示例，大家不要在乎sessionid的位数对不对）。应用网站服务器返回一个会话ID给他； 攻击者Attacker用该会话ID构造了一个URL：http://www.website.com/login.jsp?sessionid=1234567，发给了受害者Alice ； 受害者Victim点击该链接,进行了登录; 受害者Victim输入她的合法用户名和密码，正常登录了该网站，会话成功建立（注意，由于此时的sessionid预先已经被Bob设置为1234567了）； 攻击者Attacker用该会话ID成功冒充并劫持了受害者Victim的会话，这时攻击者Attacker如果输入http://www.website.com/viewprofile.jsp?sessionid=1234567，就可以看到受害者Victim的个人信息（profile）了，因此sessionid此时就是代表了Victim； 模仿实现 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;冠希哥全套视频&lt;/title&gt; &lt;script src=&quot;https://unpkg.com/axios@1.1.2/dist/axios.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt; //第三方网站恶意脚本，自动修改Cookie信息 document.cookie = &quot;JSESSIONID=B00DB7C07EAE5343016ACA99B9B42426; path=/mvc; domain=localhost&quot; //然后给你弄到原来的网站 location.href = &#x27;http://localhost:8080/mvc/&#x27;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 因为要使用JSESSIONID，所以先进行获取 之后如若用户登录，则另一端伪界面也会进行登录，这样就能操纵用户内容 当然，现在的浏览器同样有着对应的保护机制，Tomcat发送的SESSIONID默认是勾选了HttpOnly选项的，一旦被设定是无法被随意修改的，当然前提是先得正常访问一次网站才行，否则仍然存在安全隐患。 HttpOnly是Cookie中一个属性，用于防止客户端脚本通过document.cookie属性访问Cookie，有助于保护Cookie不被跨站脚本攻击窃取或篡改。但是，HttpOnly的应用仍存在局限性，一些浏览器可以阻止客户端脚本对Cookie的读操作，但允许写操作；此外大多数浏览器仍允许通过XMLHTTP对象读取HTTP响应中的Set-Cookie头 为了彻底杜绝这个问题，登陆成功之后应该重新分配一个JSESSIONID XSS跨站脚本攻击前两种攻击方式都是从外部干涉，也可以从内部进行干涉 XSS（跨站脚本攻击）是一种常见的网络安全漏洞，攻击者通过在合法网站中注入恶意脚本代码来攻击用户。当用户访问受到注入攻击的页面时，恶意代码会在用户的浏览器中执行，从而导致攻击者能够窃取用户的敏感信息、诱导用户操作、甚至控制用户的账号。 XSS攻击常见的方式有三种： 存储型XSS攻击：攻击者将恶意代码存储到目标网站的数据库中，当其他用户访问包含恶意代码的页面时，恶意代码会被执行。 反射型XSS攻击：攻击者将恶意代码嵌入到URL中，当用户点击包含恶意代码的URL时，恶意代码会被执行。 DOM-based XSS攻击：攻击者利用前端JavaScript代码的漏洞，通过修改页面的DOM结构来执行恶意代码。 在一些社交平台上，用户可以自由发帖，帖子是以富文本形式进行编辑和上传，发送给后台的帖子是直接以HTML形式的 例如下面是一个正常的代码 123456&lt;div class=&quot;content ql-editor&quot;&gt; &lt;p&gt; &lt;strong&gt;萨达睡觉了大数据&lt;/strong&gt; &lt;/p&gt; &lt;p&gt;撒大大撒大声地&lt;/p&gt;&lt;/div&gt; 但也可以进行悄悄植入 123456&lt;div class=&quot;content ql-editor&quot;&gt; &lt;p οnlοad=&quot;alert(&#x27;xss&#x27;)&quot;&gt; &lt;strong&gt;萨达睡觉了大数据&lt;/strong&gt; &lt;/p&gt; &lt;p&gt;撒大大撒大声地&lt;/p&gt;&lt;/div&gt; 可以看到p标签上添加了一段JS恶意脚本，黑客可以利用这种特性，获取用户的各种信息，甚至直接发送到他的后台，这样，我们的个人信息就从网站内部被泄露了。 XSS漏洞最早被发现是在1996年，由于JavaScript的出现，导致在Web应用程序中存在了一些安全问题。在1997年，高智文(Gareth Owen)也就是“XSS之父”，在他的博客中描述了一种称为“脚本注入”(script injection)的攻击技术，这就是XSS漏洞的前身。从那时起，XSS漏洞便成为了Web应用程序中的一种常见安全漏洞。 开发环境搭建我们依然使用之前的模板来搭建图书管理系统项目。 导入以下依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;6.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;6.1.1&lt;/version&gt;&lt;/dependency&gt; 接着我们需要配置SpringSecurity，与Mvc一样，需要一个初始化器： 12345public class SecurityInitializer extends AbstractSecurityWebApplicationInitializer &#123; //不用重写任何内容 //这里实际上会自动注册一个Filter，SpringSecurity底层就是依靠N个过滤器实现的&#125;复制代码 接着我们需要再创建一个配置类用于配置SpringSecurity： 12345@Configuration@EnableWebSecurity //开启WebSecurity相关功能public class SecurityConfiguration &#123; &#125; 接着创建根容器 1234567891011121314151617public class MainInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class[]&#123;WebConfiguration.class, SecurityConfiguration.class&#125;; &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[0]; &#125; @Override protected String[] getServletMappings() &#123; return new String[]&#123;&quot;/&quot;&#125;; &#125;&#125; 之后直接启动服务器，会发现进入一个SpringSecurity自己提供的登录页面 认证认证是网站的第一步，用户需要登录认证之后才能进入网站 直接认证首先要做的就是实现用户验证，要实现用户验证，我们需要进行一些配置： 123456789101112131415161718192021@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; @Bean //UserDetailsService就是获取用户信息的服务 public UserDetailsService userDetailsService() &#123; //每一个UserDetails就代表一个用户信息，其中包含用户的用户名和密码以及角色 UserDetails user = User.withDefaultPasswordEncoder() .username(&quot;user&quot;) .password(&quot;password&quot;) .roles(&quot;USER&quot;) //角色目前我们不需要关心，随便写就行，后面会专门讲解 .build(); UserDetails admin = User.withDefaultPasswordEncoder() .username(&quot;admin&quot;) .password(&quot;password&quot;) .roles(&quot;ADMIN&quot;, &quot;USER&quot;) .build(); return new InMemoryUserDetailsManager(user, admin); //创建一个基于内存的用户信息管理器作为UserDetailsService &#125;&#125; 之前写的Controller也可以进行一些更改 123456789101112131415161718@Controllerpublic class HelloController &#123; //现在所有接口不需要任何验证了，因为Security已经帮我们做了，没登录是根本进不来的 @GetMapping(&quot;/&quot;) public String index()&#123; return &quot;index&quot;; &#125; @ResponseBody @PostMapping(&quot;/pay&quot;) public JSONObject pay(@RequestParam String account)&#123; JSONObject object = new JSONObject(); System.out.println(&quot;转账给&quot;+account+&quot;成功，交易已完成！&quot;); object.put(&quot;success&quot;, true); return object; &#125;&#125; 配置完成之后进行登录就可以访问原界面；同时通过观察，也会发现登录前后JSESSIONID进行变化，从而防止了安全漏洞 但是登录之后进行转账操作会发现一些问题 也就是给了403错误码，这是因为SpringSecurity自带了csrf防护，需求我们在POST请求中携带页面中的csrfToken才可以，否则一律进行拦截操作，这里我们可以将其嵌入到页面中，随便找一个地方添加以下内容： 123456789101112131415161718&lt;input type=&quot;text&quot; th:id=&quot;$&#123;_csrf.getParameterName()&#125;&quot; th:value=&quot;$&#123;_csrf.token&#125;&quot; hidden&gt;...&lt;script&gt; function pay() &#123; const account = document.getElementById(&quot;account&quot;).value const _csrf = document.getElementById(&quot;_csrf&quot;).value axios.post(&#x27;/mvc/pay&#x27;, &#123;account: account, _csrf&#125;, &#123; headers: &#123; &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27; &#125; &#125;).then((&#123;data&#125;) =&gt; &#123; if(data.success) alert(&quot;success&quot;) else alert(&quot;failed&quot;) &#125;) &#125;&lt;/script&gt; 转账成功之后观察负载 对于密码加密，也可以使用提供的密码加密器 1234567891011121314151617181920212223242526@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; //这里将BCryptPasswordEncoder直接注册为Bean，Security会自动进行选择 @Bean public PasswordEncoder passwordEncoder()&#123; return new BCryptPasswordEncoder(); &#125; @Bean public UserDetailsService userDetailsService(PasswordEncoder encoder) &#123; UserDetails user = User .withUsername(&quot;user&quot;) .password(encoder.encode(&quot;password&quot;)) //这里将密码进行加密后存储 .roles(&quot;USER&quot;) .build(); System.out.println(encoder.encode(&quot;password&quot;)); //一会观察一下加密出来之后的密码长啥样 UserDetails admin = User .withUsername(&quot;admin&quot;) .password(encoder.encode(&quot;password&quot;)) //这里将密码进行加密后存储 .roles(&quot;ADMIN&quot;, &quot;USER&quot;) .build(); return new InMemoryUserDetailsManager(user, admin); &#125;&#125; SpringSecurity的密码校验并不是直接使用原文进行比较，而是使用加密算法将密码进行加密（更准确地说应该进行Hash处理，此过程是不可逆的，无法解密），最后将用户提供的密码以同样的方式加密后与密文进行比较。对于我们来说，用户提供的密码属于隐私信息，直接明文存储并不好，而且如果数据库内容被窃取，那么所有用户的密码将全部泄露，这是我们不希望看到的结果，我们需要一种既能隐藏用户密码也能完成认证的机制，而Hash处理就是一种很好的解决方案，通过将用户的密码进行Hash值计算，计算出来的结果无法还原为原文，如果需要验证是否与此密码一致，那么需要以同样的方式加密再比较两个Hash值是否一致，这样就很好的保证了用户密码的安全性。 使用数据库认证先创建一个数据库表 123create table users(username varchar(50) not null primary key,password varchar(500) not null,enabled boolean not null);create table authorities (username varchar(50) not null,authority varchar(50) not null,constraint fk_authorities_users foreign key(username) references users(username));create unique index ix_auth_username on authorities (username,authority); 添加相应的依赖项 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.13&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;version&gt;8.0.32&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;6.0.10&lt;/version&gt;&lt;/dependency&gt; 需要将加密后的密码添加到数据库中作为用户密码： 12345678910111213141516171819202122232425@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; @Bean PasswordEncoder passwordEncoder()&#123; return new BCryptPasswordEncoder(); &#125; @Bean public DataSource dataSource()&#123; //数据源配置 return new PooledDataSource(&quot;com.mysql.cj.jdbc.Driver&quot;, &quot;jdbc:mysql://localhost:3306/test&quot;, &quot;root&quot;, &quot;123456&quot;); &#125; @Bean public UserDetailsService userDetailsService(DataSource dataSource, PasswordEncoder encoder) &#123; JdbcUserDetailsManager manager = new JdbcUserDetailsManager(dataSource); //仅首次启动时创建一个新的用户用于测试，后续无需创建 manager.createUser(User.withUsername(&quot;user&quot;) .password(encoder.encode(&quot;password&quot;)).roles(&quot;USER&quot;).build()); return manager; &#125;&#125; 登录之后会发现表单里面已经存在初始化的用户 身份表 这样，当我们下次需要快速创建一个用户登录的应用程序时，直接使用这种方式就能快速完成了 无论是InMemoryUserDetailsManager还是JdbcUserDetailsManager均实现自UserDetailsManager接口，这个接口中有着一套完整的增删改查操作，方便我们直接对用户进行处理： 1234567891011121314151617public interface UserDetailsManager extends UserDetailsService &#123; //创建一个新的用户 void createUser(UserDetails user); //更新用户信息 void updateUser(UserDetails user); //删除用户 void deleteUser(String username); //修改用户密码 void changePassword(String oldPassword, String newPassword); //判断是否存在指定用户 boolean userExists(String username);&#125; 通过使用UserDetailsManager对象能快速执行用户相关的管理操作，比如我们可以直接在网站上添加一个快速重置密码的接口，首先需要配置一下JdbcUserDetailsManager，为其添加一个AuthenticationManager用于原密码的校验： 123456789101112131415161718192021222324@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; ... //手动创建一个AuthenticationManager用于处理密码校验 private AuthenticationManager authenticationManager(UserDetailsManager manager, PasswordEncoder encoder)&#123; DaoAuthenticationProvider provider = new DaoAuthenticationProvider(); provider.setUserDetailsService(manager); provider.setPasswordEncoder(encoder); return new ProviderManager(provider); &#125; @Bean public UserDetailsManager userDetailsService(DataSource dataSource, PasswordEncoder encoder) throws Exception &#123; JdbcUserDetailsManager manager = new JdbcUserDetailsManager(dataSource); //为UserDetailsManager设置AuthenticationManager即可开启重置密码的时的校验 manager.setAuthenticationManager(authenticationManager(manager, encoder)); return manager; &#125;&#125; 接着编写一个快速重置密码的接口： 123456789@ResponseBody@PostMapping(&quot;/change-password&quot;)public JSONObject changePassword(@RequestParam String oldPassword, @RequestParam String newPassword) &#123; manager.changePassword(oldPassword, encoder.encode(newPassword)); JSONObject object = new JSONObject(); object.put(&quot;success&quot;, true); return object;&#125; 接着我们在主界面中添加一个重置密码的操作： 1234567891011121314151617181920212223242526&lt;div&gt; &lt;label&gt; 修改密码： &lt;input type=&quot;text&quot; id=&quot;oldPassword&quot; placeholder=&quot;旧密码&quot;/&gt; &lt;input type=&quot;text&quot; id=&quot;newPassword&quot; placeholder=&quot;新密码&quot;/&gt; &lt;/label&gt; &lt;button onclick=&quot;change()&quot;&gt;修改密码&lt;/button&gt;&lt;/div&gt;function change() &#123; const oldPassword = document.getElementById(&quot;oldPassword&quot;).value const newPassword = document.getElementById(&quot;newPassword&quot;).value const csrf = document.getElementById(&quot;_csrf&quot;).value axios.post(&#x27;/mvc/change-password&#x27;, &#123; oldPassword: oldPassword, newPassword: newPassword, _csrf: csrf &#125;, &#123; headers: &#123; &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27; &#125; &#125;).then((&#123;data&#125;) =&gt; &#123; alert(data.success ? &quot;密码修改成功&quot; : &quot;密码修改失败，请检查原密码是否正确&quot;) &#125;)&#125; 这样我们就可以在首页进行修改密码操作了： 当然，这种方式的权限校验虽然能够直接使用数据库，但是存在一定的局限性，只适合快速搭建Demo使用，不适合实际生产环境下编写 自定义验证有些时候，我们的数据库可能并不会像SpringSecurity默认的那样进行设计，而是采用自定义的表结构，这种情况下，上面两种方式就很难进行验证了，此时我们得编写自定义验证，来应对各种任意变化的情况。 既然需要自定义，那么我们就需要自行实现UserDetailsService或是功能更完善的UserDetailsManager接口，这里为了简单，我们直接选择前者进行实现： 12345678@Servicepublic class AuthorizeService implements UserDetailsService &#123; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; return null; &#125;&#125; 现在我们需要去实现这个loadUserByUsername方法，表示在验证的时候通过自定义的方式，根据给定的用户名查询用户，并封装为UserDetails对象返回，然后由SpringSecurity将我们返回的对象与用户登录的信息进行核验，基本流程实际上跟之前是一样的，只是现在由我们自己来提供用户查询方式。 现在我们在数据库中创建一个自定义的用户表： 随便插入一点数据 接着我们自行编写对应的查询操作，首先创建一个对应的实体类： 123456@Datapublic class Account &#123; int id; String username; String password;&#125; 然后是根据用户名查询用户的Mapper接口： 1234public interface UserMapper &#123; @Select(&quot;select * from user where username = #&#123;username&#125;&quot;) Account findUserByName(String username);&#125; 最后在配置类上添加相应的包扫描： 12345678910@EnableWebMvc@Configuration@ComponentScans(&#123; @ComponentScan(&quot;com.example.controller&quot;), @ComponentScan(&quot;com.example.service&quot;)&#125;)@MapperScan(&quot;com.example.mapper&quot;)public class WebConfiguration implements WebMvcConfigurer &#123; ...&#125; 然后来到Service这边进行一下完善，从数据库中进行查询： 1234567891011121314151617@Servicepublic class AuthorizeService implements UserDetailsService &#123; @Resource UserMapper mapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; Account account = mapper.findUserByName(username); if(account == null) throw new UsernameNotFoundException(&quot;用户名或密码错误&quot;); return User .withUsername(username) .password(account.getPassword()) .build(); &#125;&#125; 这样，我们就通过自定义的方式实现了数据库信息查询，并完成用户登录操作。 其他配置如果将SpringSecurity作为我们的登录校验框架，并且实现了三种方式的校验，但是光是这样，自由度还远远不够，在实际开发场景中，我们还会面对各种各样的需求，这一部分我们接着来进行更加深层次的配置。 自定义登录界面虽然SpringSecurity为我们提供了一个还行的登录界面，但是很多情况下往往都是我们使用自定义的登录界面，这个时候就需要进行更多的配置了，我们还是以之前图书管理系统使用的模版为例。 下载好模版后，我们将其中的两个页面和资源文件放到类路径下： 之后配置视图编辑器 12345678910@Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;/static/**&quot;) .addResourceLocations(&quot;classpath:/static/&quot;); &#125; @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; configurer.enable(); &#125; 接着我们配置对应页面的Controller控制器： 123456789101112@Controllerpublic class HelloController &#123; @GetMapping(&quot;/&quot;) public String index()&#123; return &quot;index&quot;; &#125; @GetMapping(&quot;/login&quot;) public String login()&#123; return &quot;login&quot;; &#125;&#125; 这样，我们在登录之后，就可以展示前端模版页面了： 不过现在依然是默认进入到SpringSecurity默认的登录界面，现在我们来配置自定义的登录界面，将我们的前端模版中的登录页面作为SpringSecurity的默认登录界面。 12345678910111213141516171819202122232425262728@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; ... //如果你学习过SpringSecurity 5.X版本，可能会发现新版本的配置方式完全不一样 //新版本全部采用lambda形式进行配置，无法再使用之前的and()方法进行连接了 @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception &#123; return http //以下是验证请求拦截和放行配置 .authorizeHttpRequests(auth -&gt; &#123; auth.anyRequest().authenticated(); //将所有请求全部拦截，一律需要验证 &#125;) //以下是表单登录相关配置 .formLogin(conf -&gt; &#123; conf.loginPage(&quot;/login&quot;); //将登录页设置为我们自己的登录页面 conf.loginProcessingUrl(&quot;/doLogin&quot;); //登录表单提交的地址，可以自定义 conf.defaultSuccessUrl(&quot;/&quot;); //登录成功后跳转的页面 conf.permitAll(); //将登录相关的地址放行，否则未登录的用户连登录界面都进不去 //用户名和密码的表单字段名称，不过默认就是这个，可以不配置，除非有特殊需求 conf.usernameParameter(&quot;username&quot;); conf.passwordParameter(&quot;password&quot;); &#125;) .build(); &#125;&#125; 需要配置登陆页面的地址和登陆请求发送的地址，这里登陆页面填写为/login，登陆请求地址为/doLogin，登陆页面我们刚刚已经自己编写Controller来实现了，登陆请求提交处理由SpringSecurity提供，只需要写路径就可以了。现在访问我们的网站，就可以进入到自定义的登录界面了： 但是我们发现，我们的页面只有一个纯文本，这是因为在获取静态资源的时候，所有的静态资源默认情况下也会被拦截，因此全部被302重定向到登录页面，这显然是不对的： 因此，现在我们需要将所有的静态资源也给放行，否则登录界面都没法正常展示： 1234.authorizeHttpRequests(auth -&gt; &#123; auth.requestMatchers(&quot;/static/**&quot;).permitAll(); //将所有的静态资源放行，一定要添加在全部请求拦截之前 auth.anyRequest().authenticated(); //将所有请求全部拦截，一律需要验证&#125;) 再次访问我们的网站，就可以看到正常显示的登录界面了： 因此，如果各位小伙伴后续在编写项目过程中发现有302的情况，一定要先检查是否因为没有放行导致被SpringSecurity给拦截了，别再遇到302一脸懵逼了。 接着我们来配置登录操作，这里我们只需要配置一下登录的地址和登录按钮即可，当然，跟之前一样，要把CSRF的输入框也加上： 123456789101112&lt;form action=&quot;doLogin&quot; method=&quot;post&quot;&gt; ... &lt;input type=&quot;text&quot; name=&quot;username&quot; placeholder=&quot;Email Address&quot; class=&quot;ad-input&quot;&gt; ... &lt;input type=&quot;password&quot; name=&quot;password&quot; placeholder=&quot;Password&quot; class=&quot;ad-input&quot;&gt; ... &lt;input type=&quot;text&quot; th:name=&quot;$&#123;_csrf.getParameterName()&#125;&quot; th:value=&quot;$&#123;_csrf.token&#125;&quot; hidden&gt; &lt;div class=&quot;ad-auth-btn&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;ad-btn ad-login-member&quot;&gt;Login&lt;/button&gt; &lt;/div&gt; ...&lt;/form&gt; 接着我们就可以尝试进行登录操作了： 可以看到，现在我们可以成功地登录到主页了。 退出登录也是同样的操作，我们只需要稍微进行一下配置就可以实现，我们首先继续完善配置类： 12345678910111213141516171819@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; ... @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception &#123; return http ... //以下是退出登录相关配置 .logout(conf -&gt; &#123; conf.logoutUrl(&quot;/doLogout&quot;); //退出登录地址，跟上面一样可自定义 conf.logoutSuccessUrl(&quot;/login&quot;); //退出登录成功后跳转的地址，这里设置为登录界面 conf.permitAll(); &#125;) .build(); &#125;&#125; 接着我们来稍微魔改一下页面中的退出登录按钮： 12345678&lt;li&gt; &lt;form action=&quot;doLogout&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; th:name=&quot;$&#123;_csrf.getParameterName()&#125;&quot; th:value=&quot;$&#123;_csrf.token&#125;&quot; hidden&gt; &lt;button type=&quot;submit&quot;&gt; &lt;i class=&quot;fas fa-sign-out-alt&quot;&gt;&lt;/i&gt; logout &lt;/button&gt; &lt;/form&gt;&lt;/li&gt; 现在我们点击右上角的退出按钮就可以退出了： 不过，可能会有小伙伴觉得，我们现在无论提交什么请求都需要Csrf校验，有些太麻烦了，实际上现在浏览器已经很安全了，没必要防御到这种程度，我们也可以直接在配置中关闭csrf校验： 123456789101112131415161718@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; ... @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception &#123; return http ... //以下是csrf相关配置 .csrf(conf -&gt; &#123; conf.disable(); //此方法可以直接关闭全部的csrf校验，一步到位，或者用这种写法.csrf(AbstractHttpConfigurer::disable) conf.ignoringRequestMatchers(&quot;/xxx/**&quot;); //此方法可以根据情况忽略某些地址的csrf校验 &#125;) .build(); &#125;&#125; 这就不需要再往页面中嵌入CSRF相关的输入框了，发送请求时也不会进行校验，至此，我们就完成了简单的自定义登录界面配置 注意：一定要删除相关的框，否则可能会出现一些很诡异的事情 记住我功能网站还有一个重要的功能，就是记住我，也就是说我们可以在登陆之后的一段时间内，无需再次输入账号和密码进行登陆，相当于服务端已经记住当前用户，再次访问时就可以免登陆进入，这是一个非常常用的功能。 我们之前在JavaWeb阶段，使用本地Cookie存储的方式实现了记住我功能，但是这种方式并不安全，同时在代码编写上也比较麻烦，那么能否有一种更加高效的记住我功能实现呢？ SpringSecurity为我们提供了一种优秀的实现，它为每个已经登陆的浏览器分配一个携带Token的Cookie，并且此Cookie默认会被保留14天，只要我们不清理浏览器的Cookie，那么下次携带此Cookie访问服务器将无需登陆，直接继续使用之前登陆的身份，这样显然比我们之前的写法更加简便。并且我们需要进行简单配置，即可开启记住我功能： 123456789101112131415161718@Configuration@EnableWebSecuritypublic class SecurityConfiguration &#123; ... @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception &#123; return http ... .rememberMe(conf -&gt; &#123; conf.alwaysRemember(false); //这里不要开启始终记住，我们需要配置为用户自行勾选 conf.rememberMeParameter(&quot;remember-me&quot;); //记住我表单字段，默认就是这个，可以不配置 conf.rememberMeCookieName(&quot;xxxx&quot;); //记住我设置的Cookie名字，也可以自定义，不过没必要 &#125;) .build(); &#125;&#125; 配置完成后，我们需要修改一下前端页面中的表单，将记住我勾选框也作为表单的一部分进行提交： 123456&lt;div class=&quot;ad-checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; name=&quot;remember-me&quot; class=&quot;ad-checkbox&quot;&gt; &lt;span&gt;Remember Me&lt;/span&gt; &lt;/label&gt;&lt;/div&gt; 接着我们来尝试勾选记住我选项进行登录： 此时提交的表单中就已经包含记住我字段了，我们会发现，服务端返回给我们了一个记住我专属的Cookie信息 这个Cookie信息的过期时间并不是仅会话，而是默认保存一段时间，因此，我们关闭浏览器后下次再次访问网站时，就不需要我们再次进行登录操作了，而是直接继续上一次的登录状态。 当然，由于记住我信息是存放在内存中的，我们需要保证服务器一直处于运行状态，如果关闭服务器的话，记住我信息会全部丢失，因此，如果我们希望记住我能够一直持久化保存，我们就需要进一步进行配置。我们需要创建一个基于JDBC的TokenRepository实现： 12345678@Beanpublic PersistentTokenRepository tokenRepository(DataSource dataSource)&#123; JdbcTokenRepositoryImpl repository = new JdbcTokenRepositoryImpl(); //在启动时自动在数据库中创建存储记住我信息的表，仅第一次需要，后续不需要 repository.setCreateTableOnStartup(true); repository.setDataSource(dataSource); return repository;&#125; 然后添加此仓库： 12345.rememberMe(conf -&gt; &#123; conf.rememberMeParameter(&quot;remember-me&quot;); conf.tokenRepository(repository); //设置刚刚的记住我持久化存储库 conf.tokenValiditySeconds(3600 * 7); //设置记住我有效时间为7天&#125;) 这样就成功配置了数据库持久化存储记住我信息，即使重启服务器也不会导致数据丢失。当我们登录之后，数据库中会自动记录相关的信息： 这样，我们网站的登录系统就更加完善了。 授权实现方法级别的安全Web请求层面考虑安全问题很容易，但这一层面不一定是进行安全限制的最佳场所。有时候，最好在执行受保护的操作时再去校验一下用户是否通过了验证并被授予了足够的权限。 比如说当多个控制器调用同个方法时，就需要添加更多的匹配器来保护其他控制器的请求，作为替代方案，可以直接在方法上启用安全防护： 1234@PreAuthorize(&quot;hasRole(&#x27;ADMIN&#x27;)&quot;)public void deleteAllOrders() &#123; orderRepository.deleteAll();&#125; @PreAuthorize注解会接受一个SpEL表达式，如果表达式的计算结果为false，这个方法将不会被调用；如果表达式的计算结果为true，方法就允许调用。在本例中，@PreAuthorize会检查用户是否具有ROLE_ADMIN的权限：如果具有，方法将会被调用，所有的订单会被删除；否则，它会将调用中止 如果@PreAuthorize阻止调用，那么Spring Security将会抛出AccessDeniedException。这是一个非检查型异常，所以我们不需要捕获它，除非想要在异常处理中添加一些自定义的行为。如果我们不捕获它，它将会往上传递，最终被Spring Security的过滤器捕获并进行相应的处理——要么返回HTTP 403页面，要么在用户没有认证的情况返回HTTP 403页面，要么在用户没有认证的情况下重定向到登录页面 要使@PreAuthorize发挥作用，需要启用全局的方法安全功能。为了实现这一点，需要使用@EnableGlobalMethodSecurity注解标注安全配置类，如下所示： 12345@Configuration@EnableGlobalMethodSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; ...&#125; @PostAuthorize注解 它用在方法调用之后，通常来讲用处不是特别大。@PostAuthorize注解的运行机制和@PreAuthorize注解基本相同，只不过它的表达式是在目标方法调用完成并返回之后执行的。这样一来，在决定是否允许方法调用的时候，就能让表达式使用方法的返回值了 假设我们有一个能够根据ID来获取订单的方法。我们如果想限制这个方法，使其只能被管理员或订单所属的用户使用，就可以像这样使用@PostAuthorize注解： 12345@PostAuthorize(&quot;hasRole(&#x27;ADMIN&#x27;) || &quot; + &quot;returnObject.user.username == authentication.name&quot;)public TacoOrder getOrder(long id) &#123; ...&#125; 如果判定安全的条件依赖于方法调用的返回值，那么该如何保证方法不被调用呢？我们可以先允许方法调用，并在表达式返回值为false时抛出一个AccessDeniedException，从而解决这个难题。 用户登录后，可能会根据用户当前是身份进行角色划分，比如我们最常用的QQ，一个QQ群里面，有群主、管理员和普通群成员三种角色，其中群主具有最高权限，群主可以管理整个群的任何板块，并且具有解散和升级群的资格，而管理员只有群主的一部分权限，只能用于日常管理，普通群成员则只能进行最基本的聊天操作。 对于我们来说，用户的一个操作实际上就是在访问我们提供的接口(编写的对应访问路径的Servlet），比如登陆，就需要调用/login接口，退出登陆就要调用&#x2F;logout接口，而我们之前的图书管理系统中，新增图书、删除图书，所有的操作都有着对应的Servlet来进行处理。因此，从我们开发者的角度来说，决定用户能否使用某个功能，只需要决定用户是否能够访问对应的Servlet即可。 我们可以大致像下面这样进行划分： 群主：/login、/logout、/chat、/edit、/delete、/upgrade 管理员：/login、/logout、/chat、/edit 普通群成员：/login、/logout、/chat 也就是说，我们需要做的就是指定哪些请求可以由哪些用户发起。 SpringSecurity为我们提供了两种授权方式： 基于权限的授权：只要拥有某权限的用户，就可以访问某个路径。 基于角色的授权：根据用户属于哪个角色来决定是否可以访问某个路径。 两者只是概念上的不同，实际上使用起来效果差不多。这里我们就先演示以角色方式来进行授权。 基于角色授权现在希望创建两个角色，普通用户和管理员，普通用户只能访问index页面，而管理员可以访问任何页面。 首先我们需要对数据库中的角色表进行一些修改，添加一个用户角色字段，并创建一个新的用户，Test用户的角色为user，而Admin用户的角色为admin。 接着我们需要配置SpringSecurity，决定哪些角色可以访问哪些页面： 12345678.authorizeHttpRequests(auth -&gt; &#123; //静态资源依然全部可以访问 auth.requestMatchers(&quot;/static/**&quot;).permitAll(); //只有具有以下角色的用户才能访问路径&quot;/&quot; auth.requestMatchers(&quot;/&quot;).hasAnyRole(&quot;user&quot;, &quot;admin&quot;); //其他所有路径必须角色为admin才能访问 auth.anyRequest().hasRole(&quot;admin&quot;);&#125;) 接着我们需要稍微修改一下验证逻辑，我们在数据库中的用户表上添加一个新的字段，用于表示角色： 修改一下对应的实体类： 1234567@Datapublic class Account &#123; int id; String username; String password; String role;&#125; 现在我们在查询用户时，需要添加其对应的角色： 1234567891011 @Overridepublic UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; Account account = mapper.findUserByName(username); if(account == null) throw new UsernameNotFoundException(&quot;用户名或密码错误&quot;); return User .withUsername(username) .password(account.getPassword()) .roles(account.getRole()) //添加角色，一个用户可以有一个或多个角色 .build();&#125; 同时为了方便起见，我们新增一个页面 12345@ResponseBody @GetMapping(&quot;/haha&quot;) public String haha() &#123; return &quot;alright, u r a boss &quot;; &#125; 目前依然是可以正常登录的，但是我们随便访问一个其他的页面，就会被拦截并自动退回到登录界面： 这是因为我们前面配置的是user角色，那么这个角色只能访问首页，其他的都不行，所以就会被自动拦截掉了。现在我们可以到数据库中对这个用户的角色进行修改，看看修改后是否能够访问到其他页面： 通过使用角色控制页面的访问，我们就可以让某些用户只能访问部分页面。 基于权限授权基于权限的授权与角色类似，需要以hasAnyAuthority或hasAuthority进行判断： 123456.authorizeHttpRequests(auth -&gt; &#123; //静态资源依然全部可以访问 auth.requestMatchers(&quot;/static/**&quot;).permitAll(); //基于权限和基于角色其实差别并不大，使用方式是相同的 auth.anyRequest().hasAnyAuthority(&quot;page:index&quot;);&#125;) 实际上权限跟角色相比只是粒度更细 使用注解权限判断除了直接配置以外，我们还可以以注解形式直接配置，首先需要在配置类（注意这里是在Mvc的配置类上添加，因为这里只针对Controller进行过滤，所有的Controller是由Mvc配置类进行注册的，如果需要为Service或其他Bean也启用权限判断，则需要在Security的配置类上添加）上开启： 123456@Configuration@EnableWebSecurity@EnableMethodSecurity //开启方法安全校验public class SecurityConfiguration &#123; ...&#125; 现在我们就可以在我们想要进行权限校验的方法上添加注解了： 12345678910@Controllerpublic class HelloController &#123; @PreAuthorize(&quot;hasRole(&#x27;user&#x27;)&quot;) //直接使用hasRole方法判断是否包含某个角色 @GetMapping(&quot;/&quot;) public String index()&#123; return &quot;index&quot;; &#125; ...&#125; 通过添加@PreAuthorize注解，在执行之前判断判断权限，如果没有对应的权限或是对应的角色，将无法访问页面。 这里其实是使用的是SpEL表达式，可以直接在这里使用权限判断相关的方法，所有可以进行权限判断的方法在SecurityExpressionRoot类中有定义 同样的还有@PostAuthorize注解，但是它是在方法执行之后再进行拦截： 123456@PostAuthorize(&quot;hasRole(&#x27;user&#x27;)&quot;)@RequestMapping(&quot;/&quot;)public String index()&#123; System.out.println(&quot;执行了&quot;); return &quot;index&quot;;&#125; 除了Controller以外，只要是由Spring管理的Bean都可以使用注解形式来控制权限，可以在任意方法上添加这个注解，只要不具备表达式中指定的访问权限，那么就无法执行方法并且会返回403页面。 12345678@Servicepublic class UserService &#123; @PreAuthorize(&quot;hasAnyRole(&#x27;user&#x27;)&quot;) public void test()&#123; System.out.println(&quot;成功执行&quot;); &#125;&#125; 与具有相同功能的还有@Secured但是它不支持SpEL表达式的权限表示形式，并且需要添加”ROLE_”前缀 还可以使用@PreFilter和@PostFilter对集合类型的参数或返回值进行过滤。 比如： 12345678910111213@PreFilter(&quot;filterObject.equals(&#x27;xxx&#x27;)&quot;) //filterObject代表集合中每个元素，只要满足条件的元素才会留下public void test(List&lt;String&gt; list)&#123; System.out.println(&quot;成功执行&quot;+list);&#125;@RequestMapping(&quot;/&quot;)public String index()&#123; List&lt;String&gt; list = new LinkedList&lt;&gt;(); list.add(&quot;xxx&quot;); list.add(&quot;yyds&quot;); service.test(list); return &quot;index&quot;;&#125; 与@PreFilter类似的@PostFilter这里就不做演示了，它用于处理返回值，使用方法是一样的。 当有多个集合时，需要使用filterTarget进行指定： 1234@PreFilter(value = &quot;filterObject.equals(&#x27;xxx&#x27;)&quot;, filterTarget = &quot;list2&quot;)public void test(List&lt;String&gt; list, List&lt;String&gt; list2)&#123; System.out.println(&quot;成功执行&quot;+list);&#125; SpringSecurity 第三方认证在登录网页时，时常有用其他账号登录的方式，它们能够让用户避免在Web站点特定的登录页上自己输入凭证信息。这样的Web站点提供了一种通过其他网站（如Facebook）登录的方式，用户可能已经在这些其他的网站登录过了 这种类型的认证是基于OAuth2或OpenID Connect(OIDC)的。OAuth2是一个授权规范。OpenID Connect是另一个基于OAuth2的安全规范，用于规范化第三方认证过程中发生的交互 要在Spring应用中使用这种类型的认证，我们需要在构建文件中添加OAuth2客户端的starter依赖，如下所示： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-oauth2-client&lt;/artifactId&gt;&lt;/dependency&gt; 接下来至少要配置一个或多个oauth2或者openID Connect服务器的详细信息，也可以通过一些额外的属性来配置其他客户端 首先有一些通用的属性需要设置，通用格式如下： 123456789spring: security: oauth2: client: registration: &lt;oauth2 or openid provider name&gt;: clientId: &lt;client id&gt; clientSecret: &lt;client secret&gt; scope: &lt;comma-separated list of requested scopes&gt; 比如说使用fb登录： 123456789spring: security: oauth2: client: registration: facebook: clientId: &lt;facebook client id&gt; clientSecret: &lt;facebook client secret&gt; scope: email, public_profile 其中，客户端ID和secret是用来标识我们的应用在Facebook中的凭证。你可以在Facebook的开发者网站新建应用来获取客户端ID和secret。scope属性可以用来指定应用的权限范围 当用户尝试访问需要认证的页面时，就会重定向至认证页面，他们会被要求根据所请求的权限范围对我们的应用程序授权。最后，用户会被重新定向到我们的应用程序，此时他们已经完成了认证 但是，我们如果通过声明SecurityFilterChain bean来自定义安全配置，那么除了其他的安全配置，还需要启用OAuth2登录，如下所示： 12345678910111213141516171819@Beanpublic SecurityFilterChain filterChain(HttpSecurity http) throws Exception &#123; return http .authorizeRequests() .mvcMatchers(&quot;/design&quot;, &quot;/orders&quot;).hasRole(&quot;USER&quot;) .anyRequest().permitAll() .and() .formLogin() .loginPage(&quot;/login&quot;) .and() .oauth2Login() ... .and() .build();&#125; 如果同时需要支持传统的通过用户名和密码登录，可以在配置中指定登录页，如下所示： 123.and() .oauth2Login() .loginPage(&quot;/login&quot;) 应用程序始终都会为用户展示一个它本身提供的登录页，在这里，用户可以像往常一样选择输入用户名和密码进行登录。但是，我们也可以在同一个登录页上提供一个链接，从而允许用户使用Facebook登录。在登录页面的HTML模板中，这样的链接如下所示: 1&lt;a th:href = &quot;/oauth2/authorization/facebook&quot;&gt;Sign in with Facebook&lt;/a&gt; 接下来，如何退出应用，只需在HttpSecurity对象上调用方法： 12.and() .logout() 该配置会建立一个安全过滤器，拦截对“&#x2F;logout”的POST请求。所以，为了提供退出功能，我们只需要为应用的视图添加一个退出表单和按钮，如下所示： 123&lt;form method = &quot;POST&quot; th:action = &quot;@&#123;/logout&#125;&quot;&gt; &lt;input type = &quot;submit&quot; value = &quot;Logout&quot;/&gt;&lt;/form&gt; 用户点击按钮的时候，他们的会话将会被清理，这样他们就退出应用了。默认情况下，用户会被重定向到登录页面，这样他们可以重新登录。但是，如果你想要将他们导航至不同的页面，那么可以调用logoutSuccessUrl()指定退出后的页面，如下所示： 123.and() .logout() .logoutSuccessUrl(&quot;/&quot;) 内部机制探究授权校验流程SpringSecurity本质上是依靠N个Filter实现的，也就是一个完整的过滤链（注意这里是过滤器，不是拦截器） 从AbstractSecurityWebApplicationInitializer开始下手，我们来看看它配置了什么： 12345678910111213141516171819202122232425262728293031//此方法会在启动时被调用public final void onStartup(ServletContext servletContext) &#123; this.beforeSpringSecurityFilterChain(servletContext); if (this.configurationClasses != null) &#123; AnnotationConfigWebApplicationContext rootAppContext = new AnnotationConfigWebApplicationContext(); rootAppContext.register(this.configurationClasses); servletContext.addListener(new ContextLoaderListener(rootAppContext)); &#125; if (this.enableHttpSessionEventPublisher()) &#123; servletContext.addListener(&quot;org.springframework.security.web.session.HttpSessionEventPublisher&quot;); &#125; servletContext.setSessionTrackingModes(this.getSessionTrackingModes()); //重点在这里，这里插入了关键的FilterChain this.insertSpringSecurityFilterChain(servletContext); this.afterSpringSecurityFilterChain(servletContext);&#125;private void insertSpringSecurityFilterChain(ServletContext servletContext) &#123; String filterName = &quot;springSecurityFilterChain&quot;; //创建了一个DelegatingFilterProxy对象，它本质上也是一个Filter，但是是多个Filter的集合 DelegatingFilterProxy springSecurityFilterChain = new DelegatingFilterProxy(filterName); String contextAttribute = this.getWebApplicationContextAttribute(); if (contextAttribute != null) &#123; springSecurityFilterChain.setContextAttribute(contextAttribute); &#125; //通过ServletContext注册DelegatingFilterProxy这个Filter this.registerFilter(servletContext, true, filterName, springSecurityFilterChain);&#125; 我们接着来看看，DelegatingFilterProxy在做什么： 12345678910111213141516171819202122232425262728293031//这个是初始化方法，它由GenericFilterBean（父类）定义，在afterPropertiesSet方法中被调用protected void initFilterBean() throws ServletException &#123; synchronized(this.delegateMonitor) &#123; if (this.delegate == null) &#123; if (this.targetBeanName == null) &#123; this.targetBeanName = this.getFilterName(); &#125; WebApplicationContext wac = this.findWebApplicationContext(); if (wac != null) &#123; //耐心点，套娃很正常 this.delegate = this.initDelegate(wac); &#125; &#125; &#125;&#125;protected Filter initDelegate(WebApplicationContext wac) throws ServletException &#123; String targetBeanName = this.getTargetBeanName(); Assert.state(targetBeanName != null, &quot;No target bean name set&quot;); //这里通过WebApplicationContext获取了一个Bean Filter delegate = (Filter)wac.getBean(targetBeanName, Filter.class); if (this.isTargetFilterLifecycle()) &#123; delegate.init(this.getFilterConfig()); &#125; //返回Filter return delegate;&#125; 这里我们需要添加一个断点来查看到底获取到了什么Bean。 通过断点调试，我们发现这里放回的对象是一个FilterChainProxy类型的，并且调用了它的初始化方法。 当Filter返回之后，DelegatingFilterProxy的一个成员变量delegate被赋值为得到的Filter，也就是FilterChainProxy对象，接着我们来看看，DelegatingFilterProxy是如何执行doFilter方法的。 1234567891011121314public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; Filter delegateToUse = this.delegate; if (delegateToUse == null) &#123; //非正常情况，这里省略... &#125; //这里才是真正的调用，别忘了delegateToUse就是初始化的FilterChainProxy对象 this.invokeDelegate(delegateToUse, request, response, filterChain);&#125;protected void invokeDelegate(Filter delegate, ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; //最后实际上调用的是FilterChainProxy的doFilter方法 delegate.doFilter(request, response, filterChain);&#125; 接着来看，FilterChainProxy的doFilter方法又在干什么： 12345678910public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; boolean clearContext = request.getAttribute(FILTER_APPLIED) == null; if (!clearContext) &#123; //真正的过滤在这里执行 this.doFilterInternal(request, response, chain); &#125; else &#123; //... &#125;&#125; 123456789101112131415161718192021222324252627282930private void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FirewalledRequest firewallRequest = this.firewall.getFirewalledRequest((HttpServletRequest)request); HttpServletResponse firewallResponse = this.firewall.getFirewalledResponse((HttpServletResponse)response); //这里获取了一个Filter列表，实际上SpringSecurity就是由N个过滤器实现的，这里获取的都是SpringSecurity提供的过滤器 //但是请注意，经过我们之前的分析，实际上真正注册的Filter只有DelegatingFilterProxy //而这里的Filter列表中的所有Filter并没有被注册，而是在这里进行内部调用 List&lt;Filter&gt; filters = this.getFilters((HttpServletRequest)firewallRequest); //只要Filter列表不是空，就依次执行内置的Filter if (filters != null &amp;&amp; filters.size() != 0) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(LogMessage.of(() -&gt; &#123; return &quot;Securing &quot; + requestLine(firewallRequest); &#125;)); &#125; //这里创建一个虚拟的过滤链，过滤流程是由SpringSecurity自己实现的 FilterChainProxy.VirtualFilterChain virtualFilterChain = new FilterChainProxy.VirtualFilterChain(firewallRequest, chain, filters); //调用虚拟过滤链的doFilter virtualFilterChain.doFilter(firewallRequest, firewallResponse); &#125; else &#123; if (logger.isTraceEnabled()) &#123; logger.trace(LogMessage.of(() -&gt; &#123; return &quot;No security for &quot; + requestLine(firewallRequest); &#125;)); &#125; firewallRequest.reset(); chain.doFilter(firewallRequest, firewallResponse); &#125;&#125; 我们来看一下虚拟过滤链的doFilter是怎么处理的： 12345678910111213141516171819202122232425262728//看似没有任何循环，实际上就是一个循环，是一个递归调用public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException &#123; //判断是否已经通过全部的内置过滤器，定位是否等于当前大小 if (this.currentPosition == this.size) &#123; if (FilterChainProxy.logger.isDebugEnabled()) &#123; FilterChainProxy.logger.debug(LogMessage.of(() -&gt; &#123; return &quot;Secured &quot; + FilterChainProxy.requestLine(this.firewalledRequest); &#125;)); &#125; this.firewalledRequest.reset(); //所有的内置过滤器已经完成，按照正常流程走DelegatingFilterProxy的下一个Filter //也就是说这里之后就与DelegatingFilterProxy没有任何关系了，该走其他过滤器就走其他地方配置的过滤器，SpringSecurity的过滤操作已经结束 this.originalChain.doFilter(request, response); &#125; else &#123; //定位自增 ++this.currentPosition; //获取当前定位的Filter Filter nextFilter = (Filter)this.additionalFilters.get(this.currentPosition - 1); if (FilterChainProxy.logger.isTraceEnabled()) &#123; FilterChainProxy.logger.trace(LogMessage.format(&quot;Invoking %s (%d/%d)&quot;, nextFilter.getClass().getSimpleName(), this.currentPosition, this.size)); &#125; //执行内部过滤器的doFilter方法，传入当前对象本身作为Filter，执行如果成功，那么一定会再次调用当前对象的doFilter方法 //可能最不理解的就是这里，执行的难道不是内部其他Filter的doFilter方法吗，怎么会让当前对象的doFilter方法递归调用呢？ //没关系，下面我们接着了解了其中一个内部过滤器就明白了 nextFilter.doFilter(request, response, this); &#125;&#125; 因此，我们差不多已经了解了整个SpringSecurity的实现机制了，那么我们来随便看一个内部的过滤器在做什么。 比如用于处理登陆的过滤器UsernamePasswordAuthenticationFilter，它继承自AbstractAuthenticationProcessingFilter，我们来看看它是怎么进行过滤的： 1234567891011121314151617181920212223242526272829303132333435363738public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; this.doFilter((HttpServletRequest)request, (HttpServletResponse)response, chain);&#125;private void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException &#123; //如果不是登陆请求，那么根本不会理这个请求 if (!this.requiresAuthentication(request, response)) &#123; //直接调用传入的FilterChain的doFilter方法 //而这里传入的正好是VirtualFilterChain对象 //这下知道为什么上面说是递归了吧 chain.doFilter(request, response); &#125; else &#123; //如果是登陆请求，那么会执行登陆请求的相关逻辑，注意执行过程中出现任何问题都会抛出异常 //比如用户名和密码错误，我们之前也已经测试过了，会得到一个BadCredentialsException try &#123; //进行认证 Authentication authenticationResult = this.attemptAuthentication(request, response); if (authenticationResult == null) &#123; return; &#125; this.sessionStrategy.onAuthentication(authenticationResult, request, response); if (this.continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; //如果一路绿灯，没有报错，那么验证成功，执行successfulAuthentication this.successfulAuthentication(request, response, chain, authenticationResult); &#125; catch (InternalAuthenticationServiceException var5) &#123; this.logger.error(&quot;An internal error occurred while trying to authenticate the user.&quot;, var5); //验证失败，会执行unsuccessfulAuthentication this.unsuccessfulAuthentication(request, response, var5); &#125; catch (AuthenticationException var6) &#123; this.unsuccessfulAuthentication(request, response, var6); &#125; &#125;&#125; 那么我们来看看successfulAuthentication和unsuccessfulAuthentication分别做了什么： 123456789101112131415161718192021222324252627282930protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; //向SecurityContextHolder添加认证信息，我们可以通过SecurityContextHolder对象获取当前登陆的用户 SecurityContextHolder.getContext().setAuthentication(authResult); if (this.logger.isDebugEnabled()) &#123; this.logger.debug(LogMessage.format(&quot;Set SecurityContextHolder to %s&quot;, authResult)); &#125; //记住我实现 this.rememberMeServices.loginSuccess(request, response, authResult); if (this.eventPublisher != null) &#123; this.eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent(authResult, this.getClass())); &#125; //调用默认的或是我们自己定义的AuthenticationSuccessHandler的onAuthenticationSuccess方法 //这个根据我们配置文件决定 //到这里其实页面就已经直接跳转了 this.successHandler.onAuthenticationSuccess(request, response, authResult);&#125;protected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response, AuthenticationException failed) throws IOException, ServletException &#123; //登陆失败会直接清理掉SecurityContextHolder中的认证信息 SecurityContextHolder.clearContext(); this.logger.trace(&quot;Failed to process authentication request&quot;, failed); this.logger.trace(&quot;Cleared SecurityContextHolder&quot;); this.logger.trace(&quot;Handling authentication failure&quot;); //登陆失败的记住我处理 this.rememberMeServices.loginFail(request, response); //同上，调用默认或是我们自己定义的AuthenticationFailureHandler this.failureHandler.onAuthenticationFailure(request, response, failed);&#125; 了解了整个用户验证实现流程，其实其它的过滤器是如何实现的也就很容易联想到了，SpringSecurity的过滤器从某种意义上来说，更像是一个处理业务的Servlet，它做的事情不像是拦截，更像是完成自己对应的职责，只不过是使用了过滤器机制进行实现罢了，从而将所有的验证提前到进入Controller之前。 最后附上完整的过滤器清单，这里列出14个常见的内部过滤器： 过滤器名称 职责 DisableEncodeUrlFilter 禁止 HttpServletResponse 对 URL 进行编码，以防止在 URL 中包含 Session ID，此类 URL 不被视为 URL，因为会话 ID 可能会在 HTTP 访问日志等内容中泄露。 WebAsyncManagerIntegrationFilter 实现了对SecurityContext与WebAsyncManager的集成，使 Controller 中能够线程安全地获取到用户上下文认证信息。 SecurityContextHolderFilter 通过HttpSessionSecurityContextRepository接口从Session中读取SecurityContext或是直接创建新的，然后存入到SecurityContextHolder中，最后请求结束时会进行清理。 HeaderWriterFilter 给HTTP响应添加一些Header属性，如：X-Frame-Options、X-XSS-Protection、X-Content-Type-Options等。 CsrfFilter 针对Csrf相关校验。 LogoutFilter 对退出登录的请求进行处理，执行登出操作。 UsernamePasswordAuthenticationFilter 对登录的请求进行处理，执行登录操作。 ConcurrentSessionFilter 检查SessionRegistry保存的Session信息是否过期。 RequestCacheAwareFilter 缓存Request请求，可以用于恢复因登录而打断的请求。 SecurityContextHolderAwareRequestFilter 对ServletRequest进行进一步包装，让Request具有更加丰富的内容。 RememberMeAuthenticationFilter 针对于记住我Cookie进行校验。 AnonymousAuthenticationFilter 未验证成功的情况下进行匿名登录操作。 SessionManagementFilter Session管理相关。 ExceptionTranslationFilter 异常转换处理，比如最常见的AccessDenied之类的。 各位小伙伴感兴趣的话可以自行了解。 安全上下文用户登录之后，怎么获取当前已经登录用户的信息呢？通过使用SecurityContextHolder就可以很方便地得到SecurityContext对象了，我们可以直接使用SecurityContext对象来获取当前的认证信息： 123456789@RequestMapping(&quot;/index&quot;) public String index()&#123; SecurityContext context = SecurityContextHolder.getContext(); Authentication authentication = context.getAuthentication(); User user = (User) authentication.getPrincipal(); System.out.println(user.getUsername()); System.out.println(user.getAuthorities()); return &quot;index&quot;; &#125; 通过SecurityContext我们就可以快速获取当前用户的名称和授权信息等： 除了这种方式以外，我们还可以直接从Session中获取： 12345678@RequestMapping(&quot;/index&quot;)public String index(@SessionAttribute(&quot;SPRING_SECURITY_CONTEXT&quot;) SecurityContext context)&#123; Authentication authentication = context.getAuthentication(); User user = (User) authentication.getPrincipal(); System.out.println(user.getUsername()); System.out.println(user.getAuthorities()); return &quot;index&quot;;&#125; 注意SecurityContextHolder是有一定的存储策略的，SecurityContextHolder中的SecurityContext对象会在一开始请求到来时被设定，至于存储方式其实是由存储策略决定的，如果我们这样编写，那么在默认情况下是无法获取到认证信息的： 1234567891011@RequestMapping(&quot;/index&quot;)public String index()&#123; new Thread(() -&gt; &#123; //创建一个子线程去获取 SecurityContext context = SecurityContextHolder.getContext(); Authentication authentication = context.getAuthentication(); User user = (User) authentication.getPrincipal(); //NPE System.out.println(user.getUsername()); System.out.println(user.getAuthorities()); &#125;).start(); return &quot;index&quot;;&#125; 这是因为SecurityContextHolder的存储策略默认是MODE_THREADLOCAL，它是基于ThreadLocal实现的，getContext()方法本质上调用的是对应的存储策略实现的方法： 123public static SecurityContext getContext() &#123; return strategy.getContext();&#125; SecurityContextHolderStrategy有三个实现类： GlobalSecurityContextHolderStrategy：全局模式，不常用 ThreadLocalSecurityContextHolderStrategy：基于ThreadLocal实现，线程内可见 InheritableThreadLocalSecurityContextHolderStrategy：基于InheritableThreadLocal实现，线程和子线程可见 因此，如果上述情况需要在子线程中获取，那么需要修改SecurityContextHolder的存储策略，在初始化的时候设置： 1234@PostConstructpublic void init()&#123; SecurityContextHolder.setStrategyName(SecurityContextHolder.MODE_INHERITABLETHREADLOCAL);&#125; 这样在子线程中也可以获取认证信息了。 因为用户的验证信息是基于SecurityContext进行判断的，我们可以直接修改SecurityContext的内容，来手动为用户进行登陆： 123456789@RequestMapping(&quot;/auth&quot;)@ResponseBodypublic String auth()&#123; SecurityContext context = SecurityContextHolder.getContext(); //获取SecurityContext对象（当前会话肯定是没有登陆的） UsernamePasswordAuthenticationToken token = new UsernamePasswordAuthenticationToken(&quot;Test&quot;, null, AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;ROLE_user&quot;)); //手动创建一个UsernamePasswordAuthenticationToken对象，也就是用户的认证信息，角色需要添加ROLE_前缀，权限直接写 context.setAuthentication(token); //手动为SecurityContext设定认证信息 return &quot;Login success！&quot;;&#125; 在未登陆的情况下，访问此地址将直接进行手动登陆，再次访问/index页面，可以直接访问，说明手动设置认证信息成功。 疑惑：SecurityContext这玩意不是默认线程独占吗，那每次请求都是一个新的线程，按理说上一次的SecurityContext对象应该没了才对啊，为什么再次请求依然能够继续使用上一次SecurityContext中的认证信息呢？ SecurityContext的生命周期：请求到来时从Session中取出，放入SecurityContextHolder中，请求结束时从SecurityContextHolder取出，并放到Session中，实际上就是依靠Session来存储的，一旦会话过期验证信息也跟着消失。 下一节我们将详细讨论它的实现过程。 安全上下文持久化过滤器SecurityContextHolderFilter也是内置的Filter，它就是专门用于处理SecurityContext的，这里先说一下大致流程，以便我们后续更加方便地理解： 当过滤器链执行到SecurityContextHolderFilter时，它会从HttpSession中把SecurityContext对象取出来（是存在Session中的，跟随会话的消失而消失），然后放入SecurityContextHolder对象中。请求结束后，再把SecurityContext存入HttpSession中，并清除SecurityContextHolder内的SecurityContext对象。 我们还是直接进入到源码中： 12345678910111213141516171819@Overridepublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123;//开始套娃 doFilter((HttpServletRequest) request, (HttpServletResponse) response, chain);&#125;private void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException &#123;//防止重复的安全请求，不需要关心，一般是直接走下面 if (request.getAttribute(FILTER_APPLIED) != null) &#123; chain.doFilter(request, response); return; &#125; request.setAttribute(FILTER_APPLIED, Boolean.TRUE);//这里通过SecurityContextRepository的loadDeferredContext获取到SecurityContext对象的Supplier Supplier&lt;SecurityContext&gt; deferredContext = this.securityContextRepository.loadDeferredContext(request); ...&#125; 我们接着来看loadDeferredContext的实现细节，其中SecurityContextRepository的实现类是DelegatingSecurityContextRepository类，这个类中维护了多个SecurityContextRepository实现类，而其本身并没有实现loadDeferredContext方法，而是靠内部维护的其他SecurityContextRepository实现类来完成： 12345678910111213141516171819@Overridepublic DeferredSecurityContext loadDeferredContext(HttpServletRequest request) &#123;//DeferredSecurityContext是一个支持延时生成的SecurityContext，本质是一个SecurityContext的Supplier DeferredSecurityContext deferredSecurityContext = null;//遍历内部维护的其他SecurityContextRepository实现，一般包含以下两个：//1. HttpSessionSecurityContextRepository//2. RequestAttributeSecurityContextRepository for (SecurityContextRepository delegate : this.delegates) &#123; //这个if-else语句其实为了添加多个SecurityContextRepository提供的SecurityContext并将其组成一个链状结构的DelegatingDeferredSecurityContext（至于为什么，我们接着往下看） if (deferredSecurityContext == null) &#123; deferredSecurityContext = delegate.loadDeferredContext(request); &#125; else &#123; DeferredSecurityContext next = delegate.loadDeferredContext(request); deferredSecurityContext = new DelegatingDeferredSecurityContext(deferredSecurityContext, next); &#125; &#125; return deferredSecurityContext;&#125; 首先我们来看第一个HttpSessionSecurityContextRepository，它是第一个被遍历的实现： 123456789101112131415161718@Overridepublic DeferredSecurityContext loadDeferredContext(HttpServletRequest request) &#123; Supplier&lt;SecurityContext&gt; supplier = () -&gt; readSecurityContextFromSession(request.getSession(false)); //从Session中取出SecurityContext return new SupplierDeferredSecurityContext(supplier, this.securityContextHolderStrategy);&#125;public static final String SPRING_SECURITY_CONTEXT_KEY = &quot;SPRING_SECURITY_CONTEXT&quot;;private String springSecurityContextKey = SPRING_SECURITY_CONTEXT_KEY;private SecurityContext readSecurityContextFromSession(HttpSession httpSession) &#123; ...//实际上这里就是从Session中通过键“SPRING_SECURITY_CONTEXT”取出的SecurityContext//跟我们上一节使用的是完全一样的，这下就很清晰了//如果用户没有登录验证，那么这里获取到的SecurityContext就是null了 Object contextFromSession = httpSession.getAttribute(this.springSecurityContextKey); ... return (SecurityContext) contextFromSession;&#125; 最后返回回去的是一个SupplierDeferredSecurityContext对象： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final class SupplierDeferredSecurityContext implements DeferredSecurityContext &#123; private static final Log logger = LogFactory.getLog(SupplierDeferredSecurityContext.class); private final Supplier&lt;SecurityContext&gt; supplier; private final SecurityContextHolderStrategy strategy; private SecurityContext securityContext; private boolean missingContext; SupplierDeferredSecurityContext(Supplier&lt;SecurityContext&gt; supplier, SecurityContextHolderStrategy strategy) &#123; this.supplier = supplier; this.strategy = strategy; &#125; @Override public SecurityContext get() &#123; //在获取SecurityContext时会进行一次初始化 init(); return this.securityContext; &#125; @Override public boolean isGenerated() &#123; init(); //初始化后判断是否为未登录的SecurityContext return this.missingContext; &#125; private void init() &#123; //如果securityContext不为null表示已经初始化过了 if (this.securityContext != null) &#123; return; &#125; //直接通过supplier获取securityContext对象 this.securityContext = this.supplier.get(); //如果securityContext对象为null，那么就标记missingContext this.missingContext = (this.securityContext == null); if (this.missingContext) &#123; //当missingContext为真时，说明没有securityContext（一般是未登录的情况） //那么就创建一个空的securityContext，不包含任何认证信息 this.securityContext = this.strategy.createEmptyContext(); //日志无视就好 if (logger.isTraceEnabled()) &#123; logger.trace(LogMessage.format(&quot;Created %s&quot;, this.securityContext)); &#125; &#125; &#125;&#125; 接着是第二个被遍历的实现RequestAttributeSecurityContextRepository类： 123456789101112@Overridepublic DeferredSecurityContext loadDeferredContext(HttpServletRequest request) &#123; Supplier&lt;SecurityContext&gt; supplier = () -&gt; getContext(request);//同样是返回SupplierDeferredSecurityContext对象 return new SupplierDeferredSecurityContext(supplier, this.securityContextHolderStrategy);&#125;private SecurityContext getContext(HttpServletRequest request) &#123;//通过HttpServletRequest的Attribute获取SecurityContext//由于一般情况下没有设定过，因此得到的就是null return (SecurityContext) request.getAttribute(this.requestAttributeName);&#125; 最后，两个SecurityContext就会以链式存放在DelegatingDeferredSecurityContext对象中，一并返回了，它的内部长这样： 12345678910111213141516171819202122232425262728static final class DelegatingDeferredSecurityContext implements DeferredSecurityContext &#123; private final DeferredSecurityContext previous; private final DeferredSecurityContext next; DelegatingDeferredSecurityContext(DeferredSecurityContext previous, DeferredSecurityContext next) &#123; this.previous = previous; this.next = next; &#125; @Override public SecurityContext get() &#123; //在获取SecurityContext时，会首先从最前面的开始获取 SecurityContext securityContext = this.previous.get(); //如果最前面的SecurityContext是已登录的，那么直接返回这个SecurityContext if (!this.previous.isGenerated()) &#123; return securityContext; &#125; //否则继续看后面的，也许后面的会有已登录的（实在没有就直接返回一个空的SecurityContext了） return this.next.get(); &#125; @Override public boolean isGenerated() &#123; return this.previous.isGenerated() &amp;&amp; this.next.isGenerated(); &#125;&#125; 兜了这么大一圈，现在回到一开始的Filter中： 1234567891011121314151617private void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException &#123; ...Supplier&lt;SecurityContext&gt; deferredContext = this.securityContextRepository.loadDeferredContext(request);//拿到最终的SecurityContext的Supplier后，继续下面的语句 try &#123; //向securityContextHolderStrategy中设置我们上面得到的DeferredSecurityContext this.securityContextHolderStrategy.setDeferredContext(deferredContext); //请求前的任务已完成，继续其他过滤器了 chain.doFilter(request, response); &#125; finally &#123; //请求结束后，清理掉securityContextHolderStrategy中的DeferredSecurityContext this.securityContextHolderStrategy.clearContext(); request.removeAttribute(FILTER_APPLIED); &#125;&#125; 最后我们再来看一下我们之前通过SecurityContextHolder是如何获取到SecurityContext的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class SecurityContextHolder &#123; ... private static String strategyName = System.getProperty(SYSTEM_PROPERTY); private static SecurityContextHolderStrategy strategy; private static int initializeCount = 0; static &#123; //类加载时会进行一次初始化 initialize(); &#125; private static void initialize() &#123; //初始化会将对应的SecurityContextHolderStrategy对象给创建 initializeStrategy(); initializeCount++; &#125; //初始化SecurityContextHolderStrategy对象 private static void initializeStrategy() &#123; ... // 尝试加载系统配置中设定的Strategy实现类，默认是MODE_THREADLOCAL try &#123; Class&lt;?&gt; clazz = Class.forName(strategyName); Constructor&lt;?&gt; customStrategy = clazz.getConstructor(); // 这里直接根据配置中的类名，用反射怒艹一个对象出来 strategy = (SecurityContextHolderStrategy) customStrategy.newInstance(); &#125; catch (Exception ex) &#123; ReflectionUtils.handleReflectionException(ex); &#125; &#125; //清除Context中的内容，实际上就是清理SecurityContextHolderStrategy中的内容 public static void clearContext() &#123; strategy.clearContext(); &#125; //获取SecurityContext对象 public static SecurityContext getContext() &#123; //获取SecurityContext实际上也是通过SecurityContextHolderStrategy根据策略来获取 return strategy.getContext(); &#125; ...&#125; 我们发现，实际上SecurityContextHolder获取SecurityContext对象，就是通过SecurityContextHolderStrategy根据策略来获取，我们直接来看SecurityContextHolderStrategy的实现类： 1234567891011121314151617181920212223242526272829303132final class ThreadLocalSecurityContextHolderStrategy implements SecurityContextHolderStrategy &#123; //内部维护一个ThreadLocal对象，按线程存储对应的DeferredSecurityContext private static final ThreadLocal&lt;Supplier&lt;SecurityContext&gt;&gt; contextHolder = new ThreadLocal&lt;&gt;(); @Override public void clearContext() &#123; //清理实际上是直接清理掉ThreadLocal中存的对象 contextHolder.remove(); &#125; @Override public SecurityContext getContext() &#123; //获取也很简单，直接通过Supplier拿到需要的SecurityContext对象 return getDeferredContext().get(); &#125; @Override public Supplier&lt;SecurityContext&gt; getDeferredContext() &#123; Supplier&lt;SecurityContext&gt; result = contextHolder.get(); //如果存储的DeferredSecurityContext为null，这里临时创建一个空的SecurityContext并保存 if (result == null) &#123; SecurityContext context = createEmptyContext(); result = () -&gt; context; contextHolder.set(result); &#125; return result; &#125; ...&#125; 这样，整个流程其实就很清楚了，项目启动时，SecurityContextHolder会自动根据配置创建对应的SecurityContextHolderStrategy对象。当我们的请求到来之后，首先会经过SecurityContextHolderFilter，然后在这个阶段，通过SecurityContextRepository来将不同地方存储（一般是Session中存储）的SecurityContext对象取出并封装为DefferdSecurityContext，然后将其添加到一开始创建好的SecurityContextHolderStrategy对象中，这样，我们的Controller在处理时就能直接从SecurityContextHolder取出SecurityContext对象了，最后在处理结束返回响应时，SecurityContextHolderFilter也会将SecurityContextHolderStrategy存储的DefferdSecurityContext清除掉，至此，一个完整流程结束。","tags":["SpringSecurity"],"categories":["Java","SpringSecurity"]},{"title":"SpringBoot数据交互","path":"/Java/SpringBoot/SpringBoot2/","content":"深入SpringBoot数据交互前面我们了解了SpringBoot以及一些常用的框架整合，相信各位小伙伴已经体验到SpringBoot带来的超便捷开发体验了。本章我们将深入讲解SpringBoot的数据交互，使用更多方便好用的持久层框架。 JDBC交互框架除了我们前面一直认识的Mybatis之外，实际上Spring官方也提供了一个非常方便的JDBC操作工具，它同样可以快速进行增删改查。首先我们还是通过starter将依赖导入： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 导入完成之后就可以轻松使用了。 JDBC模版类Spring JDBC为我们提供了一个非常方便的JdbcTemplate类，它封装了常用的JDBC操作，我们可以快速使用这些方法来实现增删改查，这里我们还是配置一下MySQL数据源信息： 1234&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt;&lt;/dependency&gt; 123456spring: datasource: url: jdbc:mysql://localhost:3306/test username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver 我们要操作数据库，最简单直接的方法就是使用JdbcTemplate来完成： 12@ResourceJdbcTemplate template; 它给我们封装了很多方法使用，比如我们要查询数据库中的一条记录： 我们可以使用queryForMap快速以Map为结果的形式查询一行数据： 12345@Testvoid contextLoads() &#123; Map&lt;String, Object&gt; map = template.queryForMap(&quot;select * from user where id = ?&quot;, 1); System.out.println(map);&#125; 非常方便： 我们也可以编写自定义的Mapper用于直接得到查询结果： 12345678@Data@AllArgsConstructorpublic class User &#123; int id; String name; String email; String password;&#125; 123456@Testvoid contextLoads() &#123; User user = template.queryForObject(&quot;select * from user where id = ?&quot;, (r, i) -&gt; new User(r.getInt(1), r.getString(2), r.getString(3), r.getString(4)), 1); System.out.println(user);&#125; 当然除了这些之外，它还提供了update方法适用于各种情况的查询、更新、删除操作： 12345 @Testvoid contextLoads() &#123; int update = template.update(&quot;insert into user values(2, &#x27;admin&#x27;, &#x27;654321@qq.com&#x27;, &#x27;123456&#x27;)&quot;); System.out.println(&quot;更新了 &quot;+update+&quot; 行&quot;);&#125; 这样，如果是那种非常小型的项目，甚至是测试用例的话，都可以快速使用JdbcTemplate快速进行各种操作。 JDBC简单封装对于一些插入操作，Spring JDBC为我们提供了更方便的SimpleJdbcInsert工具，它可以实现更多高级的插入功能，比如我们的表主键采用的是自增ID，那么它支持插入后返回自动生成的ID，这就非常方便了： 1234567891011121314151617181920@Configurationpublic class WebConfiguration &#123; @Resource DataSource source; @Test void contextLoads() &#123; //这个类需要自己创建对象 SimpleJdbcInsert simple = new SimpleJdbcInsert(source) .withTableName(&quot;user&quot;) //设置要操作的表名称 .usingGeneratedKeyColumns(&quot;id&quot;); //设置自增主键列 Map&lt;String, Object&gt; user = new HashMap&lt;&gt;(2); //插入操作需要传入一个Map作为数据 user.put(&quot;name&quot;, &quot;bob&quot;); user.put(&quot;email&quot;, &quot;112233@qq.com&quot;); user.put(&quot;password&quot;, &quot;123456&quot;); Number number = simple.executeAndReturnKey(user); //最后得到的Numver就是得到的自增主键 System.out.println(number); &#125;&#125; 这样就可以快速进行插入操作并且返回自增主键了，还是挺方便的。 当然，虽然SpringJDBC给我们提供了这些小工具，但是其实只适用于简单小项目，稍微复杂一点就不太适合了，下一部分我们将介绍JPA框架。 JPA框架 用了Mybatis之后，你看那个JDBC，真是太逊了。 这么说，你的项目很勇哦？ 开玩笑，我的写代码超勇的好不好。 阿伟，你可曾幻想过有一天你的项目里不再有SQL语句？ 不再有SQL语句？那我怎么和数据库交互啊？ 我看你是完全不懂哦 懂，懂什么啊？ 你想懂？来，到我项目里来，我给你看点好康的。 好康？是什么新框架哦？ 什么新框架，比新框架还刺激，还可以让你的项目登duang郎哦。 哇，杰哥，你项目里面都没SQL语句诶，这是用的什么框架啊？ ​ 在我们之前编写的项目中，我们不难发现，实际上大部分的数据库交互操作，到最后都只会做一个事情，那就是把数据库中的数据映射为Java中的对象。比如我们要通过用户名去查找对应的用户，或是通过ID查找对应的学生信息，在使用Mybatis时，我们只需要编写正确的SQL语句就可以直接将获取的数据映射为对应的Java对象，通过调用Mapper中的方法就能直接获得实体类，这样就方便我们在Java中数据库表中的相关信息了。 ​ 但是以上这些操作都有一个共性，那就是它们都是通过某种条件去进行查询，而最后的查询结果，都是一个实体类，所以你会发现你写的很多SQL语句都是一个套路select * from xxx where xxx=xxx，实际上对于这种简单SQL语句，我们完全可以弄成一个模版来使用，那么能否有一种框架，帮我们把这些相同的套路给封装起来，直接把这类相似的SQL语句给屏蔽掉，不再由我们编写，而是让框架自己去组合拼接。 认识SpringData JPA首先我们来看一个国外的统计： 不对吧，为什么Mybatis这么好用，这么强大，却只有10%的人喜欢呢？然而事实就是，在国外JPA几乎占据了主导地位，而Mybatis并不像国内那样受待见，所以你会发现，JPA都有SpringBoot的官方直接提供的starter，而Mybatis没有，直到SpringBoot 3才开始加入到官方模版中。 那么，什么是JPA？ JPA（Java Persistence API）和JDBC类似，也是官方定义的一组接口，但是它相比传统的JDBC，它是为了实现ORM而生的，即Object-Relationl Mapping，它的作用是在关系型数据库和对象之间形成一个映射，这样，我们在具体的操作数据库的时候，就不需要再去和复杂的SQL语句打交道，只要像平时操作对象一样操作它就可以了。 其中比较常见的JPA实现有： Hibernate：Hibernate是JPA规范的一个具体实现，也是目前使用最广泛的JPA实现框架之一。它提供了强大的对象关系映射功能，可以将Java对象映射到数据库表中，并提供了丰富的查询语言和缓存机制。 EclipseLink：EclipseLink是另一个流行的JPA实现框架，由Eclipse基金会开发和维护。它提供了丰富的特性，如对象关系映射、缓存、查询语言和连接池管理等，并具有较高的性能和可扩展性。 OpenJPA：OpenJPA是Apache基金会的一个开源项目，也是JPA规范的一个实现。它提供了高性能的JPA实现和丰富的特性，如延迟加载、缓存和分布式事务等。 TopLink：TopLink是Oracle公司开发的一个对象关系映射框架，也是JPA规范的一个实现。虽然EclipseLink已经取代了TopLink成为Oracle推荐的JPA实现，但TopLink仍然得到广泛使用。 在之前，我们使用JDBC或是Mybatis来操作数据，通过直接编写对应的SQL语句来实现数据访问，但是我们发现实际上我们在Java中大部分操作数据库的情况都是读取数据并封装为一个实体类，因此，为什么不直接将实体类直接对应到一个数据库表呢？也就是说，一张表里面有什么属性，那么我们的对象就有什么属性，所有属性跟数据库里面的字段一一对应，而读取数据时，只需要读取一行的数据并封装为我们定义好的实体类既可以，而具体的SQL语句执行，完全可以交给框架根据我们定义的映射关系去生成，不再由我们去编写，因为这些SQL实际上都是千篇一律的。 而实现JPA规范的框架一般最常用的就是Hibernate，它是一个重量级框架，学习难度相比Mybatis也更高一些，而SpringDataJPA也是采用Hibernate框架作为底层实现，并对其加以封装。 官网：https://spring.io/projects/spring-data-jpa 使用JPA快速上手同样的，我们只需要导入stater依赖即可： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt; 接着我们可以直接创建一个类，比如用户类，我们只需要把一个账号对应的属性全部定义好即可： 123456@Datapublic class Account &#123; int id; String username; String password;&#125; 接着，我们可以通过注解形式，在属性上添加数据库映射关系，这样就能够让JPA知道我们的实体类对应的数据库表长啥样，这里用到了很多注解： 12345678910111213141516@Data@Entity //表示这个类是一个实体类@Table(name = &quot;account&quot;) //对应的数据库中表名称public class Account &#123; @GeneratedValue(strategy = GenerationType.IDENTITY) //生成策略，这里配置为自增 @Column(name = &quot;id&quot;) //对应表中id这一列 @Id //此属性为主键 int id; @Column(name = &quot;username&quot;) //对应表中username这一列 String username; @Column(name = &quot;password&quot;) //对应表中password这一列 String password;&#125; 接着我们来修改一下配置文件，把日志打印给打开： 1234567spring: jpa: #开启SQL语句执行日志信息 show-sql: true hibernate: #配置为检查数据库表结构，没有时会自动创建 ddl-auto: update ddl-auto属性用于设置自动表定义，可以实现自动在数据库中为我们创建一个表，表的结构会根据我们定义的实体类决定，它有以下几种： none: 不执行任何操作，数据库表结构需要手动创建。 create: 框架在每次运行时都会删除所有表，并重新创建。 create-drop: 框架在每次运行时都会删除所有表，然后再创建，但在程序结束时会再次删除所有表。 update: 框架会检查数据库表结构，如果与实体类定义不匹配，则会做相应的修改，以保持它们的一致性。 validate: 框架会检查数据库表结构与实体类定义是否匹配，如果不匹配，则会抛出异常。 这个配置项的作用是为了避免手动管理数据库表结构，使开发者可以更方便地进行开发和测试，但在生产环境中，更推荐使用数据库迁移工具来管理表结构的变更。 我们可以在日志中发现，在启动时执行了如下SQL语句： 我们的数据库中对应的表已经自动创建好了。 我们接着来看如何访问我们的表，我们需要创建一个Repository实现类： 123@Repositorypublic interface AccountRepository extends JpaRepository&lt;Account, Integer&gt; &#123;&#125; 注意JpaRepository有两个泛型，前者是具体操作的对象实体，也就是对应的表，后者是ID的类型，接口中已经定义了比较常用的数据库操作。编写接口继承即可，我们可以直接注入此接口获得实现类： 12345678910@ResourceAccountRepository repository;@Testvoid contextLoads() &#123; Account account = new Account(); account.setUsername(&quot;小红&quot;); account.setPassword(&quot;1234567&quot;); System.out.println(repository.save(account).getId()); //使用save来快速插入数据，并且会返回插入的对象，如果存在自增ID，对象的自增id属性会自动被赋值，这就很方便了&#125; 执行结果如下： 同时，查询操作也很方便： 12345@Testvoid contextLoads() &#123; //默认通过通过ID查找的方法，并且返回的结果是Optional包装的对象，非常人性化 repository.findById(1).ifPresent(System.out::println);&#125; 得到结果为： 包括常见的一些计数、删除操作等都包含在里面，仅仅配置应该接口就能完美实现增删改查： 我们发现，使用了JPA之后，整个项目的代码中没有出现任何的SQL语句，可以说是非常方便了，JPA依靠我们提供的注解信息自动完成了所有信息的映射和关联。 相比Mybatis，JPA几乎就是一个全自动的ORM框架，而Mybatis则顶多算是半自动ORM框架。 方法名称拼接自定义SQL虽然接口预置的方法使用起来非常方便，但是如果我们需要进行条件查询等操作或是一些判断，就需要自定义一些方法来实现，同样的，我们不需要编写SQL语句，而是通过方法名称的拼接来实现条件判断，这里列出了所有支持的条件判断名称： 属性 拼接方法名称示例 执行的语句 Distinct findDistinctByLastnameAndFirstname select distinct … where x.lastname &#x3D; ?1 and x.firstname &#x3D; ?2 And findByLastnameAndFirstname … where x.lastname &#x3D; ?1 and x.firstname &#x3D; ?2 Or findByLastnameOrFirstname … where x.lastname &#x3D; ?1 or x.firstname &#x3D; ?2 Is，Equals findByFirstname,findByFirstnameIs,findByFirstnameEquals … where x.firstname &#x3D; ?1 Between findByStartDateBetween … where x.startDate between ?1 and ?2 LessThan findByAgeLessThan … where x.age &lt; ?1 LessThanEqual findByAgeLessThanEqual … where x.age &lt;&#x3D; ?1 GreaterThan findByAgeGreaterThan … where x.age &gt; ?1 GreaterThanEqual findByAgeGreaterThanEqual … where x.age &gt;&#x3D; ?1 After findByStartDateAfter … where x.startDate &gt; ?1 Before findByStartDateBefore … where x.startDate &lt; ?1 IsNull，Null findByAge(Is)Null … where x.age is null IsNotNull，NotNull findByAge(Is)NotNull … where x.age not null Like findByFirstnameLike … where x.firstname like ?1 NotLike findByFirstnameNotLike … where x.firstname not like ?1 StartingWith findByFirstnameStartingWith … where x.firstname like ?1（参数与附加%绑定） EndingWith findByFirstnameEndingWith … where x.firstname like ?1（参数与前缀%绑定） Containing findByFirstnameContaining … where x.firstname like ?1（参数绑定以%包装） OrderBy findByAgeOrderByLastnameDesc … where x.age &#x3D; ?1 order by x.lastname desc Not findByLastnameNot … where x.lastname &lt;&gt; ?1 In findByAgeIn(Collection ages) … where x.age in ?1 NotIn findByAgeNotIn(Collection ages) … where x.age not in ?1 True findByActiveTrue … where x.active &#x3D; true False findByActiveFalse … where x.active &#x3D; false IgnoreCase findByFirstnameIgnoreCase … where UPPER(x.firstname) &#x3D; UPPER(?1) 比如我们想要实现根据用户名模糊匹配查找用户： 12345@Repositorypublic interface AccountRepository extends JpaRepository&lt;Account, Integer&gt; &#123; //按照表中的规则进行名称拼接，不用刻意去记，IDEA会有提示 List&lt;Account&gt; findAllByUsernameLike(String str);&#125; 我们来测试一下： 1234@Testvoid contextLoads() &#123; repository.findAllByUsernameLike(&quot;%明%&quot;).forEach(System.out::println);&#125; 又比如我们想同时根据用户名和ID一起查询： 1234567@Repositorypublic interface AccountRepository extends JpaRepository&lt;Account, Integer&gt; &#123; List&lt;Account&gt; findAllByUsernameLike(String str); Account findByIdAndUsername(int id, String username); //也可以使用Optional类进行包装，Optional&lt;Account&gt; findByIdAndUsername(int id, String username);&#125; 1234@Testvoid contextLoads() &#123; System.out.println(repository.findByIdAndUsername(1, &quot;小明&quot;));&#125; 比如我们想判断数据库中是否存在某个ID的用户： 1234567@Repositorypublic interface AccountRepository extends JpaRepository&lt;Account, Integer&gt; &#123; List&lt;Account&gt; findAllByUsernameLike(String str); Account findByIdAndUsername(int id, String username); //使用exists判断是否存在 boolean existsAccountById(int id);&#125; 注意自定义条件操作的方法名称一定要遵循规则，不然会出现异常： 1Caused by: org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract ... 有了这些操作，我们在编写一些简单SQL的时候就很方便了，用久了甚至直接忘记SQL怎么写。 关联查询在实际开发中，比较常见的场景还有关联查询，也就是我们会在表中添加一个外键字段，而此外键字段又指向了另一个表中的数据，当我们查询数据时，可能会需要将关联数据也一并获取，比如我们想要查询某个用户的详细信息，一般用户简略信息会单独存放一个表，而用户详细信息会单独存放在另一个表中。当然，除了用户详细信息之外，可能在某些电商平台还会有用户的购买记录、用户的购物车，交流社区中的用户帖子、用户评论等，这些都是需要根据用户信息进行关联查询的内容。 我们知道，在JPA中，每张表实际上就是一个实体类的映射，而表之间的关联关系，也可以看作对象之间的依赖关系，比如用户表中包含了用户详细信息的ID字段作为外键，那么实际上就是用户表实体中包括了用户详细信息实体对象： 12345678910111213141516171819202122@Data@Entity@Table(name = &quot;users_detail&quot;)public class AccountDetail &#123; @Column(name = &quot;id&quot;) @GeneratedValue(strategy = GenerationType.IDENTITY) @Id int id; @Column(name = &quot;address&quot;) String address; @Column(name = &quot;email&quot;) String email; @Column(name = &quot;phone&quot;) String phone; @Column(name = &quot;real_name&quot;) String realName;&#125; 而用户信息和用户详细信息之间形成了一对一的关系，那么这时我们就可以直接在类中指定这种关系： 1234567891011121314151617181920@Data@Entity@Table(name = &quot;users&quot;)public class Account &#123; @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;id&quot;) @Id int id; @Column(name = &quot;username&quot;) String username; @Column(name = &quot;password&quot;) String password; @JoinColumn(name = &quot;detail_id&quot;) //指定存储外键的字段名称 @OneToOne //声明为一对一关系 AccountDetail detail;&#125; 在修改实体类信息后，我们发现在启动时也进行了更新，日志如下： 123Hibernate: alter table users add column detail_id integerHibernate: create table users_detail (id integer not null auto_increment, address varchar(255), email varchar(255), phone varchar(255), real_name varchar(255), primary key (id)) engine=InnoDBHibernate: alter table users add constraint FK7gb021edkxf3mdv5bs75ni6jd foreign key (detail_id) references users_detail (id) 是不是感觉非常方便！都懒得去手动改表结构了。 接着我们往用户详细信息中添加一些数据，一会我们可以直接进行查询： 1234@Testvoid pageAccount() &#123; repository.findById(1).ifPresent(System.out::println);&#125; 查询后，可以发现，得到如下结果： 12Hibernate: select account0_.id as id1_0_0_, account0_.detail_id as detail_i4_0_0_, account0_.password as password2_0_0_, account0_.username as username3_0_0_, accountdet1_.id as id1_1_1_, accountdet1_.address as address2_1_1_, accountdet1_.email as email3_1_1_, accountdet1_.phone as phone4_1_1_, accountdet1_.real_name as real_nam5_1_1_ from users account0_ left outer join users_detail accountdet1_ on account0_.detail_id=accountdet1_.id where account0_.id=?Account(id=1, username=Test, password=123456, detail=AccountDetail(id=1, address=四川省成都市青羊区, email=8371289@qq.com, phone=1234567890, realName=本伟)) 也就是，在建立关系之后，我们查询Account对象时，会自动将关联数据的结果也一并进行查询。 那要是我们只想要Account的数据，不想要用户详细信息数据怎么办呢？我希望在我要用的时候再获取详细信息，这样可以节省一些网络开销，我们可以设置懒加载，这样只有在需要时才会向数据库获取： 123@JoinColumn(name = &quot;detail_id&quot;)@OneToOne(fetch = FetchType.LAZY) //将获取类型改为LAZYAccountDetail detail; 接着我们测试一下： 12345678@Transactional //懒加载属性需要在事务环境下获取，因为repository方法调用完后Session会立即关闭@Testvoid pageAccount() &#123; repository.findById(1).ifPresent(account -&gt; &#123; System.out.println(account.getUsername()); //获取用户名 System.out.println(account.getDetail()); //获取详细信息（懒加载） &#125;);&#125; 接着我们来看看控制台输出了什么： 1234Hibernate: select account0_.id as id1_0_0_, account0_.detail_id as detail_i4_0_0_, account0_.password as password2_0_0_, account0_.username as username3_0_0_ from users account0_ where account0_.id=?TestHibernate: select accountdet0_.id as id1_1_0_, accountdet0_.address as address2_1_0_, accountdet0_.email as email3_1_0_, accountdet0_.phone as phone4_1_0_, accountdet0_.real_name as real_nam5_1_0_ from users_detail accountdet0_ where accountdet0_.id=?AccountDetail(id=1, address=四川省成都市青羊区, email=8371289@qq.com, phone=1234567890, realName=卢本) 可以看到，获取用户名之前，并没有去查询用户的详细信息，而是当我们获取详细信息时才进行查询并返回AccountDetail对象。 那么我们是否也可以在添加数据时，利用实体类之间的关联信息，一次性添加两张表的数据呢？可以，但是我们需要稍微修改一下级联关联操作设定： 123@JoinColumn(name = &quot;detail_id&quot;)@OneToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL) //设置关联操作为ALLAccountDetail detail; ALL：所有操作都进行关联操作 PERSIST：插入操作时才进行关联操作 REMOVE：删除操作时才进行关联操作 MERGE：修改操作时才进行关联操作 可以多个并存，接着我们来进行一下测试： 1234567891011121314@Testvoid addAccount()&#123; Account account = new Account(); account.setUsername(&quot;Nike&quot;); account.setPassword(&quot;123456&quot;); AccountDetail detail = new AccountDetail(); detail.setAddress(&quot;重庆市渝中区解放碑&quot;); detail.setPhone(&quot;1234567890&quot;); detail.setEmail(&quot;73281937@qq.com&quot;); detail.setRealName(&quot;张三&quot;); account.setDetail(detail); account = repository.save(account); System.out.println(&quot;插入时，自动生成的主键ID为：&quot;+account.getId()+&quot;，外键ID为：&quot;+account.getDetail().getId());&#125; 可以看到日志结果： 123Hibernate: insert into users_detail (address, email, phone, real_name) values (?, ?, ?, ?)Hibernate: insert into users (detail_id, password, username) values (?, ?, ?)插入时，自动生成的主键ID为：6，外键ID为：3 结束后会发现数据库中两张表都同时存在数据。 接着我们来看一对多关联，比如每个用户的成绩信息： 123@JoinColumn(name = &quot;uid&quot;) //注意这里的name指的是Score表中的uid字段对应的就是当前的主键，会将uid外键设置为当前的主键@OneToMany(fetch = FetchType.LAZY, cascade = CascadeType.REMOVE) //在移除Account时，一并移除所有的成绩信息，依然使用懒加载List&lt;Score&gt; scoreList; 1234567891011121314151617181920@Data@Entity@Table(name = &quot;users_score&quot;) //成绩表，注意只存成绩，不存学科信息，学科信息id做外键public class Score &#123; @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;id&quot;) @Id int id; @OneToOne //一对一对应到学科上 @JoinColumn(name = &quot;cid&quot;) Subject subject; @Column(name = &quot;socre&quot;) double score; @Column(name = &quot;uid&quot;) int uid;&#125; 12345678910111213141516171819@Data@Entity@Table(name = &quot;subjects&quot;) //学科信息表public class Subject &#123; @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;cid&quot;) @Id int cid; @Column(name = &quot;name&quot;) String name; @Column(name = &quot;teacher&quot;) String teacher; @Column(name = &quot;time&quot;) int time;&#125; 在数据库中填写相应数据，接着我们就可以查询用户的成绩信息了： 1234567@Transactional@Testvoid test() &#123; repository.findById(1).ifPresent(account -&gt; &#123; account.getScoreList().forEach(System.out::println); &#125;);&#125; 成功得到用户所有的成绩信息，包括得分和学科信息。 同样的，我们还可以将对应成绩中的教师信息单独分出一张表存储，并建立多对一的关系，因为多门课程可能由同一个老师教授（千万别搞晕了，一定要理清楚关联关系，同时也是考验你的基础扎不扎实）： 123@ManyToOne(fetch = FetchType.LAZY)@JoinColumn(name = &quot;tid&quot;) //存储教师ID的字段，和一对一是一样的，也会当前表中创个外键Teacher teacher; 接着就是教师实体类了： 12345678910111213141516@Data@Entity@Table(name = &quot;teachers&quot;)public class Teacher &#123; @Column(name = &quot;id&quot;) @GeneratedValue(strategy = GenerationType.IDENTITY) @Id int id; @Column(name = &quot;name&quot;) String name; @Column(name = &quot;sex&quot;) String sex;&#125; 最后我们再进行一下测试： 1234567891011@Transactional@Testvoid test() &#123; repository.findById(3).ifPresent(account -&gt; &#123; account.getScoreList().forEach(score -&gt; &#123; System.out.println(&quot;课程名称：&quot;+score.getSubject().getName()); System.out.println(&quot;得分：&quot;+score.getScore()); System.out.println(&quot;任课教师：&quot;+score.getSubject().getTeacher().getName()); &#125;); &#125;);&#125; 成功得到多对一的教师信息。 最后我们再来看最复杂的情况，现在我们一门课程可以由多个老师教授，而一个老师也可以教授多个课程，那么这种情况就是很明显的多对多场景，现在又该如何定义呢？我们可以像之前一样，插入一张中间表表示教授关系，这个表中专门存储哪个老师教哪个科目： 123456@ManyToMany(fetch = FetchType.LAZY) //多对多场景@JoinTable(name = &quot;teach_relation&quot;, //多对多中间关联表 joinColumns = @JoinColumn(name = &quot;cid&quot;), //当前实体主键在关联表中的字段名称 inverseJoinColumns = @JoinColumn(name = &quot;tid&quot;) //教师实体主键在关联表中的字段名称)List&lt;Teacher&gt; teacher; 接着，JPA会自动创建一张中间表，并自动设置外键，我们就可以将多对多关联信息编写在其中了。 JPQL自定义SQL语句虽然SpringDataJPA能够简化大部分数据获取场景，但是难免会有一些特殊的场景，需要使用复杂查询才能够去完成，这时你又会发现，如果要实现，只能用回Mybatis了，因为我们需要自己手动编写SQL语句，过度依赖SpringDataJPA会使得SQL语句不可控。 使用JPA，我们也可以像Mybatis那样，直接编写SQL语句，不过它是JPQL语言，与原生SQL语句很类似，但是它是面向对象的，当然我们也可以编写原生SQL语句。 比如我们要更新用户表中指定ID用户的密码： 12345678@Repositorypublic interface AccountRepository extends JpaRepository&lt;Account, Integer&gt; &#123; @Transactional //DML操作需要事务环境，可以不在这里声明，但是调用时一定要处于事务环境下 @Modifying //表示这是一个DML操作 @Query(&quot;update Account set password = ?2 where id = ?1&quot;) //这里操作的是一个实体类对应的表，参数使用?代表，后面接第n个参数 int updatePasswordById(int id, String newPassword);&#125; 1234@Testvoid updateAccount()&#123; repository.updatePasswordById(1, &quot;654321&quot;);&#125; 现在我想使用原生SQL来实现根据用户名称修改密码： 12345@Transactional@Modifying@Query(value = &quot;update users set password = :pwd where username = :name&quot;, nativeQuery = true) //使用原生SQL，和Mybatis一样，这里使用 :名称 表示参数，当然也可以继续用上面那种方式。int updatePasswordByUsername(@Param(&quot;name&quot;) String username, //我们可以使用@Param指定名称 @Param(&quot;pwd&quot;) String newPassword); 1234@Testvoid updateAccount()&#123; repository.updatePasswordByUsername(&quot;Admin&quot;, &quot;654321&quot;);&#125; 通过编写原生SQL，在一定程度上弥补了SQL不可控的问题。 虽然JPA能够为我们带来非常便捷的开发体验，但是正是因为太便捷了，保姆级的体验有时也会适得其反，尤其是一些国内用到复杂查询业务的项目，可能开发到后期特别庞大时，就只能从底层SQL语句开始进行优化，而由于JPA尽可能地在屏蔽我们对SQL语句的编写，所以后期优化是个大问题，并且Hibernate相对于Mybatis来说，更加重量级。不过，在微服务的时代，单体项目一般不会太大，JPA的劣势并没有太明显地体现出来。 MybatisPlus框架前面我们体验了JPA带来的快速开发体验，但是我们发现，面对一些复杂查询时，JPA似乎有点力不从心，反观稍微麻烦一点的Mybatis却能够手动编写SQL，使用起来更加灵活，那么有没有一种既能灵活掌控逻辑又能快速完成开发的持久层框架呢？ MyBatis-Plus（简称 MP）是一个 MyBatis的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。 MybatisPlus的愿景是成为 MyBatis 最好的搭档，就像 魂斗罗 中的 1P、2P，基友搭配，效率翻倍。 官方网站地址 MybatisPlus具有以下特性： 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询 分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库 内置性能分析插件：可输出 SQL 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作 框架整体结构如下： 不过，光说还是不能体会到它带来的便捷性，我们接着就来上手体验一下。 快速上手跟之前一样，还是添加依赖： 123456789&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件依然只需要配置数据源即可： 123456spring: datasource: url: jdbc:mysql://localhost:3306/test username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver 然后依然是实体类，可以直接映射到数据库中的表： 123456789101112@Data@TableName(&quot;user&quot;) //对应的表名public class User &#123; @TableId(type = IdType.AUTO) //对应的主键 int id; @TableField(&quot;name&quot;) //对应的字段 String name; @TableField(&quot;email&quot;) String email; @TableField(&quot;password&quot;) String password;&#125; 接着，我们就可以编写一个Mapper来操作了： 12345@Mapperpublic interface UserMapper extends BaseMapper&lt;User&gt; &#123; //使用方式与JPA极其相似，同样是继承一个基础的模版Mapper //这个模版里面提供了预设的大量方法直接使用，跟JPA如出一辙&#125; 这里我们就来写一个简单测试用例： 1234567891011@SpringBootTestclass DemoApplicationTests &#123; @Resource UserMapper mapper; @Test void contextLoads() &#123; System.out.println(mapper.selectById(1)); //同样可以直接selectById，非常快速方便 &#125;&#125; 可以看到这个Mapper提供的方法还是很丰富的： 最后查到的结果 条件构造器对于一些复杂查询的情况，MybatisPlus支持我们自己构造QueryWrapper用于复杂条件查询： 123456789@Testvoid contextLoads() &#123; QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); //复杂查询可以使用QueryWrapper来完成 wrapper .select(&quot;id&quot;, &quot;name&quot;, &quot;email&quot;, &quot;password&quot;) //可以自定义选择哪些字段 .ge(&quot;id&quot;, 2) //选择判断id大于等于1的所有数据 .orderByDesc(&quot;id&quot;); //根据id字段进行降序排序 System.out.println(mapper.selectList(wrapper)); //Mapper同样支持使用QueryWrapper进行查询&#125; 通过使用上面的QueryWrapper对象进行查询，也就等价于下面的SQL语句： 1select id,name,email,password from user where id &gt;= 2 order by id desc 我们可以在配置中开启SQL日志打印： 123mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 最后得到的结果如下： 有些时候我们遇到需要批处理的情况，也可以直接使用批处理操作： 123456@Testvoid contextLoads() &#123; //支持批处理操作，我们可以一次性删除多个指定ID的用户 int count = mapper.deleteBatchIds(List.of(1, 3)); System.out.println(count);&#125; 我们也可以快速进行分页查询操作，不过在执行前我们需要先配置一下： 12345678910@Configurationpublic class MybatisConfiguration &#123; @Bean public MybatisPlusInterceptor paginationInterceptor() &#123; MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); //添加分页拦截器到MybatisPlusInterceptor中 interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; &#125;&#125; 这样我们就可以愉快地使用分页功能了： 123456@Testvoid contextLoads() &#123; //这里我们将用户表分2页，并获取第一页的数据 Page&lt;User&gt; page = mapper.selectPage(Page.of(1, 2), Wrappers.emptyWrapper()); System.out.println(page.getRecords()); //获取分页之后的数据&#125; 对于数据更新操作，我们也可以使用UpdateWrapper非常方便的来完成： 12345678@Testvoid contextLoads() &#123; UpdateWrapper&lt;User&gt; wrapper = new UpdateWrapper&lt;&gt;(); wrapper .set(&quot;username&quot;, &quot;hHHH&quot;) .eq(&quot;id&quot;,4); System.out.println(mapper.update(null, wrapper));&#125; 这样就可以快速完成更新操作了： QueryWrapper和UpdateWrapper还有专门支持Java 8新增的Lambda表达式的特殊实现，可以直接以函数式的形式进行编写，使用方法是一样的： 12345678@Testvoid contextLoads() &#123; LambdaQueryWrapper&lt;User&gt; wrapper = Wrappers .&lt;User&gt;lambdaQuery() .eq(User::getId, 2) //比如我们需要选择id为2的用户，前面传入方法引用，后面比的值 .select(User::getName, User::getId); //比如我们只需要选择name和id，那就传入对应的get方法引用 System.out.println(mapper.selectOne(wrapper));&#125; 接口基本操作虽然使用MybatisPlus提供的BaseMapper已经很方便了，但是我们的业务中，实际上很多时候也是一样的工作，都是去简单调用底层的Mapper做一个很简单的事情，MybatisPlus为我们提供了很方便的CRUD接口，直接实现了各种业务中会用到的增删改查操作。 我们只需要继承即可： 1234@Servicepublic interface UserService extends IService&lt;User&gt; &#123; //除了继承模版，我们也可以把它当成普通Service添加自己需要的方法&#125; 接着需要编写一个实现类，这个实现类就是UserService的实现： 123@Service //需要继承ServiceImpl才能实现那些默认的CRUD方法public class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123;&#125; 使用起来也很方便，整合了超多方法： 比如想批量插入一组用户数据到数据库中： 123456@Testvoid contextLoads() &#123; List&lt;User&gt; users = List.of(new User(&quot;xxx&quot;), new User(&quot;yyy&quot;)); //预设方法中已经支持批量保存了，这相比我们直接用for效率高不少 service.saveBatch(users);&#125; 还有更加方便快捷的保存或更新操作，当数据不存在时（通过主键ID判断）则插入新数据，否则就更新数据： 1234@Testvoid contextLoads() &#123; service.saveOrUpdate(new User(&quot;aaa&quot;));&#125; 也可以直接使用Service来进行链式查询，写法非常舒服： 12345@Testvoid contextLoads() &#123; User one = service.query().eq(&quot;id&quot;, 1).one(); System.out.println(one);&#125; 新版代码生成器它能够根据数据库做到代码的一键生成，能做到什么程度呢？ 首先我们需要先把整个项目的数据库给创建好，创建好之后，我们继续下一步，这里我们从头开始创建一个项目，感受一下它的强大，首先创建一个普通的SpringBoot项目： 接着导入一会需要用到的依赖： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.5.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt;&lt;/dependency&gt; 然后再配置一下数据源： 123456spring: datasource: url: jdbc:mysql://localhost:3306/test username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver 接着我们就可以开始编写自动生成脚本了，这里依然选择测试类，用到FastAutoGenerator作为生成器： 12345678910@Resource DataSource dataSource;@Test void contextLoads() &#123; FastAutoGenerator //首先使用create来配置数据库链接信息 .create(new DataSourceConfig.Builder(dataSource)) .execute(); &#125; 接着我们配置一下全局设置，这些会影响一会生成的代码： 1234567891011@Testvoid contextLoads() &#123; FastAutoGenerator .create(new DataSourceConfig.Builder(dataSource)) .globalConfig(builder -&gt; &#123; builder.author(&quot;rx&quot;); //作者信息，一会会变成注释 builder.commentDate(&quot;2023-09-06&quot;); //日期信息，一会会变成注释 builder.outputDir(&quot;src/main/java&quot;); //输出目录设置为当前项目的目录 &#125;) .execute();&#125; 然后是打包设置，也就是项目的生成的包等等，这里简单配置一下： 123456789101112131415@Testvoid contextLoads() &#123; FastAutoGenerator ... //打包设置，这里设置一下包名就行，注意跟我们项目包名设置为一致的 .packageConfig(builder -&gt; builder.parent(&quot;com.example&quot;)) .strategyConfig(builder -&gt; &#123; //设置为所有Mapper添加@Mapper注解 builder .mapperBuilder() .mapperAnnotation(Mapper.class) .build(); &#125;) .execute();&#125; 接着我们就可以直接执行了这个脚本了： 现在，可以看到我们的项目中已经出现自动生成代码了： 我们也可以直接运行这个项目： 速度可以说是非常之快，一个项目模版就搭建完成了，我们只需要接着写业务就可以了，当然如果各位小伙伴需要更多定制化的话，可以在官网查看其他的配置：配置 对于一些有特殊要求的用户来说，我们希望能够以自己的模版来进行生产，怎么才能修改它自动生成的代码模版呢，我们可以直接找到mybatis-plus-generator的源码： 生成模版都在在这个里面有写，我们要做的就是去修改这些模版，变成我们自己希望的样子，由于默认的模版解析引擎为Velocity，我们需要复制以.vm结尾的文件到resource随便一个目录中，然后随便改： 接着我们配置一下模版： 12345678910111213141516@Testvoid contextLoads() &#123; FastAutoGenerator ... .strategyConfig(builder -&gt; &#123; builder .mapperBuilder() .enableFileOverride() //开启文件重写，自动覆盖新的 .mapperAnnotation(Mapper.class) .build(); &#125;) .templateConfig(builder -&gt; &#123; builder.mapper(&quot;/templates/mapper.java.vm&quot;); &#125;) .execute();&#125; 这样，新生成的代码中就是按照我们自己的模版来定义了:","tags":["SpringBoot"],"categories":["Java","SpringBoot"]},{"title":"SpringMVC总结","path":"/Java/Spring/SpringMVC/","content":"[TOC] SpringMVC在SpringMVC阶段，你就能逐渐够体会到Spring框架为我们带来的便捷之处了。 此阶段，我们将再次回到Tomcat的Web应用程序开发中，去感受SpringMVC为我们带来的巨大便捷。 MVC理论基础在之前，我们给大家讲解了三层架构，包括： 每一层都有着各自的职责，其中最关键的当属表示层，因为它相当于就是直接与用户的浏览器打交道的一层，并且所有的请求都会经过它进行解析，然后再告知业务层进行处理，任何页面的返回和数据填充也全靠表示层来完成，因此它实际上是整个三层架构中最关键的一层，而在之前的实战开发中，我们编写了大量的Servlet（也就是表示层实现）来处理来自浏览器的各种请求，但是我们发现，仅仅是几个很小的功能，以及几个很基本的页面，我们都要编写将近十个Servlet，如果是更加大型的网站系统，比如淘宝、B站，光是一个页面中可能就包含了几十甚至上百个功能，想想那样的话写起来得多恐怖。 因此，SpringMVC正是为了解决这种问题而生的，它是一个非常优秀的表示层框架（在此之前还有一个叫做Struts2的框架，但是现阶段貌似快凉透了），采用MVC思想设计实现。 MVC解释如下： M是指业务模型（Model）：通俗的讲就是我们之前用于封装数据传递的实体类。 V是指用户界面（View）：一般指的是前端页面。 C则是控制器（Controller）：控制器就相当于Servlet的基本功能，处理请求，返回响应。 SpringMVC正是希望这三者之间进行解耦，实现各干各的，更加精细地划分对应的职责。最后再将View和Model进行渲染，得到最终的页面并返回给前端（就像之前使用Thymeleaf那样，把实体数据对象和前端页面都给到Thymeleaf，然后它会将其进行整合渲染得到最终有数据的页面，而本教程也会使用Thymeleaf作为视图解析器进行讲解） 配置环境并搭建项目由于SpringMVC还没有支持最新的Tomcat10（主要是之前提到的包名问题，神仙打架百姓遭殃）所以我们干脆就再来配置一下Tomcat9环境，相当于回顾一下。 下载地址：https://tomcat.apache.org/download-90.cgi 添加SpringMVC的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.3.13&lt;/version&gt;&lt;/dependency&gt; 接着我们需要配置一下web.xml，将DispatcherServlet替换掉Tomcat自带的Servlet，这里url-pattern需要写为/，即可完成替换： 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot; version=&quot;4.0&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 接着需要为整个Web应用程序配置一个Spring上下文环境（也就是容器），因为SpringMVC是基于Spring开发的，它直接利用Spring提供的容器来实现各种功能，这里我们直接使用注解方式进行配置，不再使用XML配置文件： 12345678&lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;com.example.config.MvcConfiguration&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;contextClass&lt;/param-name&gt; &lt;param-value&gt;org.springframework.web.context.support.AnnotationConfigWebApplicationContext&lt;/param-value&gt; &lt;/init-param&gt; 如果还是想使用XML配置文件进行配置，则不需要下半部分，直接这样写： 1234&lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;配置文件名称&lt;/param-value&gt;&lt;/init-param&gt; 如果你希望完完全全丢弃配置文件，可以直接添加一个类，Tomcat会在类路径中查找实现ServletContainerInitializer 接口的类，如果发现的话，就用它来配置Servlet容器，Spring提供了这个接口的实现类 SpringServletContainerInitializer , 通过@HandlesTypes(WebApplicationInitializer.class)设置，这个类反过来会查找实现WebApplicationInitializer 的类，并将配置的任务交给他们来完成，因此直接实现接口即可： 12345678910111213141516public class MainInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class[]&#123;MainConfiguration.class&#125;; //基本的Spring配置类，一般用于业务层配置 &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[0]; //配置DispatcherServlet的配置类、主要用于Controller等配置 &#125; @Override protected String[] getServletMappings() &#123; return new String[]&#123;&quot;/&quot;&#125;; //匹配路径，与上面一致 &#125;&#125; 顺便编写一下最基本的配置类： 1234@Configurationpublic class MainConfiguration &#123;&#125; 后面我们都采用无XML配置方式进行讲解。 这样，就完成最基本的配置了，现在任何请求都会优先经过DispatcherServlet进行集中处理，下面我们会详细讲解如何使用它。 Controller控制器有了SpringMVC之后，我们不必再像之前那样一个请求地址创建一个Servlet了，它使用DispatcherServlet替代Tomcat为我们提供的默认的静态资源Servlet，也就是说，现在所有的请求（除了jsp，因为Tomcat还提供了一个jsp的Servlet）都会经过DispatcherServlet进行处理。 那么DispatcherServlet会帮助我们做什么呢？ 根据图片我们可以了解，我们的请求到达Tomcat服务器之后，会交给当前的Web应用程序进行处理，而SpringMVC使用DispatcherServlet来处理所有的请求，也就是说它被作为一个统一的访问点，所有的请求全部由它来进行调度。 当一个请求经过DispatcherServlet之后，会先走HandlerMapping，它会将请求映射为HandlerExecutionChain，依次经过HandlerInterceptor有点类似于之前我们所学的过滤器，不过在SpringMVC中我们使用的是拦截器，然后再交给HandlerAdapter，根据请求的路径选择合适的控制器进行处理，控制器处理完成之后，会返回一个ModelAndView对象，包括数据模型和视图，通俗的讲就是页面中数据和页面本身（只包含视图名称即可）。 返回ModelAndView之后，会交给ViewResolver（视图解析器）进行处理，视图解析器会对整个视图页面进行解析，SpringMVC自带了一些视图解析器，但是只适用于JSP页面，我们也可以像之前一样使用Thymeleaf作为视图解析器，这样我们就可以根据给定的视图名称，直接读取HTML编写的页面，解析为一个真正的View。 解析完成后，就需要将页面中的数据全部渲染到View中，最后返回给DispatcherServlet一个包含所有数据的成形页面，再响应给浏览器，完成整个过程。 因此，实际上整个过程我们只需要编写对应请求路径的的Controller以及配置好我们需要的ViewResolver即可，之后还可以继续补充添加拦截器，而其他的流程已经由SpringMVC帮助我们完成了。 配置视图解析器和控制器首先我们需要实现最基本的页面解析并返回，第一步就是配置视图解析器，这里我们使用Thymeleaf为我们提供的视图解析器，导入需要的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.thymeleaf&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-spring5&lt;/artifactId&gt; &lt;version&gt;3.0.12.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置视图解析器非常简单，我们只需要将对应的ViewResolver注册为Bean即可，这里我们直接在配置类中编写： 1234567891011121314151617181920212223242526272829303132@ComponentScan(&quot;com.example.controller&quot;)@Configuration@EnableWebMvcpublic class WebConfiguration &#123; //我们需要使用ThymeleafViewResolver作为视图解析器，并解析我们的HTML页面 @Bean public ThymeleafViewResolver thymeleafViewResolver(@Autowired SpringTemplateEngine springTemplateEngine)&#123; ThymeleafViewResolver resolver = new ThymeleafViewResolver(); resolver.setOrder(1); //可以存在多个视图解析器，并且可以为他们设定解析顺序 resolver.setCharacterEncoding(&quot;UTF-8&quot;); //编码格式是重中之重 resolver.setTemplateEngine(springTemplateEngine); //和之前JavaWeb阶段一样，需要使用模板引擎进行解析，所以这里也需要设定一下模板引擎 return resolver; &#125; //配置模板解析器 @Bean public SpringResourceTemplateResolver templateResolver()&#123; SpringResourceTemplateResolver resolver = new SpringResourceTemplateResolver(); resolver.setSuffix(&quot;.html&quot;); //需要解析的后缀名称 resolver.setPrefix(&quot;/&quot;); //需要解析的HTML页面文件存放的位置 return resolver; &#125; //配置模板引擎Bean @Bean public SpringTemplateEngine springTemplateEngine(@Autowired ITemplateResolver resolver)&#123; SpringTemplateEngine engine = new SpringTemplateEngine(); engine.setTemplateResolver(resolver); //模板解析器，默认即可 return engine; &#125;&#125; 别忘了在Initializer中添加此类作为配置： 1234@Overrideprotected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[]&#123;MvcConfiguration.class&#125;;&#125; 现在我们就完成了视图解析器的配置，我们接着来创建一个Controller，创建Controller也非常简单，只需在一个类上添加一个@Controller注解即可，它会被Spring扫描并自动注册为Controller类型的Bean，然后我们只需要在类中编写方法用于处理对应地址的请求即可： 123456789@Controller //直接添加注解即可public class MainController &#123; @RequestMapping(&quot;/index&quot;) //直接填写访问路径 public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;); //返回ModelAndView对象，这里填入了视图的名称 //返回后会经过视图解析器进行处理 &#125;&#125; 我们会发现，打开浏览器之后就可以直接访问我们的HTML页面了。 而页面中的数据我们可以直接向Model进行提供： 123456@RequestMapping(value = &quot;/index&quot;)public ModelAndView index()&#123; ModelAndView modelAndView = new ModelAndView(&quot;index&quot;); modelAndView.getModel().put(&quot;name&quot;, &quot;啊这&quot;); return modelAndView;&#125; 输出 这样Thymeleaf就能收到我们传递的数据进行解析： 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;static/test.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; HelloWorld！ &lt;div th:text=&quot;$&#123;name&#125;&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 当然，如果仅仅是传递一个页面不需要任何的附加属性，我们可以直接返回View名称，SpringMVC会将其自动包装为ModelAndView对象： 1234@RequestMapping(value = &quot;/index&quot;)public String index()&#123; return &quot;index&quot;;&#125; 还可以单独添加一个Model作为形参进行设置，SpringMVC会自动帮助我们传递实例对象： 12345@RequestMapping(value = &quot;/index&quot;)public String index(Model model)&#123; //这里不仅仅可以是Model，还可以是Map、ModelMap model.addAttribute(&quot;name&quot;, &quot;yyds&quot;); return &quot;index&quot;;&#125; 注意，一定要保证视图名称下面出现横线并且按住Ctrl可以跳转，配置才是正确的（最新版IDEA） 我们的页面中可能还会包含一些静态资源，比如js、css，因此这里我们还需要配置一下，让静态资源通过Tomcat提供的默认Servlet进行解析，我们需要让配置类实现一下WebMvcConfigurer接口，这样在Web应用程序启动时，会根据我们重写方法里面的内容进行进一步的配置： 12345678910@Overridepublic void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; configurer.enable(); //开启默认的Servlet&#125;@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;/static/**&quot;).addResourceLocations(&quot;/WEB-INF/static/&quot;); //配置静态资源的访问路径&#125; 我们编写一下前端内容： 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;!-- 引用静态资源，这里使用Thymeleaf的网址链接表达式，Thymeleaf会自动添加web应用程序的名称到链接前面 --&gt; &lt;script th:src=&quot;@&#123;/static/test.js&#125;&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; HelloWorld！&lt;/body&gt;&lt;/html&gt; 创建test.js并编写如下内容： 1window.alert(&quot;Welcome to Wonderland!&quot;) 最后访问页面，页面在加载时就会显示一个弹窗，这样我们就完成了最基本的页面配置。相比之前的方式，这样就简单很多了，直接避免了编写大量的Servlet来处理请求 @RequestMapping详解此注解就是将请求和处理请求的方法建立一个映射关系，当收到请求时就可以根据映射关系调用对应的请求处理方法，注解定义如下： 1234567891011121314151617181920@Mappingpublic @interface RequestMapping &#123; String name() default &quot;&quot;; @AliasFor(&quot;path&quot;) String[] value() default &#123;&#125;; @AliasFor(&quot;value&quot;) String[] path() default &#123;&#125;; RequestMethod[] method() default &#123;&#125;; String[] params() default &#123;&#125;; String[] headers() default &#123;&#125;; String[] consumes() default &#123;&#125;; String[] produces() default &#123;&#125;;&#125; 其中最关键的是path属性（等价于value），它决定了当前方法处理的请求路径，注意路径必须全局唯一，任何路径只能有一个方法进行处理，它是一个数组，也就是说可以使用此方法处理多个请求路径： 1234@RequestMapping(&#123;&quot;/index&quot;, &quot;/test&quot;&#125;)public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;);&#125; 现在我们访问&#x2F;index或是&#x2F;test都会经过此方法进行处理。 我们也可以直接将@RequestMapping添加到类名上，表示为此类中的所有请求映射添加一个路径前缀，比如： 123456789@Controller@RequestMapping(&quot;/yyds&quot;)public class MainController &#123; @RequestMapping(&#123;&quot;/index&quot;, &quot;/test&quot;&#125;) public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;); &#125;&#125; 那么现在我们需要访问/yyds/index或是/yyds/test才可以得到此页面。我们可以直接在IDEA下方的端点板块中查看当前Web应用程序定义的所有请求映射，并且可以通过IDEA为我们提供的内置Web客户端直接访问某个路径 路径还支持使用通配符进行匹配： ?：表示任意一个字符，比如@RequestMapping(&quot;/index/x?&quot;)可以匹配&#x2F;index&#x2F;xa、&#x2F;index&#x2F;xb等等。 *：表示任意0-n个字符，比如@RequestMapping(&quot;/index/*&quot;)可以匹配&#x2F;index&#x2F;haha、&#x2F;index&#x2F;yyds等。 **：表示当前目录或基于当前目录的多级目录，比如@RequestMapping(&quot;/index/**&quot;)可以匹配&#x2F;index、&#x2F;index&#x2F;xxx等。 method属性，顾名思义，它就是请求的方法类型，可以限定请求方式，比如： 1234@RequestMapping(value = &quot;/index&quot;, method = RequestMethod.POST)public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;);&#125; 如果直接使用浏览器访问此页面，会显示405方法不支持，因为浏览器默认使用GET方法获取页面，而这里指定为POST方法访问此地址，所以访问失败，我们现在再去端点中用POST方式去访问，成功得到页面。 也可以使用衍生注解直接设定为指定类型的请求映射： 1234@PostMapping(value = &quot;/index&quot;)public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;);&#125; 这里使用了@PostMapping直接指定为POST请求类型的请求映射，同样的，还有@GetMapping可以直接指定为GET请求方式，这里就不一一列举了。 我们可以使用params属性来指定请求必须携带哪些请求参数，比如： 1234@RequestMapping(value = &quot;/index&quot;, params = &#123;&quot;username&quot;, &quot;password&quot;&#125;)public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;);&#125; 比如这里我们要求请求中必须携带username和password属性，否则无法访问。 它还支持表达式，比如我们可以这样编写： 1234@RequestMapping(value = &quot;/index&quot;, params = &#123;&quot;!username&quot;, &quot;password&quot;&#125;)public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;);&#125; 在username之前添加一个感叹号表示请求的不允许携带此参数，否则无法访问，我们甚至可以直接设定一个固定值： 1234@RequestMapping(value = &quot;/index&quot;, params = &#123;&quot;username!=test&quot;, &quot;password=123&quot;&#125;)public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;);&#125; 这样，请求参数username不允许为test，并且password必须为123，否则无法访问。 header属性用法与params一致，但是它要求的是请求头中需要携带什么内容，比如： 1234@RequestMapping(value = &quot;/index&quot;, headers = &quot;!Connection&quot;)public ModelAndView index()&#123; return new ModelAndView(&quot;index&quot;);&#125; 那么，如果请求头中携带了Connection属性，将无法访问。其他两个属性： consumes： 指定处理请求的提交内容类型（Content-Type），例如application&#x2F;json, text&#x2F;html; produces: 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回； @RequestParam和@RequestHeader详解如何获取到请求中的参数? 为方法添加一个形式参数，并在形式参数前面添加@RequestParam注解即可： 12345@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(@RequestParam(&quot;username&quot;) String username)&#123; System.out.println(&quot;收到一个参数&quot;+username); return new ModelAndView(&quot;index&quot;);&#125; 需要在@RequestParam中填写参数名称，参数的值会自动传递给形式参数，我们可以直接在方法中使用，注意，如果参数名称与形式参数名称相同，即使不添加@RequestParam也能获取到参数值。 一旦添加@RequestParam，那么此请求必须携带指定参数 输出 我们也可以将require属性设定为false来将属性设定为非必须： 12345@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(@RequestParam(value = &quot;username&quot;, required = false) String username)&#123; System.out.println(&quot;接受到请求参数：&quot;+username); return new ModelAndView(&quot;index&quot;);&#125; 我们还可以直接设定一个默认值，当请求参数缺失时，可以直接使用默认值： 12345@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(@RequestParam(value = &quot;username&quot;, required = false, defaultValue = &quot;ha&quot;) String username)&#123; System.out.println(&quot;接受到请求参数：&quot;+username); return new ModelAndView(&quot;index&quot;);&#125; 如果需要使用Servlet原本的一些类，比如： 12345@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(HttpServletRequest request)&#123; System.out.println(&quot;接受到请求参数：&quot;+request.getParameterMap().keySet()); return new ModelAndView(&quot;index&quot;);&#125; 直接添加HttpServletRequest为形式参数即可，SpringMVC会自动传递该请求原本的HttpServletRequest对象 同理，我们也可以添加HttpServletResponse作为形式参数，甚至可以直接将HttpSession也作为参数传递： 123456@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(HttpSession session)&#123; System.out.println(session.getAttribute(&quot;test&quot;)); session.setAttribute(&quot;test&quot;, &quot;haha&quot;); return new ModelAndView(&quot;index&quot;);&#125; 我们还可以直接将请求参数传递给一个实体类： 12345@Datapublic class User &#123; String username; String password;&#125; 注意必须携带set方法或是构造方法中包含所有参数，请求参数会自动根据类中的字段名称进行匹配： 12345@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(User user)&#123; System.out.println(&quot;收到一个请求参数&quot;+user); return new ModelAndView(&quot;index&quot;);&#125; 输出 @RequestHeader与@RequestParam用法一致，不过它是用于获取请求头参数的 @CookieValue和@SessionAttrbutie通过使用@CookieValue注解，我们也可以快速获取请求携带的Cookie信息： 1234567@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(HttpServletResponse response, @CookieValue(value = &quot;test&quot;, required = false) String test)&#123; System.out.println(&quot;获取到cookie值为：&quot;+test); response.addCookie(new Cookie(&quot;test&quot;, &quot;Omg&quot;)); return new ModelAndView(&quot;index&quot;);&#125; 会发现第一次没有cookie，后来经过刷新之后，才有cookie显示 同样的，Session也能使用注解快速获取： 1234567@RequestMapping(value = &quot;/index&quot;)public ModelAndView index(@SessionAttribute(value = &quot;test&quot;, required = false) String test, HttpSession session)&#123; session.setAttribute(&quot;test&quot;, &quot;xxxx&quot;); System.out.println(test); return new ModelAndView(&quot;index&quot;);&#125; 可以发现，通过使用SpringMVC框架，整个Web应用程序的开发变得非常简单，大部分功能只需要一个注解就可以搞定了，正是得益于Spring框架，SpringMVC才能大显身手。 重定向和请求转发重定向和请求转发也非常简单，我们只需要在视图名称前面添加一个前缀即可，比如重定向： 123456789@RequestMapping(&quot;/index&quot;)public String index()&#123; return &quot;redirect:home&quot;;&#125;@RequestMapping(&quot;/home&quot;)public String home()&#123; return &quot;home&quot;;&#125; 通过添加redirect:前缀，就可以很方便地实现重定向，那么请求转发呢，其实也是一样的，使用forward:前缀表示转发给其他请求映射： 123456789@RequestMapping(&quot;/index&quot;)public String index()&#123; return &quot;forward:home&quot;;&#125;@RequestMapping(&quot;/home&quot;)public String home()&#123; return &quot;home&quot;;&#125; 我们会发现链接是index，但实际上给home进行处理 使用SpringMVC，只需要一个前缀就可以实现重定向和请求转发，非常方便。 Bean的Web作用域在学习Spring时我们讲解了Bean的作用域，包括singleton和prototype，Bean分别会以单例和多例模式进行创建，而在SpringMVC中，它的作用域被继续细分： request：对于每次HTTP请求，使用request作用域定义的Bean都将产生一个新实例，请求结束后Bean也消失。 session：对于每一个会话，使用session作用域定义的Bean都将产生一个新实例，会话过期后Bean也消失。 global session：不常用，不做讲解。 这里我们创建一个测试类来试试看： 123public class TestBean &#123;&#125; 接着将其注册为Bean，注意这里需要添加@RequestScope或是@SessionScope表示此Bean的Web作用域： 12345@Bean@RequestScopepublic TestBean testBean()&#123; return new TestBean();&#125; 接着我们将其自动注入到Controller中： 123456789101112@Controllerpublic class MainController &#123; @Resource TestBean bean; @RequestMapping(value = &quot;/index&quot;) public ModelAndView index()&#123; System.out.println(bean); return new ModelAndView(&quot;index&quot;); &#125;&#125; 我们发现，每次发起得到的Bean实例都不同 接着我们将其作用域修改为@SessionScope，这样作用域就上升到Session，只要清理浏览器的Cookie，那么都会被认为是同一个会话，只要是同一个会话，那么Bean实例始终不变 实际上，它也是通过代理实现的，我们调用Bean中的方法会被转发到真正的Bean对象去执行。 RestFul风格中文释义为“表现层状态转换”，它不是一种标准，而是一种设计风格。它的主要作用是充分并正确利用HTTP协议的特性，规范资源获取的URI路径。通俗的讲，RESTful风格的设计允许将参数通过URL拼接传到服务端，目的是让URL看起来更简洁实用，并且我们可以充分使用多种HTTP请求方式（POST&#x2F;GET&#x2F;PUT&#x2F;DELETE），来执行相同请求地址的不同类型操作 因此，这种风格的连接，我们就可以直接从请求路径中读取参数，比如： http://localhost:8080/mvc/index/123456 我们可以直接将index的下一级路径作为请求参数进行处理，也就是说现在的请求参数包含在了请求路径中： 12345@RequestMapping(&quot;/index/&#123;str&#125;&quot;)public String index(@PathVariable String str) &#123; System.out.println(str); return &quot;index&quot;;&#125; 注意请求路径我们可以手动添加类似占位符一样的信息，这样占位符位置的所有内容都会被作为请求参数，而方法的形参列表中必须包括一个与占位符同名的并且添加了@PathVariable注解的参数，或是由@PathVariable注解指定为占位符名称： 12345@RequestMapping(&quot;/index/&#123;str&#125;&quot;)public String index(@PathVariable(&quot;str&quot;) String text)&#123; System.out.println(&quot;receive :&quot;+text); return &quot;index&quot;;&#125; 输出 如果没有配置正确，方法名称上会出现黄线。 我们可以按照不同功能进行划分： POST http://localhost:8080/mvc/index - 添加用户信息，携带表单数据 GET http://localhost:8080/mvc/index/{id} - 获取用户信息，id直接放在请求路径中 PUT http://localhost:8080/mvc/index - 修改用户信息，携带表单数据 DELETE http://localhost:8080/mvc/index/{id} - 删除用户信息，id直接放在请求路径中 我们分别编写四个请求映射： 123456789101112131415161718192021222324252627@Controllerpublic class MainController &#123; @RequestMapping(value = &quot;/index/&#123;id&#125;&quot;, method = RequestMethod.GET) public String get(@PathVariable(&quot;id&quot;) String text)&#123; System.out.println(&quot;获取用户：&quot;+text); return &quot;index&quot;; &#125; @RequestMapping(value = &quot;/index&quot;, method = RequestMethod.POST) public String post(String username)&#123; System.out.println(&quot;添加用户：&quot;+username); return &quot;index&quot;; &#125; @RequestMapping(value = &quot;/index/&#123;id&#125;&quot;, method = RequestMethod.DELETE) public String delete(@PathVariable(&quot;id&quot;) String text)&#123; System.out.println(&quot;删除用户：&quot;+text); return &quot;index&quot;; &#125; @RequestMapping(value = &quot;/index&quot;, method = RequestMethod.PUT) public String put(String username)&#123; System.out.println(&quot;修改用户：&quot;+username); return &quot;index&quot;; &#125;&#125; 之后点开端点，进行测试 之后输出 Interceptor拦截器拦截器是整个SpringMVC的一个重要内容，拦截器与过滤器类似，都是用于拦截一些非法请求，但是我们之前讲解的过滤器是作用于Servlet之前，只有经过层层的拦截器才可以成功到达Servlet，而拦截器并不是在Servlet之前，它在Servlet与RequestMapping之间，相当于DispatcherServlet在将请求交给对应Controller中的方法之前进行拦截处理，它只会拦截所有Controller中定义的请求映射对应的请求（不会拦截静态资源），这里一定要区分两者的不同。 创建拦截器创建一个拦截器我们需要实现一个HandlerInterceptor接口： 1234567891011121314151617public class MainInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println(&quot;我是处理之前！&quot;); return true; //只有返回true才会继续，否则直接结束 &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println(&quot;我是处理之后！&quot;); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println(&quot;我是完成之后！&quot;); &#125;&#125; 接着我们需要在配置类中进行注册： 123456@Overridepublic void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new MainInterceptor()) .addPathPatterns(&quot;/**&quot;) //添加拦截器的匹配路径，只要匹配一律拦截 .excludePathPatterns(&quot;/home&quot;); //拦截器不进行拦截的路径&#125; 现在我们在浏览器中访问index页面，再访问home页面 得到整理拦截器的执行顺序： 我是处理之前！ 我是处理！ 我是处理之后！ 我是完成之后！ 也就是说，处理前和处理后，包含了真正的请求映射的处理，在整个流程结束后还执行了一次afterCompletion方法，其实整个过程与我们之前所认识的Filter类似，不过在处理前，我们只需要返回true或是false表示是否被拦截即可，而不是再去使用FilterChain进行向下传递。 那么我们就来看看，如果处理前返回false，会怎么样： 我是处理之前！ 通过结果发现一旦返回false，之后的所有流程全部取消，那么如果是在处理中发生异常了呢？ 123456@RequestMapping(&quot;/index&quot;)public String index()&#123; System.out.println(&quot;我是处理！&quot;); if(true) throw new RuntimeException(&quot;&quot;); return &quot;index&quot;;&#125; 结果为： 我是处理之前！我是处理！我是完成之后！ 我们发现如果处理过程中抛出异常，那么久不会执行处理后postHandle方法，但是会执行afterCompletion方法，我们可以在此方法中获取到抛出的异常。 多级拦截器前面介绍了仅仅只有一个拦截器的情况，我们接着来看如果存在多个拦截器会如何执行，我们以同样的方式创建二号拦截器： 1234567891011121314151617public class SubInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println(&quot;二号拦截器：我是处理之前！&quot;); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println(&quot;二号拦截器：我是处理之后！&quot;); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println(&quot;二号拦截器：我是完成之后！&quot;); &#125;&#125; 注册二号拦截器： 1234567@Overridepublic void addInterceptors(InterceptorRegistry registry) &#123; //一号拦截器 registry.addInterceptor(new MainInterceptor()).addPathPatterns(&quot;/**&quot;).excludePathPatterns(&quot;/home&quot;); //二号拦截器 registry.addInterceptor(new SubInterceptor()).addPathPatterns(&quot;/**&quot;);&#125; 注意拦截顺序就是注册的顺序，因此拦截器会根据注册顺序依次执行，我们可以打开浏览器运行一次： 一号拦截器：我是处理之前！二号拦截器：我是处理之前！我是处理！二号拦截器：我是处理之后！一号拦截器：我是处理之后！二号拦截器：我是完成之后！一号拦截器：我是完成之后！ 和多级Filter相同，在处理之前，是按照顺序从前向后进行拦截的，但是处理完成之后，就按照倒序执行处理后方法，而完成后是在所有的postHandle执行之后再同样的以倒序方式执行。 那么如果这时一号拦截器在处理前就返回了false呢？ 12345@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println(&quot;一号拦截器：我是处理之前！&quot;); return false;&#125; 得到结果如下： 一号拦截器：我是处理之前！ 与单个拦截器的情况一样，一旦拦截器返回false，那么之后无论有无拦截器，都不再继续。 异常处理当我们的请求映射方法中出现异常时，会直接展示在前端页面，这是因为SpringMVC为我们提供了默认的异常处理页面，当出现异常时，我们的请求会被直接转交给专门用于异常处理的控制器进行处理。 我们可以自定义一个异常处理控制器，一旦出现指定异常，就会转接到此控制器执行： 12345678910@ControllerAdvicepublic class ErrorController &#123; @ExceptionHandler(Exception.class) public String error(Exception e, Model model)&#123; //可以直接添加形参来获取异常 e.printStackTrace(); model.addAttribute(&quot;e&quot;, e); return &quot;500&quot;; &#125;&#125; 接着我们编写一个专门显示异常的页面： 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; error exists！ &lt;div th:text=&quot;$&#123;e&#125;&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 接着修改： 123456@RequestMapping(&quot;/index&quot;)public String index()&#123; System.out.println(&quot;我是处理！&quot;); if(true) throw new RuntimeException(&quot;您的氪金力度不足，无法访问！&quot;); return &quot;index&quot;;&#125; 访问后，我们发现控制台会输出异常信息，同时页面也是我们自定义的一个页面 JSON数据格式与AJAX请求JSON (JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。 我们现在推崇的是前后端分离的开发模式，而不是所有的内容全部交给后端渲染再发送给浏览器，也就是说，整个Web页面的内容在一开始就编写完成了，而其中的数据由前端执行JS代码来向服务器动态获取，再到前端进行渲染（填充），这样可以大幅度减少后端的压力，并且后端只需要传输关键数据即可（在即将到来的SpringBoot阶段，我们将完全采用前后端分离的开发模式） JSON数据格式既然要实现前后端分离，那么我们就必须约定一种更加高效的数据传输模式，来向前端页面传输后端提供的数据。因此JSON横空出世，它非常容易理解，并且与前端的兼容性极好，因此现在比较主流的数据传输方式则是通过JSON格式承载的。 一个JSON格式的数据长这样，以学生对象为例： 1&#123;&quot;name&quot;: &quot;ALice&quot;, &quot;age&quot;: 18&#125; 多个学生可以以数组的形式表示： 1[&#123;&quot;name&quot;: Alice&quot;, &quot;age&quot;: 18&#125;, &#123;&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 18&#125;] 嵌套关系可以表示为： 1&#123;&quot;studentList&quot;: [&#123;&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 18&#125;, &#123;&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 18&#125;], &quot;count&quot;: 2&#125; 它直接包括了属性的名称和属性的值，与JavaScript的对象极为相似，它到达前端后，可以直接转换为对象，以对象的形式进行操作和内容的读取，相当于以字符串形式表示了一个JS对象，我们可以直接在控制台窗口中测试： 123let obj = JSON.parse(&#x27;&#123;&quot;studentList&quot;: [&#123;&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 18&#125;, &#123;&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 18&#125;], &quot;count&quot;: 2&#125;&#x27;)//将JSON格式字符串转换为JS对象obj.studentList[0].name //直接访问第一个学生的名称 实例 我们也可以将JS对象转换为JSON字符串： 1JSON.stringify(obj) 我们后端就可以以JSON字符串的形式向前端返回数据，这样前端在拿到数据之后，就可以快速获取，非常方便 快速创建一个JSON格式的数据 我们首先需要导入以下依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.78&lt;/version&gt;&lt;/dependency&gt; JSON解析框架有很多种，比较常用的是Jackson和FastJSON，这里我们使用阿里巴巴的FastJSON进行解析。 首先要介绍的是JSONObject，它和Map的使用方法一样（实现了Map接口），比如我们向其中存放几个数据： 12345678@RequestMapping(value = &quot;/index&quot;)public String index()&#123; JSONObject object = new JSONObject(); object.put(&quot;name&quot;, &quot;Alice&quot;); object.put(&quot;age&quot;, 18); System.out.println(object.toJSONString()); //以JSON格式输出JSONObject字符串 return &quot;index&quot;;&#125; 最后我们得到的结果为： 1&#123;&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 18&#125; 在test文件夹里面添加一个测试 123456789public class MsinTest &#123; @Test public void test() &#123; JSONObject object = new JSONObject(); object.put(&quot;list&quot;, Arrays.asList(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)); object.put(&quot;count&quot;,3); System.out.println(object.toJSONString()); &#125;&#125; 输出 实际上JSONObject就是对JSON数据的一种对象表示。同样的还有JSONArray，它表示一个数组，用法和List一样，数组中可以嵌套其他的JSONObject或是JSONArray： 1234567891011@RequestMapping(value = &quot;/index&quot;)public String index()&#123; JSONObject object = new JSONObject(); object.put(&quot;name&quot;, &quot;Alice&quot;); object.put(&quot;age&quot;, 18); JSONArray array = new JSONArray(); array.add(object); array.add(new JSONObject()); System.out.println(array.toJSONString()); return &quot;index&quot;;&#125; 得到的结果为： 当出现循环引用时，会按照以下语法来解析 我们可以也直接创建一个实体类，将实体类转换为JSON格式的数据： 12345678@RequestMapping(value = &quot;/index&quot;, produces = &quot;application/json&quot;)@ResponseBodypublic String data()&#123; Student student = new Student(); student.setUsername(&quot;Alice&quot;); student.setPassword(&quot;123456&quot;); return JSON.toJSONString(student);&#125; 输出 这里我们修改了produces的值，将返回的内容类型设定为application/json，表示服务器端返回了一个JSON格式的数据（当然不设置也行，也能展示，这样是为了规范）然后我们在方法上添加一个@ResponseBody表示方法返回（也可以在类上添加@RestController表示此Controller默认返回的是字符串数据）的结果不是视图名称而是直接需要返回一个字符串作为页面数据，这样，返回给浏览器的就是我们直接返回的字符串内容。 接着我们使用JSON工具类将其转换为JSON格式的字符串，打开浏览器，得到JSON格式数据。 SpringMVC非常智能，我们可以直接返回一个对象类型，它会被自动转换为JSON字符串格式： 12345678@RequestMapping(value = &quot;/data&quot;, produces = &quot;application/json&quot;)@ResponseBodypublic Student data()&#123; Student student = new Student(); student.setName(&quot;Alice&quot;); student.setAge(18); return student;&#125; 此时会报错 需要在配置类中添加一下FastJSON转换器（默认只支持JackSon）： 1234@Overridepublic void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; converters.add(new FastJsonHttpMessageConverter());&#125; AJAX请求前面我们讲解了如何向浏览器发送一个JSON格式的数据，那么我们现在来看看如何向服务器请求数据。 Ajax即Asynchronous Javascript And XML（异步JavaScript和XML），它的目标就是实现页面中的数据动态更新，而不是直接刷新整个页面，它是一个概念。 它在JQuery框架中有实现，因此我们直接导入JQuery（JQuery极大地简化了JS的开发，封装了很多内容，感兴趣的可以了解一下）： 1&lt;script src=&quot;https://code.jquery.com/jquery-3.1.1.min.js&quot;&gt;&lt;/script&gt; 修改一下前端页面： 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;https://code.jquery.com/jquery-3.1.1.min.js&quot;&gt;&lt;/script&gt; &lt;script th:src=&quot;@&#123;/static/test.js&#125;&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; 你好， &lt;span id=&quot;username&quot;&gt;&lt;/span&gt; 您的年龄是： &lt;span id=&quot;password&quot;&gt;&lt;/span&gt; &lt;button onclick=&quot;updateData()&quot;&gt;点我更新页面数据&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; 实现用户名称和年龄需要在我们点击按钮之后才会更新，编写JS： 12345678function updateData() &#123; //美元符.的方式来使用Ajax请求，这里使用的是get方式，第一个参数为请求的地址（注意需要带上Web应用程序名称），第二个参数为成功获取到数据的方法，data就是返回的数据内容 $.get(&quot;/mvc/data&quot;, function (data) &#123; //获取成功执行的方法 window.alert(&#x27;接受到异步请求数据：&#x27;+JSON.stringify(data)) //弹窗展示数据 $(&quot;#username&quot;).text(data.name) //这里使用了JQuery提供的选择器，直接选择id为username的元素，更新数据 $(&quot;#password&quot;).text(data.password) &#125;)&#125; 使用JQuery非常方便，通过JQuery的选择器就可以快速获取页面中的元素，注意这里获取的元素是被JQuery封装过的元素，需要使用JQuery提供的方法来进行操作。 这样，我们就实现了从服务端获取数据并更新到页面中（实际上之前，我们在JavaWeb阶段使用XHR请求也演示过，不过当时是纯粹的数据） 向服务端发送一个JS对象数据并进行解析： 12345678function submitData() &#123; $.post(&quot;/mvc/submit&quot;, &#123; //这里使用POST方法发送请求 name: &quot;测试&quot;, //第二个参数是要传递的对象，会以表单数据的方式发送 age: 18 &#125;, function (data) &#123; window.alert(JSON.stringify(data)) //发送成功执行的方法 &#125;)&#125; 服务器端只需要在请求参数位置添加一个对象接收即可（和前面是一样的，因为这里也是提交的表单数据）： 123456@RequestMapping(&quot;/submit&quot;)@ResponseBodypublic String submit(Student student)&#123; System.out.println(&quot;接收到前端数据：&quot;+student); return &quot;&#123;\\&quot;success\\&quot;: true&#125;&quot;;&#125; 还要修改一下覆盖函数，否则会报错 123456@Overridepublic void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter(); converter.setSupportedMediaTypes(Collections.singletonList(MediaType.APPLICATION_JSON)); converters.add(converter);&#125; 这样实现了前后端使用JSON字符串进行通信。 将js对象转换为JSON字符串的形式进行传输，这里需要使用ajax方法来处理： 1234567891011function submitData() &#123; $.ajax(&#123; //最基本的请求方式，需要自己设定一些参数 type: &#x27;POST&#x27;, //设定请求方法 url: &quot;/mvc/submit&quot;, //请求地址 data: JSON.stringify(&#123;name: &quot;测试&quot;, age: 18&#125;), //转换为JSON字符串进行发送 success: function (data) &#123; window.alert(JSON.stringify(data)) &#125;, contentType: &quot;application/json&quot; //请求头Content-Type一定要设定为JSON格式 &#125;)&#125; 读取前端发送给我们的JSON格式数据，那么这个时候就需要添加@RequestBody注解： 123456@RequestMapping(&quot;/submit&quot;)@ResponseBodypublic String submit(@RequestBody JSONObject object)&#123; System.out.println(&quot;接收到前端数据：&quot;+object); return &quot;&#123;\\&quot;success\\&quot;: true&#125;&quot;;&#125; 实现文件上传和下载利用SpringMVC，可以很轻松地实现文件上传和下载，同样的，我们只需要配置一个Resolver： 1234567@Bean(&quot;multipartResolver&quot;) //注意这里Bean的名称是固定的，必须是multipartResolverpublic CommonsMultipartResolver commonsMultipartResolver()&#123; CommonsMultipartResolver resolver = new CommonsMultipartResolver(); resolver.setMaxUploadSize(1024 * 1024 * 10); //最大10MB大小 resolver.setDefaultEncoding(&quot;UTF-8&quot;); //默认编码格式 return resolver;&#125; 直接编写Controller： 12345678@RequestMapping(value = &quot;/upload&quot;, method = RequestMethod.POST)@ResponseBodypublic String upload(@RequestParam CommonsMultipartFile file) throws IOException &#123; File fileObj = new File(&quot;test.html&quot;); file.transferTo(fileObj); System.out.println(&quot;用户上传的文件已保存到：&quot;+fileObj.getAbsolutePath()); return &quot;文件上传成功！&quot;;&#125; 使用CommonsMultipartFile对象来接收用户上传的文件。它是基于Apache的Commons-fileupload框架实现的，我们还需要导入一个依赖： 12345&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt; 最后在前端添加一个文件的上传点： 123456&lt;div&gt; &lt;form action=&quot;upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;file&quot;&gt; &lt;input type=&quot;submit&quot;&gt; &lt;/form&gt;&lt;/div&gt; 这样，点击提交之后，文件就会上传到服务器了。 下载其实和我们之前的写法大致一样，直接使用HttpServletResponse，并向输出流中传输数据即可。 1234567891011@RequestMapping(value = &quot;/download&quot;, method = RequestMethod.GET)@ResponseBodypublic void download(HttpServletResponse response)&#123; response.setContentType(&quot;multipart/form-data&quot;); try(OutputStream stream = response.getOutputStream(); InputStream inputStream = new FileInputStream(&quot;test.html&quot;))&#123; IOUtils.copy(inputStream, stream); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125;&#125; 在前端页面中添加一个下载点： 1&lt;a href=&quot;download&quot; download=&quot;test.html&quot;&gt;下载最新资源&lt;/a&gt; 解读DispatcherServlet源码到目前为止，关于SpringMVC的相关内容就学习得差不多了，但是我们在最后还是需要深入了解一下DispatcherServlet底层是如何进行调度的，因此，我们会从源码角度进行讲解。 首先我们需要找到DispatcherServlet的最顶层HttpServletBean，在这里直接继承的HttpServlet，那么我们首先来看一下，它在初始化方法中做了什么： 123456789101112131415161718192021public final void init() throws ServletException &#123; //读取配置参数，并进行配置 PropertyValues pvs = new HttpServletBean.ServletConfigPropertyValues(this.getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(this.getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, this.getEnvironment())); this.initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException var4) &#123; if (this.logger.isErrorEnabled()) &#123; this.logger.error(&quot;Failed to set bean properties on servlet &#x27;&quot; + this.getServletName() + &quot;&#x27;&quot;, var4); &#125; throw var4; &#125; &#125; //此初始化阶段由子类实现， this.initServletBean();&#125; 我们接着来看initServletBean()方法是如何实现的，它是在子类FrameworkServlet中定义的： 123456789101112131415161718protected final void initServletBean() throws ServletException &#123; this.getServletContext().log(&quot;Initializing Spring &quot; + this.getClass().getSimpleName() + &quot; &#x27;&quot; + this.getServletName() + &quot;&#x27;&quot;); if (this.logger.isInfoEnabled()) &#123; this.logger.info(&quot;Initializing Servlet &#x27;&quot; + this.getServletName() + &quot;&#x27;&quot;); &#125; long startTime = System.currentTimeMillis(); try &#123; //注意：我们在一开始说了SpringMVC有两个容器，一个是Web容器一个是根容器 //Web容器只负责Controller等表现层内容 //根容器就是Spring容器，它负责Service、Dao等，并且它是Web容器的父容器。 //初始化WebApplicationContext，这个阶段会为根容器和Web容器进行父子关系建立 this.webApplicationContext = this.initWebApplicationContext(); this.initFrameworkServlet(); &#125; catch (RuntimeException | ServletException var4) &#123; //...以下内容全是打印日志&#125; 我们来看看initWebApplicationContext是如何进行初始化的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected WebApplicationContext initWebApplicationContext() &#123; //这里获取的是根容器，一般用于配置Service、数据源等 WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(this.getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; //如果webApplicationContext在之前已经存在，则直接给到wac wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext)wac; if (!cwac.isActive()) &#123; if (cwac.getParent() == null) &#123; //设定根容器为Web容器的父容器 cwac.setParent(rootContext); &#125; this.configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; if (wac == null) &#123; //如果webApplicationContext是空，那么就从ServletContext找一下有没有初始化上下文 wac = this.findWebApplicationContext(); &#125; if (wac == null) &#123; //如果还是找不到，直接创个新的，并直接将根容器作为父容器 wac = this.createWebApplicationContext(rootContext); &#125; if (!this.refreshEventReceived) &#123; synchronized(this.onRefreshMonitor) &#123; //此方法由DispatcherServlet实现 this.onRefresh(wac); &#125; &#125; if (this.publishContext) &#123; String attrName = this.getServletContextAttributeName(); //把Web容器丢进ServletContext this.getServletContext().setAttribute(attrName, wac); &#125; return wac;&#125; 我们接着来看DispatcherServlet中实现的onRefresh()方法： 123456789101112131415161718192021222324@Overrideprotected void onRefresh(ApplicationContext context) &#123; initStrategies(context);&#125; protected void initStrategies(ApplicationContext context) &#123; //初始化各种解析器 initMultipartResolver(context); initLocaleResolver(context); initThemeResolver(context); //在容器中查找所有的HandlerMapping，放入集合中 //HandlerMapping保存了所有的请求映射信息（Controller中定义的），它可以根据请求找到处理器Handler，但并不是简单的返回处理器，而是将处理器和拦截器封装，形成一个处理器执行链（类似于之前的Filter） initHandlerMappings(context); //在容器中查找所有的HandlerAdapter，它用于处理请求并返回ModelAndView对象 //默认有三种实现HttpRequestHandlerAdapter，SimpleControllerHandlerAdapter和AnnotationMethodHandlerAdapter //当HandlerMapping找到处理请求的Controller之后，会选择一个合适的HandlerAdapter处理请求 //比如我们之前使用的是注解方式配置Controller，现在有一个请求携带了一个参数，那么HandlerAdapter会对请求的数据进行解析，并传入方法作为实参，最后根据方法的返回值将其封装为ModelAndView对象 initHandlerAdapters(context); //其他的内容 initHandlerExceptionResolvers(context); initRequestToViewNameTranslator(context); initViewResolvers(context); initFlashMapManager(context);&#125; DispatcherServlet初始化过程我们已经了解了，那么我们接着来看DispatcherServlet是如何进行调度的，首先我们的请求肯定会经过HttpServlet，然后其交给对应的doGet、doPost等方法进行处理，而在FrameworkServlet中，这些方法都被重写，并且使用processRequest来进行处理： 1234567protected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; this.processRequest(request, response);&#125;protected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; this.processRequest(request, response);&#125; 我们来看看processRequest做了什么： 123456789101112131415161718protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //前期准备工作 long startTime = System.currentTimeMillis(); Throwable failureCause = null; LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); LocaleContext localeContext = this.buildLocaleContext(request); RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes requestAttributes = this.buildRequestAttributes(request, response, previousAttributes); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new FrameworkServlet.RequestBindingInterceptor()); this.initContextHolders(request, localeContext, requestAttributes); try &#123; //重点在这里，这里进行了Service的执行，不过是在DispatcherServlet中定义的 this.doService(request, response); &#125; catch (IOException | ServletException var16) &#123; //...&#125; 请各位一定要耐心，这些大型框架的底层一般都是层层套娃，因为这样写起来层次会更加清晰，那么我们来看看DispatcherServlet中是如何实现的： 12345678protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //... try &#123; //重点在这里，这才是整个处理过程中最核心的部分 this.doDispatch(request, response); &#125; finally &#123; //...&#125; 终于找到最核心的部分了： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; try &#123; ModelAndView mv = null; Object dispatchException = null; try &#123; processedRequest = this.checkMultipart(request); multipartRequestParsed = processedRequest != request; //在HandlerMapping集合中寻找可以处理当前请求的HandlerMapping mappedHandler = this.getHandler(processedRequest); if (mappedHandler == null) &#123; this.noHandlerFound(processedRequest, response); //找不到HandlerMapping则无法进行处理 return; &#125; //根据HandlerMapping提供的信息，找到可以处理的HandlerAdapter HandlerAdapter ha = this.getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = HttpMethod.GET.matches(method); if (isGet || HttpMethod.HEAD.matches(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if ((new ServletWebRequest(request, response)).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; //执行所有拦截器的preHandle()方法 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; //使用HandlerAdapter进行处理（我们编写的请求映射方法在这个位置才真正地执行了） //HandlerAdapter会帮助我们将请求的数据进行处理，再来调用我们编写的请求映射方法 //最后HandlerAdapter会将结果封装为ModelAndView返回给mv mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; this.applyDefaultViewName(processedRequest, mv); //执行所有拦截器的postHandle()方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception var20) &#123; dispatchException = var20; &#125; catch (Throwable var21) &#123; dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, var21); &#125; //最后处理结果，对视图进行渲染等，如果抛出异常会出现错误页面 this.processDispatchResult(processedRequest, response, mappedHandler, mv, (Exception)dispatchException); &#125; catch (Exception var22) &#123; this.triggerAfterCompletion(processedRequest, response, mappedHandler, var22); &#125; catch (Throwable var23) &#123; this.triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(&quot;Handler processing failed&quot;, var23)); &#125; &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else if (multipartRequestParsed) &#123; this.cleanupMultipart(processedRequest); &#125; &#125;&#125; 所以，根据以上源码分析得出最终的流程图： 虽然完成本章学习后，我们已经基本能够基于Spring去重新编写一个更加高级的图书管理系统了，但是登陆验证复杂的问题依然没有解决，如果我们依然按照之前的方式编写登陆验证，显然太过简单，它仅仅只是一个登陆，但是没有任何的权限划分或是加密处理，我们需要更加高级的权限校验框架来帮助我们实现登陆操作，下一章，我们会详细讲解如何使用更加高级的SpringSecurity框架来进行权限验证，并在学习的过程中，重写我们的图书管理系统。","tags":["Spring","Java"],"categories":["Java","Spring"]},{"title":"Spring原理、JavaBean","path":"/Java/Spring/Spring/","content":"JavaBean有一定规范的Java实体类，类内提供了一些公共方法以便外界对该对象的内部属性进行操作 所有属性都是private，所有的属性都可以通过get&#x2F;set方法进行访问，同时还需要有一个无参构造（默认就有） 12345678910111213141516public class User&#123;\tprivate String name;\tprivate int age;\tpublic String getName()&#123; return name;\t&#125;\tpublic String getAge()&#123; return age;\t&#125;\tpublic void setName(String name)&#123; this.name = name;\t&#125;\tpublic void setAge(int age)&#123; this.age = age;\t&#125;&#125; IoC理论基础高内聚，低耦合是现代软件的开发的设计模式 之前编写的图书管理系统具有高耦合性，虽然体系逻辑清晰，流程也快，但是当要对一个功能进行修改时，很容易需要大量的时间进行修改；因此如果需要改善这种情况，只能对各个模块进行解耦，降低依赖性，也就是说，所有的实现类对象全部交给程序来管理，对象之间的关系也由程序来动态决定 IOC是Inversion of Control的缩写，翻译为：“控制反转”，把复杂系统分解成相互合作的对象，这些对象类通过封装以后，内部实现对外部是透明的，从而降低了解决问题的复杂度，而且可以灵活地被重用和扩展 可以将对象交给IoC容器进行管理，这时我们就只需要关心接口定义之类 使用IoC容器使用Spring的首要目的是为了使得软件项目进行解耦，而不是简化代码 Spring并不是一个独立的框架，实际上有很多模块 Spring是一个非入侵式的框架，就像一个工具库一样，因此，我们只需要直接导入其依赖就可以使用 使用Spring先导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.3.19&lt;/version&gt;&lt;/dependency&gt; 在resources目录中创建Spring配置文件 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;/beans&gt; 在主方法中编写 123public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;text&quot;); &#125; 注册JavaBean 写一个类之后，在配置文件中添加bean 1&lt;bean name=&quot;Student&quot; class=&quot;org.example.entity.Student&quot;/&gt; 之后在主方法中使用IoC容器生成 12345public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;); Student student = context.getBean(Student.class); //直接输入name也行 System.out.println(student);&#125; 输出：说明是可行的 这里得到的Student对象是由Spring通过反射机制进行创建 生命周期与继承生命周期1&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot;/&gt; name属性：也可以是id属性，全局唯一，不可出现重复的名称，我们发现，之前其实就是通过Bean的名称来向IoC容器索要对应的对象，也可以通过其他方式获取。 我们现在在主方法中连续获取两个对象： 123456789public class Main &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;); Student student = context.getBean(Student.class); Student student1 = (Student) context.getBean(&quot;Student&quot;); System.out.println(student); System.out.println(student1); &#125;&#125; 我们发现两次获取到的实际上是同一个对象 也就是说，默认情况下，通过IoC容器进行管理的JavaBean是单例模式的， 那么如何进行修改：只需要修改其作用域即可，添加scope属性： 1&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot; scope=&quot;prototype&quot;/&gt; 通过将其设定为prototype（原型模式）来使得其每次都会创建一个新的对象 观察一下这两种模式下Bean的生命周期，我们给构造方法添加一个输出： 12345678public class Student &#123; String name; int age; public Student()&#123; System.out.println(&quot;我被构造了！&quot;); &#125;&#125; 接着在mian方法中打上断点来查看对象分别是在什么时候被构造的 原型模式 prototype 每new一个对象，就构造一次 单例模式 singleton 在一开始的时候就进行构造 我们发现，当Bean的作用域为单例模式，那么它会在一开始就被创建，而处于原型模式下，只有在获取时才会被创建，也就是说，单例模式下，Bean会被IoC容器存储，只要容器没有被销毁，那么此对象将一直存在，而原型模式才是相当于直接new了一个对象，并不会被保存。 我们还可以通过配置文件，告诉创建一个对象需要执行此初始化方法，以及销毁一个对象的销毁方法： 123456789101112131415public class Student &#123; String name; int age; public Student() &#123; System.out.println(&quot;我被构造了&quot;); &#125; public void init() &#123; System.out.println(&quot;我是初始化&quot;); &#125; public void destroy() &#123; System.out.println(&quot;我是销毁方法&quot;); &#125;&#125; 123456public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;test.xml&quot;); Student student = (Student) context.getBean(&quot;student&quot;); System.out.println(student); context.close(); //手动销毁容器&#125; 最后在XML文件中编写配置： 1&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;/&gt; 看输出 我们还可以手动指定Bean的加载顺序，若某个Bean需要保证一定在另一个Bean加载之前加载，那么就可以使用depend-on属性 添加一个类 1234567891011121314public class teacher &#123; String name; int age; public teacher() &#123; System.out.println(&quot;老师被构造了&quot;); &#125; public void init() &#123; System.out.println(&quot;老师初始化&quot;); &#125; public void destroy() &#123; System.out.println(&quot;我是老师的销毁方法&quot;); &#125;&#125; 再添加配置文件：此处注意depend-on后跟的是name 最后输出 继承Bean之间也存在继承关系，是属性的继承 XML文件 虽然是继承但是也可以进行增删改，而不是完全继承 123456&lt;bean name=&quot;Art&quot; class=&quot;...&quot;&gt;\t&lt;property name=&quot;name&quot; value=&quot;Alice&quot;/&gt;&lt;/bean&gt;&lt;bean name=&quot;Sports&quot; class=&quot;...Sports&quot; parent=&quot;Art&quot;&gt;\t&lt;property name=&quot;id&quot; value=&quot;1&quot;/&gt;&lt;/bean&gt; 也可以将一个bean作为抽象的bean，此时就不能直接去获取，有点类似Java当中的抽象类 1&lt;bean name=&quot;Art&quot; class=&quot;...&quot; abstract=&quot;true&quot;&gt; 依赖注入 Dependency Injection将bean装配在一起的行为是基于依赖注入的模式实现的，此时，组件不会再去创建它所依赖的组件并管理它们的生命周期，使用依赖注入的应用依赖于单独的实体（容器）来创建和维护所有的组件，并将其注入到需要的bean中，通常通过构造器参数和属性访问（property accessor）方法来实现 基本类型注入实现向Bean的成员属性进行赋值，使用set方法+property标签来实现 123456789101112public class Student &#123; String name; int age; public void setName(String name) &#123; this.name = name; &#125; public void say()&#123; System.out.println(&quot;I&#x27;m &quot;+name); &#125;&#125; 在xml文件中设置 123&lt;bean name=&quot;Student&quot; class=&quot;org.example.entity.Student&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;Alice&quot;/&gt;&lt;/bean&gt; 最后设置主方法 12345public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;test.xml&quot;); Student student = (Student) context.getBean(&quot;student&quot;); student.say();&#125; 输出：发现属性被成功注入到对象当中 非基本类型注入如果成员类型是一个非基本类型的对象，应该这样注入 123456789101112@ToStringpublic class teacher &#123; String name; int age; public teacher() &#123; System.out.println(&quot;老师被构造了&quot;); &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; Student类 123456789101112131415161718192021@ToStringpublic class Student &#123; String name; int age; teacher t; public Student() &#123; System.out.println(&quot;我被构造了&quot;); &#125; public void setName(String name) &#123; this.name = name; &#125; public void setT(teacher t) &#123; this.t = t; &#125; public void say() &#123; System.out.println(&quot;I&#x27;m &quot; + name); &#125;&#125; 我们只需要将对应的类型也注册为bean即可，然后直接使用ref属性来进行引用： 看输出 集合注入需要在property内部进行编写： 123456789&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot;&gt; &lt;property name=&quot;list&quot;&gt; &lt;list&gt; &lt;value type=&quot;double&quot;&gt;100.0&lt;/value&gt; &lt;value type=&quot;double&quot;&gt;95.0&lt;/value&gt; &lt;value type=&quot;double&quot;&gt;92.5&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 就可以直接以一个数组的方式将属性注入，注意如果是List类型的话，可以使用array数组。如果是一个Map类型，也可以使用entry来注入： 12345678910111213public class Student &#123; String name; int age; Map&lt;String, Double&gt; map; public void setMap(Map&lt;String, Double&gt; map) &#123; this.map = map; &#125; public void say()&#123; System.out.println(&quot;我的成绩：&quot;+ map); &#125;&#125; 123456789&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot;&gt; &lt;property name=&quot;map&quot;&gt; &lt;map&gt; &lt;entry key=&quot;语文&quot; value=&quot;100.0&quot;/&gt; &lt;entry key=&quot;数学&quot; value=&quot;80.0&quot;/&gt; &lt;entry key=&quot;英语&quot; value=&quot;92.5&quot;/&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; 自动装配注入使用自动装配来实现属性值的注入： 12&lt;bean name=&quot;card&quot; class=&quot;com.test.bean.Card&quot;/&gt;&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot; autowire=&quot;byType&quot;/&gt; 自动装配会根据set方法中需要的类型，自动在容器中查找是否存在对应类型或是对应名称以及对应构造方法的Bean，比如我们上面指定的为byType，那么其中的card属性就会被自动注入类型为Card的Bean 我们已经了解了如何使用set方法来创建对象，那么能否不使用默认的无参构造方法，而是指定一个有参构造进行对象的创建呢？我们可以指定构造方法： 1234&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot;&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;小明&quot;/&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;18&quot;/&gt; &lt;/bean&gt; 12345678910111213public class Student &#123; String name; int age; public Student(String name, int age)&#123; this.name = name; this.age = age; &#125; public void say()&#123; System.out.println(&quot;我是：&quot;+name+&quot;今年&quot;+age+&quot;岁了！&quot;); &#125;&#125; 通过手动指定构造方法参数，就可以直接告诉容器使用哪一个构造方法来创建对象 面向切面AOPAOP思想实际上就是：在运行时，动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程。也就是说，我们可以使用AOP来帮助我们在方法执行前或执行之后，做一些额外的操作，实际上，就是代理！ 通过AOP我们可以在保证原有业务不变的情况下，添加额外的动作，比如我们的某些方法执行完成之后，需要打印日志，那么这个时候，我们就可以使用AOP来帮助我们完成，它可以批量地为这些方法添加动作。可以说，它相当于将我们原有的方法，在不改变源代码的基础上进行了增强处理。 相当于我们的整个业务流程，被直接斩断，并在断掉的位置添加了一个额外的操作，再连接起来，也就是在一个切点位置插入内容。它的原理实际上就是通过动态代理机制实现的，我们在JavaWeb阶段已经给大家讲解过动态代理了。不过Spring底层并不是使用的JDK提供的动态代理，而是使用的第三方库实现，它能够以父类的形式代理，而不是接口 使用SpringAOPSpring是支持AOP编程的框架之一（实际上它整合了AspectJ框架的一部分），要使用AOP我们需要先导入一个依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.3.13&lt;/version&gt;&lt;/dependency&gt; 那么，如何使用AOP呢？首先我们要明确，要实现AOP操作，我们需要知道这些内容： 需要切入的类，类的哪个方法需要被切入 切入之后需要执行什么动作 是在方法执行前切入还是在方法执行后切入 如何告诉Spring需要进行切入 那么我们依次来看，首先需要解决的问题是，找到需要切入的类： 12345678910public class Student &#123; String name; int age; //分别在test方法执行前后切入 public int test(String str) &#123; System.out.println(&quot;我是一个测试方法：&quot;+str); return str.length(); &#125;&#125; 现在我们希望在test方法执行前后添加我们的额外执行的内容，接着，我们来看看如何为方法执行前和执行后添加切入动作。比如现在我们想在方法返回之后，再执行我们的动作，首先定义我们要执行的操作： 123456789101112public class AopTest &#123; //执行之后的方法 public void after()&#123; System.out.println(&quot;我是执行之后&quot;); &#125; //执行之前的方法 public void before()&#123; System.out.println(&quot;我是执行之前&quot;); &#125;&#125; 那么，现在如何告诉Spring我们需要在方法执行之前和之后插入其他逻辑呢？首先我们将要进行AOP操作的类注册为Bean： 12&lt;bean name=&quot;student&quot; class=&quot;com.test.bean.Student&quot;/&gt;&lt;bean name=&quot;aopTest&quot; class=&quot;com.test.aop.AopTest&quot;/&gt; 一个是Student类，还有一个就是包含我们要切入方法的AopTest类，注册为Bean后，他们就交给Spring进行管理，这样Spring才能帮助我们完成AOP操作。 接着，我们需要告诉Spring，我们需要添加切入点，首先将顶部修改为，引入aop相关标签： 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; 通过使用aop:config来添加一个新的AOP配置： 123&lt;aop:config&gt; &lt;/aop:config&gt; 首先第一行，我们需要告诉Spring，我们要切入的是哪一个类的哪个或是哪些方法： 1&lt;aop:pointcut id=&quot;test&quot; expression=&quot;execution(* com.test.bean.Student.say())&quot;/&gt; 其中，expression属性的execution填写格式如下： 1修饰符 包名.类名.方法名称(方法参数) 修饰符：public、protected、private、包括返回值类型、static等等（使用*代表任意修饰符） 包名：如com.test（*代表全部，比如com.*代表com包下的全部包） 类名：使用*也可以代表包下的所有类 方法名称：可以使用*代表全部方法 方法参数：填写对应的参数即可，比如(String, String)，也可以使用*来代表任意一个参数，使用..代表所有参数 也可以使用其他属性来进行匹配，比如@annotation可以用于表示标记了哪些注解的方法被切入 接着，为此方法添加一个执行前动作和一个执行后动作： 1234&lt;aop:aspect ref=&quot;aopTest&quot;&gt; &lt;aop:before method=&quot;before&quot; pointcut-ref=&quot;test&quot;/&gt; &lt;aop:after-returning method=&quot;after&quot; pointcut-ref=&quot;test&quot;/&gt;&lt;/aop:aspect&gt; 最后总设置 现在来实验一下吧： 12345678public class Main &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring.xml&quot;); Student student = context.getBean(Student.class); student.say(); context.close(); &#125;&#125; 输出 我们发现，方法执行前后，分别调用了对应的方法。但是仅仅这样还是不能满足一些需求，在某些情况下，我们可以需求方法执行的一些参数，比如方法执行之后返回了什么，或是方法开始之前传入了什么参数等等。 这个时候，可以为切入的方法添加一个参数，通过此参数就可以快速获取切点位置的一些信息： 123456//执行之前的方法public void before(JoinPoint point)&#123; System.out.println(&quot;我是执行之前&quot;); System.out.println(point.getTarget()); //获取执行方法的对象 System.out.println(Arrays.toString(point.getArgs())); //获取传入方法的实参&#125; 通过添加JoinPoint作为形参，Spring会自动给我们一个实现类对象，这样我们就能获取方法的一些信息了。 环绕方法环绕方法相当于完全代理了此方法，它完全将此方法包含在中间，需要手动调用才可以执行此方法，并且可以直接获取更多的参数： 123456public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println(&quot;方法开始之前&quot;); Object value = joinPoint.proceed(); //如果没有此语句，则指定方法不会被调用 System.out.println(&quot;方法执行完成，结果为：&quot;+value); return value;&#125; 注意，如果代理方法存在返回值，那么环绕方法也需要有一个返回值，通过proceed方法来执行代理的方法，也可以修改参数之后调用proceed(Object[])，使用我们给定的参数再去执行： 1234567public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println(&quot;方法开始之前&quot;); String arg = joinPoint.getArgs()[0] + &quot;lailou&quot;; Object value = joinPoint.proceed(new Object[]&#123;arg&#125;); System.out.println(&quot;方法执行完成，结果为：&quot;+value); return value;&#125; 使用接口实现AOP如何使用Advice实现AOP 它与之前学习的动态代理更接近一些，比如在方法开始执行之前或是执行之后会去调用实现的接口，首先需要将一个类实现Advice接口，只有实现此接口，才可以被通知，比如这里使用MethodBeforeAdvice表示是一个在方法执行之前的动作： 123456public class AopTest implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;通过Advice实现AOP&quot;); &#125;&#125; 我们发现，方法中包括了很多的参数，其中args代表的是方法执行前得到的实参列表，还有target表示执行此方法的实例对象。运行之后，效果和之前是一样的，但是在这里我们就可以快速获取到更多信息。 1234&lt;aop:config&gt; &lt;aop:pointcut id=&quot;stu&quot; expression=&quot;execution(* com.test.bean.Student.say(String))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;before&quot; pointcut-ref=&quot;stu&quot;/&gt;&lt;/aop:config&gt; 除了此接口以外，还有其他的接口，比如AfterReturningAdvice就需要实现一个方法执行之后的操作： 1234567891011public class AopTest implements MethodBeforeAdvice, AfterReturningAdvice &#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;我是方法执行之前！&quot;); &#125; @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;我是方法执行之后！&quot;); &#125;&#125; AOP 领域中的特性术语： 通知（Advice）: AOP 框架中的增强处理，通知描述了切面何时执行以及如何执行增强处理，也就是我们上面编写的方法实现。 连接点（join point）: 连接点表示应用执行过程中能够插入切面的一个点，这个点可以是方法的调用、异常的抛出，实际上就是我们在方法执行前或是执行后需要做的内容。 切点（PointCut）: 可以插入增强处理的连接点，可以是方法执行之前也可以方法执行之后，还可以是抛出异常之类的。 切面（Aspect）: 切面是通知和切点的结合，我们之前在xml中定义的就是切面，包括很多信息。 引入（Introduction）：引入允许我们向现有的类添加新的方法或者属性。 织入（Weaving）: 将增强处理添加到目标对象中，并创建一个被增强的对象，我们之前都是在将我们的增强处理添加到目标对象，也就是织入（这名字挺有文艺范的） 使用注解开发好处：更强的类型安全性和更好的重构能力 注解实现配置文件那么，现在既然不使用XML文件了，那通过注解的方式就只能以实体类的形式进行配置了，给作为配置的类上添加@Configuration注解，先创建一个新的类MainConfiguration： @Configuration 注解会告知Spring这是一个配置类，会为Spring上下文提供bean 1234@Configurationpublic class MainConfiguration &#123; //没有配置任何Bean&#125; 可以看作： 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!-- 没有配置任何Bean --&gt;&lt;/beans&gt; Bean配置 之前我们是直接在配置文件中编写Bean的一些信息，现在在配置类中，我们只需要编写一个方法，并返回我们要创建的Bean的对象即可，并在其上方添加@Bean注解： @Bean注解表明这些方法所返回的对象会以Bean的形式添加到 Spring的应用上下文，默认情况下，bean所对应的bean ID与定义它们的方法名称是相同的 1234@Bean //如果想设置别名，则使用 @Bean(&quot;card&quot;)public Card card()&#123; return new Card();&#125; 这样，等价于： 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean class=&quot;com.test.bean.Card&quot;&gt;&lt;/bean&gt;&lt;/beans&gt; 指定作用域 还可以继续添加@Scope注解来指定作用域，例如： 12345@Bean @Scope(&quot;prototype&quot;)public Card card()&#123; return new Card();&#125; 采用这种方式，可以更加方便地控制一个Bean对象的创建过程，相当于这个对象时由我们创建好了再交给Spring进行后续处理，我们可以在对象创建时做很多额外的操作，包括一些属性值的配置等 加载配置类 既然现在我们已经创建好了配置类，接着我们就可以在主方法中加载此配置类，并创建一个基于配置类的容器： 123456789public class Main &#123; public static void main(String[] args) &#123; //使用AnnotationConfigApplicationContext来实现注解配置 AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfiguration.class); //这里需要告诉Spring哪个类作为配置类 Card card = context.getBean(Card.class); //容器用法和之前一样 System.out.println(card); &#125;&#125; 在配置的过程中，我们可以点击IDEA底部的Spring标签，打开后可以对当前向容器中注册的Bean进行集中查看，并且会标注Bean之间的依赖关系 Bean的默认名称实际上就是首字母小写的方法名称，可以手动指定： 12345@Bean(&quot;test&quot;)@Scope(&quot;prototype&quot;)public Card card()&#123; return new Card();&#125; 还可以直接在类上添加@Component注解来将一个类进行注册（现在最常用的方式），不过要实现这样的方式，我们需要添加一个自动扫描 在配置类上添加一个@ComponentScan注解，也可以使用@ComponentScans来批量添加。这里演示将bean包下的所有类进行扫描： 12345@ComponentScan(&quot;com.test.bean&quot;) //表示扫描bean目录中的所有@Configurationpublic class MainConfiguration &#123;&#125; 现在删除类中的Bean定义，我们在Student类的上面添加@Component注解，来表示此类型需要作为Bean交给容器进行管理： 1234567@Component@Scope(&quot;prototype&quot;)public class Student &#123; String name; int age; Card card;&#125; 同样的，在类上也可以直接添加@Scope来限定作用域。 效果和刚刚实际上是相同的，我们可以来测试一下： 123456public class Main &#123; public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfiguration.class); System.out.println(context.getBean(Student.class)); &#125;&#125; 我们可以看到IDEA的Spring板块中也显示了我们刚刚通过直接在类上添加@Component声明的Bean。 与@Component同样效果的还有@Controller、@Service和@Repository 现在我们就有两种方式注册一个Bean了，那么如何实现像之前一样的自动注入呢，比如我们将Card也注册为Bean，我们希望Spring自动将其注入到Student的属性中： 123456@Componentpublic class Student &#123; String name; int sid; Card card;&#125; 因此，我们可以将此类型，也通过这种方式注册为一个Bean： 1234@Component@Scope(&quot;prototype&quot;)public class Card &#123;&#125; 在需要注入的位置，添加一个@Resource注解来实现自动装配： 12345678@Componentpublic class Student &#123; String name; int sid; @Resource Card card;&#125; 这样的好处是，完全不需要创建任何的set方法，只需要添加这样的一个注解就可以了，Spring会跟之前配置文件的自动注入一样，在整个容器中进行查找，并将对应的Bean实例对象注入到此属性中，当然，如果还是需要通过set方法来注入，可以将注解添加到方法上： 123456789101112@Componentpublic class Student &#123; String name; int sid; Card card; @Resource public void setCard(Card card) &#123; System.out.println(&quot;通过方法&quot;); this.card = card; &#125;&#125; 除了使用@Resource以外，我们还可以使用@Autowired（IDEA不推荐将其使用在字段上，会出现黄标，但是可以放在方法或是构造方法上），它们的效果是一样的，但是它们存在区别，虽然它们都是自动装配： @Resource默认ByName如果找不到则ByType，可以添加到set方法、字段上。 @Autowired默认是byType，可以添加在构造方法、set方法、字段、方法参数上。 并且@Autowired可以配合@Qualifier使用，来指定一个名称的Bean进行注入： 123456@Autowired@Qualifier(&quot;sxc&quot;)public void setCard(Card card) &#123; System.out.println(&quot;通过方法&quot;); this.card = card;&#125; 如果Bean是在配置文件中进行定义的，我们还可以在方法的参数中使用@Autowired来进行自动注入： 1234567891011@ComponentScan(&quot;com.test.bean&quot;)@Configurationpublic class MainConfiguration &#123; @Bean public Student student(@Autowired Card card)&#123; Student student = new Student(); student.setCard(card); return student; &#125;&#125; 我们还可以通过@PostConstruct注解来添加构造后执行的方法，它等价于之前讲解的init-method： 1234@PostConstructpublic void init()&#123; System.out.println(&quot;我是初始化方法！1&quot;);&#125; 注意它们的顺序：Constructor(构造方法) -&gt; @Autowired(依赖注入) -&gt; @PostConstruct 同样的，如果需要销毁方法，也可以使用@PreDestroy注解，这里就不做演示了。 这样，两种通过注解进行Bean声明的方式就讲解完毕了，那么什么时候该用什么方式去声明呢？ 如果要注册为Bean的类是由其他框架提供，我们无法修改其源代码，那么我们就使用第一种方式进行配置。 如果要注册为Bean的类是我们自己编写的，我们就可以直接在类上添加注解，并在配置中添加扫描。 注解实现AOP操作首先在主类添加@EnableAspectJAutoProxy注解，开启AOP注解支持： 12345@EnableAspectJAutoProxy@ComponentScan(&quot;com.test.bean&quot;)@Configurationpublic class MainConfiguration &#123;&#125; 接着在定义AOP增强操作的类上添加@Aspect注解和@Component将其注册为Bean，如同之前在配置文件中也要将其注册为Bean： 12345@Component@Aspectpublic class AopTest &#123;&#125; 接着，在里面编写方法，并将此方法添加到一个切点中，比如我们希望在Student的test方法执行之前执行我们的方法： 1234public int test(String str)&#123; System.out.println(&quot;我被调用了:&quot;+str); return str.length();&#125; 只需要添加@Before注解即可： 1234@Before(&quot;execution(* com.test.bean.Student.test(..))&quot;)public void before()&#123; System.out.println(&quot;我是之前执行的内容！&quot;);&#125; 同样的，为其添加JoinPoint参数来获取切入点信息： 12345@Before(&quot;execution(* com.test.bean.Student.test(..))&quot;)public void before(JoinPoint point)&#123; System.out.println(&quot;参数列表：&quot;+ Arrays.toString(point.getArgs())); System.out.println(&quot;我是之前执行的内容！&quot;);&#125; 使用@AfterReturning注解来指定方法返回后的操作： 1234@AfterReturning(value = &quot;execution(* com.test.bean.Student.test(..))&quot;, returning = &quot;returnVal&quot;)public void after(Object returnVal)&#123; System.out.println(&quot;方法已返回，结果为：&quot;+returnVal);&#125; 指定returning属性，并将其作为方法某个参数的实参。同样的，环绕也可以直接通过注解声明： 1234567@Around(&quot;execution(* com.test.bean.Student.test(..))&quot;)public Object around(ProceedingJoinPoint point) throws Throwable &#123; System.out.println(&quot;方法执行之前！&quot;); Object val = point.proceed(); System.out.println(&quot;方法执行之后！&quot;); return val;&#125; 其他注解配置配置文件可能不止一个，我们有可能会根据模块划分，定义多个配置文件，这个时候，可能会出现很多个配置类，如果我们需要@Import注解来快速将某个类加入到容器中，比如我们现在创建一个新的配置文件，并将数据库Bean也搬过去： 123456789public class Test2Configuration &#123; @Bean public Connection getConnection() throws SQLException &#123; System.out.println(&quot;创建新的连接！&quot;); return DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/study&quot;, &quot;root&quot;, &quot;root&quot;); &#125;&#125; 1234567891011121314@EnableAspectJAutoProxy@Configuration@ComponentScan(&quot;com.test&quot;)@Import(Test2Configuration.class) //可以强制注册为一个Beanpublic class TestConfiguration &#123; @Resource Connection connection; @PostConstruct public void init()&#123; System.out.println(connection); &#125;&#125; 注意另一个配置类并没有添加任何注解，实际上，相当于导入的类被强制注册为了一个Bean，到现在，我们一共了解了三种注册为Bean的方式，利用这种特性，我们还可以将其他的类型也强制注册为Bean： 12345678910111213141516@EnableAspectJAutoProxy@Configuration@ComponentScan(&quot;com.test&quot;)@Import(&#123;Test2Configuration.class, Date.class&#125;)public class TestConfiguration &#123; @Resource Connection connection; @Resource Date date; @PostConstruct public void init()&#123; System.out.println(date+&quot; -&gt; &quot;+connection); &#125;&#125; 日期直接作为一个Bean放入到IoC容器中，并且时间永远都是被new的那个时间，也就是同一个对象（因为默认是单例模式） 通过@Import方式最主要为了实现的目标并不是创建Bean，而是为了方便一些框架的Registrar进行Bean定义 深入Mybatis框架学习了Spring之后，已经了解如何将一个类作为Bean交由IoC容器管理，也就是说，现在可以通过更方便的方式来使用Mybatis框架，可以直接把SqlSessionFactory、Mapper交给Spring进行管理，并且可以通过注入的方式快速地使用它们。 了解数据源在之前，我们如果需要创建一个JDBC的连接，那么必须使用DriverManager.getConnection()来创建连接，连接建立后，我们才可以进行数据库操作。 而学习了Mybatis之后，我们就不用再去使用DriverManager为我们提供连接对象，而是直接使用Mybatis为我们提供的SqlSessionFactory工具类来获取对应的SqlSession通过会话对象去操作数据库。 那么，它到底是如何封装JDBC的呢？看Mybatis的源码： 123public SqlSession openSession(boolean autoCommit) &#123; return this.openSessionFromDataSource(this.configuration.getDefaultExecutorType(), (TransactionIsolationLevel)null, autoCommit);&#125; 在通过SqlSessionFactory调用openSession方法之后，它调用了内部的一个私有的方法openSessionFromDataSource，我们接着来看，这个方法里面定义了什么内容： 12345678910111213141516171819202122232425private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; DefaultSqlSession var8; try &#123; //获取当前环境（由配置文件映射的对象实体） Environment environment = this.configuration.getEnvironment(); //事务工厂（暂时不提，下一板块讲解） TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment); //配置文件中：&lt;transactionManager type=&quot;JDBC&quot;/&gt; //生成事务（根据我们的配置，会默认生成JdbcTransaction），这里是关键，我们看到这里用到了environment.getDataSource()方法 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //执行器，包括全部的数据库操作方法定义，本质上是在使用执行器操作数据库，需要传入事务对象 Executor executor = this.configuration.newExecutor(tx, execType); //封装为SqlSession对象 var8 = new DefaultSqlSession(this.configuration, executor, autoCommit); &#125; catch (Exception var12) &#123; this.closeTransaction(tx); throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + var12, var12); &#125; finally &#123; ErrorContext.instance().reset(); &#125; return var8;&#125; 也就是说，我们的数据源配置信息，存放在了Transaction对象中，那么现在我们只需要知道执行器到底是如何执行SQL语句的，我们就知道到底如何创建Connection对象了，就需要获取数据库的链接信息了，那么我们来看看，这个DataSource到底是个什么： 1234567public interface DataSource extends CommonDataSource, Wrapper &#123; Connection getConnection() throws SQLException; Connection getConnection(String username, String password) throws SQLException;&#125; 我们发现，它是在javax.sql定义的一个接口，它包括了两个方法，都是用于获取连接的。因此，现在我们可以断定，并不是通过之前DriverManager的方法去获取连接了，而是使用DataSource的实现类来获取的，因此，也就正式引入到我们这一节的话题了： 数据库链接的建立和关闭是极其耗费系统资源的操作，通过DriverManager获取的数据库连接，一个数据库连接对象均对应一个物理数据库连接，每次操作都打开一个物理连接，使用完后立即关闭连接，频繁的打开、关闭连接会持续消耗网络资源，造成整个系统性能的低下。 因此，JDBC为我们定义了一个数据源的标准，也就是DataSource接口，告诉数据源数据库的连接信息，并将所有的连接全部交给数据源进行集中管理，当需要一个Connection对象时，可以向数据源申请，数据源会根据内部机制，合理地分配连接对象给我们。 一般比较常用的DataSource实现，都是采用池化技术，就是在一开始就创建好N个连接，这样之后使用就无需再次进行连接，而是直接使用现成的Connection对象进行数据库操作。 当然，也可以使用传统的即用即连的方式获取Connection对象，Mybatis为我们提供了几个默认的数据源实现，我们之前一直在使用的是官方的默认配置，也就是池化数据源： 123456&lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;$&#123;driver&#125;&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt; &lt;/dataSource&gt; 一共三个选项： UNPOOLED 不使用连接池的数据源 POOLED 使用连接池的数据源 JNDI 使用JNDI实现的数据源 解读Mybatis数据源实现非池化的数据源实现先看不使用池化的数据源实现，它叫做UnpooledDataSource，源码： 1234567891011public class UnpooledDataSource implements DataSource &#123; private ClassLoader driverClassLoader; private Properties driverProperties; private static Map&lt;String, Driver&gt; registeredDrivers = new ConcurrentHashMap(); private String driver; private String url; private String username; private String password; private Boolean autoCommit; private Integer defaultTransactionIsolationLevel; private Integer defaultNetworkTimeout; 首先这个类中定义了很多的成员，包括数据库的连接信息、数据库驱动信息、事务相关信息等。 我们接着来看，它是如何实现DataSource中提供的接口的： 1234567public Connection getConnection() throws SQLException &#123; return this.doGetConnection(this.username, this.password);&#125;public Connection getConnection(String username, String password) throws SQLException &#123; return this.doGetConnection(username, password);&#125; 实际上，这两个方法都指向了内部的一个doGetConnection方法，那么我们接着来看： 12345678910111213141516private Connection doGetConnection(String username, String password) throws SQLException &#123; Properties props = new Properties(); if (this.driverProperties != null) &#123; props.putAll(this.driverProperties); &#125; if (username != null) &#123; props.setProperty(&quot;user&quot;, username); &#125; if (password != null) &#123; props.setProperty(&quot;password&quot;, password); &#125; return this.doGetConnection(props);&#125; 首先它将数据库的连接信息也给添加到Properties对象中进行存放，并交给下一个doGetConnection来处理，接着来看下一层源码： 123456789private Connection doGetConnection(Properties properties) throws SQLException &#123; //若未初始化驱动，需要先初始化，内部维护了一个Map来记录初始化信息 this.initializeDriver(); //传统的获取连接的方式 Connection connection = DriverManager.getConnection(this.url, properties); //对连接进行额外的一些配置 this.configureConnection(connection); return connection;&#125; 到这里，就返回Connection对象了，而此对象正是通过DriverManager来创建的，因此，非池化的数据源实现依然使用的是传统的连接创建方式 池化的数据源实现接着来看池化的数据源实现，它是PooledDataSource类： 12345678910111213public class PooledDataSource implements DataSource &#123; private static final Log log = LogFactory.getLog(PooledDataSource.class); private final PoolState state = new PoolState(this); private final UnpooledDataSource dataSource; protected int poolMaximumActiveConnections = 10; protected int poolMaximumIdleConnections = 5; protected int poolMaximumCheckoutTime = 20000; protected int poolTimeToWait = 20000; protected int poolMaximumLocalBadConnectionTolerance = 3; protected String poolPingQuery = &quot;NO PING QUERY SET&quot;; protected boolean poolPingEnabled; protected int poolPingConnectionsNotUsedFor; private int expectedConnectionTypeCode; 我们发现，在这里的定义就比非池化的实现复杂得多了，因为它还要考虑并发的问题，并且还要考虑如何合理地存放大量的链接对象，该如何进行合理分配 首先注意，它存放了一个UnpooledDataSource，此对象是在构造时就被创建，其实创建Connection还是依靠数据库驱动创建，来看看它是如何实现接口方法的： 1234567public Connection getConnection() throws SQLException &#123; return this.popConnection(this.dataSource.getUsername(), this.dataSource.getPassword()).getProxyConnection();&#125;public Connection getConnection(String username, String password) throws SQLException &#123; return this.popConnection(username, password).getProxyConnection();&#125; 可以看到，它调用了popConnection()方法来获取连接对象，然后进行了一个代理，我们可以猜测，有可能整个连接池就是一个类似于栈的集合类型结构实现的。那么我们接着来看看popConnection方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129private PooledConnection popConnection(String username, String password) throws SQLException &#123; boolean countedWait = false; //返回的是PooledConnection对象， PooledConnection conn = null; long t = System.currentTimeMillis(); int localBadConnectionCount = 0; while(conn == null) &#123; synchronized(this.state) &#123; //加锁，因为有可能很多个线程都需要获取连接对象 PoolState var10000; //PoolState存了两个List，一个是空闲列表，一个是活跃列表 if (!this.state.idleConnections.isEmpty()) &#123; //有空闲连接时，可以直接分配Connection conn = (PooledConnection)this.state.idleConnections.remove(0); //ArrayList中取第一个元素 if (log.isDebugEnabled()) &#123; log.debug(&quot;Checked out connection &quot; + conn.getRealHashCode() + &quot; from pool.&quot;); &#125; //如果已经没有多余的连接可以分配，那么就检查一下活跃连接数是否达到最大的分配上限，如果没有，就new一个 &#125; else if (this.state.activeConnections.size() &lt; this.poolMaximumActiveConnections) &#123; //注意new了之后并没有立即往List里面塞，只是存了一些基本信息 //我们发现，这里依靠UnpooledDataSource创建了一个Connection对象，并将其封装到PooledConnection中 conn = new PooledConnection(this.dataSource.getConnection(), this); if (log.isDebugEnabled()) &#123; log.debug(&quot;Created connection &quot; + conn.getRealHashCode() + &quot;.&quot;); &#125; //以上条件都不满足，那么只能从之前的连接中寻找了，看看有没有那种卡住的链接（由于网络问题有可能之前的连接一直被卡住，然而正常情况下早就结束并且可以使用了，所以这里相当于是优化也算是一种捡漏的方式） &#125; else &#123; //获取最早创建的连接 PooledConnection oldestActiveConnection = (PooledConnection)this.state.activeConnections.get(0); long longestCheckoutTime = oldestActiveConnection.getCheckoutTime(); //判断是否超过最大的使用时间 if (longestCheckoutTime &gt; (long)this.poolMaximumCheckoutTime) &#123; //超时统计信息（不重要） ++this.state.claimedOverdueConnectionCount; var10000 = this.state; var10000.accumulatedCheckoutTimeOfOverdueConnections += longestCheckoutTime; var10000 = this.state; var10000.accumulatedCheckoutTime += longestCheckoutTime; //从活跃列表中移除此链接信息 this.state.activeConnections.remove(oldestActiveConnection); //如果开启事务，还需要回滚一下 if (!oldestActiveConnection.getRealConnection().getAutoCommit()) &#123; try &#123; oldestActiveConnection.getRealConnection().rollback(); &#125; catch (SQLException var15) &#123; log.debug(&quot;Bad connection. Could not roll back&quot;); &#125; &#125; //这里就根据之前的连接对象直接new一个新的连接（注意使用的还是之前的Connection对象，只是被重新封装了） conn = new PooledConnection(oldestActiveConnection.getRealConnection(), this); conn.setCreatedTimestamp(oldestActiveConnection.getCreatedTimestamp()); conn.setLastUsedTimestamp(oldestActiveConnection.getLastUsedTimestamp()); //过期 oldestActiveConnection.invalidate(); if (log.isDebugEnabled()) &#123; log.debug(&quot;Claimed overdue connection &quot; + conn.getRealHashCode() + &quot;.&quot;); &#125; &#125; else &#123; //确实是没得用了，只能卡住了（阻塞） //然后记录一下有几个线程在等待当前的任务搞完 try &#123; if (!countedWait) &#123; ++this.state.hadToWaitCount; countedWait = true; &#125; if (log.isDebugEnabled()) &#123; log.debug(&quot;Waiting as long as &quot; + this.poolTimeToWait + &quot; milliseconds for connection.&quot;); &#125; long wt = System.currentTimeMillis(); this.state.wait((long)this.poolTimeToWait); //要是超过等待时间还是没等到，只能放弃 //注意这样的话con就为null了 var10000 = this.state; var10000.accumulatedWaitTime += System.currentTimeMillis() - wt; &#125; catch (InterruptedException var16) &#123; break; &#125; &#125; &#125; //经过之前的操作，已经成功分配到连接对象的情况下 if (conn != null) &#123; if (conn.isValid()) &#123; //是否有效 if (!conn.getRealConnection().getAutoCommit()) &#123; //清理之前遗留的事务操作 conn.getRealConnection().rollback(); &#125; conn.setConnectionTypeCode(this.assembleConnectionTypeCode(this.dataSource.getUrl(), username, password)); conn.setCheckoutTimestamp(System.currentTimeMillis()); conn.setLastUsedTimestamp(System.currentTimeMillis()); //添加到活跃表中 this.state.activeConnections.add(conn); //统计信息（不重要） ++this.state.requestCount; var10000 = this.state; var10000.accumulatedRequestTime += System.currentTimeMillis() - t; &#125; else &#123; //无效的连接，直接抛异常 if (log.isDebugEnabled()) &#123; log.debug(&quot;A bad connection (&quot; + conn.getRealHashCode() + &quot;) was returned from the pool, getting another connection.&quot;); &#125; ++this.state.badConnectionCount; ++localBadConnectionCount; conn = null; if (localBadConnectionCount &gt; this.poolMaximumIdleConnections + this.poolMaximumLocalBadConnectionTolerance) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;PooledDataSource: Could not get a good connection to the database.&quot;); &#125; throw new SQLException(&quot;PooledDataSource: Could not get a good connection to the database.&quot;); &#125; &#125; &#125; &#125; &#125; //最后该干嘛干嘛，拿不到连接直接抛异常 if (conn == null) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;PooledDataSource: Unknown severe error condition. The connection pool returned a null connection.&quot;); &#125; throw new SQLException(&quot;PooledDataSource: Unknown severe error condition. The connection pool returned a null connection.&quot;); &#125; else &#123; return conn; &#125;&#125; 经过上面一顿猛如虎的操作之后，我们可以得到以下信息： 如果最后得到了连接对象（有可能是从空闲列表中得到，有可能是直接创建的新的，还有可能是经过回收策略回收得到的），那么连接(Connection)对象一定会被放在活跃列表中(state.activeConnections) 获取一个链接会直接进入到活跃列表中，那么，如果一个连接被关闭，又会发生什么事情呢，我们来看看此方法返回之后，会调用getProxyConnection来获取一个代理对象，实际上就是PooledConnection类： 1234567891011class PooledConnection implements InvocationHandler &#123; private static final String CLOSE = &quot;close&quot;; private static final Class&lt;?&gt;[] IFACES = new Class[]&#123;Connection.class&#125;; private final int hashCode; //会记录是来自哪一个数据源创建的的 private final PooledDataSource dataSource; //连接对象本体 private final Connection realConnection; //代理的链接对象 private final Connection proxyConnection; ... 它直接代理了构造方法中传入的Connection对象，也是使用JDK的动态代理实现的，那么我们来看一下，它是如何进行代理的： 123456789101112131415161718192021public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); //如果调用的是Connection对象的close方法， if (&quot;close&quot;.equals(methodName)) &#123; //这里并不会真的关闭连接（这也是为什么用代理），而是调用之前数据源的pushConnection方法，将此连接改为为空闲状态 this.dataSource.pushConnection(this); return null; &#125; else &#123; try &#123; if (!Object.class.equals(method.getDeclaringClass())) &#123; this.checkConnection(); //任何操作执行之前都会检查连接是否可用 &#125; //该干嘛干嘛 return method.invoke(this.realConnection, args); &#125; catch (Throwable var6) &#123; throw ExceptionUtil.unwrapThrowable(var6); &#125; &#125;&#125; 那么我们最后再来看看pushConnection方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051protected void pushConnection(PooledConnection conn) throws SQLException &#123; synchronized(this.state) &#123; //老规矩，先来把锁 //先从活跃列表移除此连接 this.state.activeConnections.remove(conn); //判断此链接是否可用 if (conn.isValid()) &#123; PoolState var10000; //看看闲置列表容量是否已满（容量满了就回不去了） if (this.state.idleConnections.size() &lt; this.poolMaximumIdleConnections &amp;&amp; conn.getConnectionTypeCode() == this.expectedConnectionTypeCode) &#123; var10000 = this.state; var10000.accumulatedCheckoutTime += conn.getCheckoutTime(); if (!conn.getRealConnection().getAutoCommit()) &#123; conn.getRealConnection().rollback(); &#125; //把唯一有用的Connection对象拿出来，然后重新创建一个PooledConnection PooledConnection newConn = new PooledConnection(conn.getRealConnection(), this); //放入闲置列表，成功回收 this.state.idleConnections.add(newConn); newConn.setCreatedTimestamp(conn.getCreatedTimestamp()); newConn.setLastUsedTimestamp(conn.getLastUsedTimestamp()); conn.invalidate(); if (log.isDebugEnabled()) &#123; log.debug(&quot;Returned connection &quot; + newConn.getRealHashCode() + &quot; to pool.&quot;); &#125; this.state.notifyAll(); &#125; else &#123; var10000 = this.state; var10000.accumulatedCheckoutTime += conn.getCheckoutTime(); if (!conn.getRealConnection().getAutoCommit()) &#123; conn.getRealConnection().rollback(); &#125; conn.getRealConnection().close(); if (log.isDebugEnabled()) &#123; log.debug(&quot;Closed connection &quot; + conn.getRealHashCode() + &quot;.&quot;); &#125; conn.invalidate(); &#125; &#125; else &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;A bad connection (&quot; + conn.getRealHashCode() + &quot;) attempted to return to the pool, discarding connection.&quot;); &#125; ++this.state.badConnectionCount; &#125; &#125;&#125; 这样，我们就已经完全了解了Mybatis的池化数据源的执行流程了。只不过，无论Connection管理方式如何变换，无论数据源再高级，我们要知道，它都最终都会使用DriverManager来创建连接对象，而最终使用的也是DriverManager提供的Connection对象。 整合Mybatis框架通过了解数据源，我们已经清楚，Mybatis实际上是在使用自己编写的数据源（数据源有很多，之后我们再聊其他的）默认使用的是池化的数据源，它预先存储了很多的连接对象。 那么我们来看一下，如何将Mybatis与Spring更好的结合呢，比如我们现在希望将SqlSessionFactory交给IoC容器进行管理，而不是我们自己创建工具类来管理（我们之前一直都在使用工具类管理和创建会话） 首先导入依赖： 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.25&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.3.13&lt;/version&gt;&lt;/dependency&gt; 在mybatis-spring依赖中，为我们提供了SqlSessionTemplate类，它其实就是官方封装的一个工具类，可以将其注册为Bean，这样我们随时都可以向IoC容器索要，而不用自己再去编写一个工具类了： 123456789@Configuration@ComponentScan(&quot;com.test&quot;)public class TestConfiguration &#123; @Bean public SqlSessionTemplate sqlSessionTemplate() throws IOException &#123; SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(Resources.getResourceAsReader(&quot;mybatis-config.xml&quot;)); return new SqlSessionTemplate(factory); &#125;&#125; 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/study&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper class=&quot;com.test.mapper.TestMapper&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 123456public static void main(String[] args) &#123; ApplicationContext context = new AnnotationConfigApplicationContext(TestConfiguration.class); SqlSessionTemplate template = context.getBean(SqlSessionTemplate.class); TestMapper testMapper = template.getMapper(TestMapper.class); System.out.println(testMapper.getStudent());&#125; 123456@Mapperpublic interface TestMapper &#123; @Select(&quot;select * from student where sid = 1&quot;) Student getStudent();&#125; 123456@Datapublic class Student &#123; int sid; String name; String sex;&#125; 最后成功得到Student实体类，证明SqlSessionTemplate成功注册为Bean可以使用了。虽然这样已经很方便了，但是还不够方便，我们依然需要手动去获取Mapper对象，那么能否直接得到对应的Mapper对象呢，我们希望让Spring直接帮助我们管理所有的Mapper，当需要时，可以直接从容器中获取，我们可以直接在配置类上方添加注解： 1@MapperScan(&quot;com.test.mapper&quot;) 这样，Spring会自动扫描所有的Mapper，并将其实现注册为Bean，那么我们现在就可以直接通过容器获取了： 12345public static void main(String[] args) throws InterruptedException &#123; ApplicationContext context = new AnnotationConfigApplicationContext(TestConfiguration.class); TestMapper mapper = context.getBean(TestMapper.class); System.out.println(mapper.getStudent());&#125; 请一定注意，必须存在SqlSessionTemplate或是SqlSessionFactoryBean的Bean，否则会无法初始化（毕竟要数据库的链接信息） 我们接着来看，如果我们希望直接去除Mybatis的配置文件，那么改怎么去实现呢？我们可以使用SqlSessionFactoryBean类： 1234567891011121314151617@Configuration@ComponentScan(&quot;com.test&quot;)@MapperScan(&quot;com.test.mapper&quot;)public class TestConfiguration &#123; @Bean public DataSource dataSource()&#123; return new PooledDataSource(&quot;com.mysql.cj.jdbc.Driver&quot;, &quot;jdbc:mysql://localhost:3306/study&quot;, &quot;root&quot;, &quot;123456&quot;); &#125; @Bean public SqlSessionFactoryBean sqlSessionFactoryBean(@Autowired DataSource dataSource)&#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); return bean; &#125;&#125; 首先需要创建一个数据源的实现类，因为这是数据库最基本的信息，然后再给到SqlSessionFactoryBean实例，这样相当于直接在一开始通过IoC容器配置了SqlSessionFactory，只需要传入一个DataSource的实现 删除配置文件，重新再来运行，同样可以正常使用Mapper。从这里开始，通过IoC容器，Mybatis已经不再需要使用配置文件了，之后基于Spring的开发将不会再出现Mybatis的配置文件 使用HikariCP连接池前面我们提到了数据源还有其他实现，比如C3P0、Druid等，它们都是非常优秀的数据源实现（可以自行了解），不过我们这里要介绍的，是之后在SpringBoot中还会遇到的HikariCP连接池。 HikariCP是由日本程序员开源的一个数据库连接池组件，代码非常轻量，并且速度非常的快。根据官方提供的数据，在酷睿i7开启32个线程32个连接的情况下，进行随机数据库读写操作，HikariCP的速度是现在常用的C3P0数据库连接池的数百倍。在SpringBoot2.0中，官方也是推荐使用HikariCP。 首先，我们需要导入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt;&lt;/dependency&gt; 接着修改一下Bean的定义： 123456789@Beanpublic DataSource dataSource() throws SQLException &#123; HikariDataSource dataSource = new HikariDataSource(); dataSource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/study&quot;); dataSource.setDriverClassName(&quot;com.mysql.cj.jdbc.Driver&quot;); dataSource.setUsername(&quot;root&quot;); dataSource.setPassword(&quot;123456&quot;); return dataSource;&#125; 最后我们发现，同样可以得到输出结果，但是出现了一个报错： 123SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. 此数据源实际上是采用了SLF4J日志框架打印日志信息，但是现在没有任何的日志实现（slf4j只是一个API标准，它规范了多种日志框架的操作，统一使用SLF4J定义的方法来操作不同的日志框架）我们这里就使用JUL作为日志实现，我们需要导入另一个依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt; 注意版本一定要和slf4j-api保持一致！ 这样就能得到我们的日志信息了： 12345十二月 07, 2021 8:46:41 下午 com.zaxxer.hikari.HikariDataSource getConnection信息: HikariPool-1 - Starting...十二月 07, 2021 8:46:41 下午 com.zaxxer.hikari.HikariDataSource getConnection信息: HikariPool-1 - Start completed.Student(sid=1, name=小明, sex=男) 在SpringBoot阶段，我们还会遇到HikariPool-1 - Starting...和HikariPool-1 - Start completed.同款日志信息。 当然，Lombok肯定也是支持这个日志框架快速注解的： 123456789@Slf4jpublic class Main &#123; public static void main(String[] args) &#123; log.info(&quot;项目正在启动...&quot;); ApplicationContext context = new AnnotationConfigApplicationContext(TestConfiguration.class); TestMapper mapper = context.getBean(TestMapper.class); System.out.println(mapper.getStudent()); &#125;&#125; Mybatis事务管理回顾一下事务机制。首先事务遵循一个ACID原则： 原子性（Atomicity）：事务是一个原子操作，由一系列动作组成。事务的原子性确保动作要么全部完成，要么完全不起作用。 一致性（Consistency）：一旦事务完成（不管成功还是失败），系统必须确保它所建模的业务处于一致的状态，而不会是部分完成部分失败。在现实中的数据不应该被破坏。 隔离性（Isolation）：可能有许多事务会同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏。 持久性（Durability）：一旦事务完成，无论发生什么系统错误，它的结果都不应该受到影响，这样就能从任何系统崩溃中恢复过来。通常情况下，事务的结果被写到持久化存储器中。 简单来说，事务就是要么完成，要么就啥都别做！并且不同的事务直接相互隔离，互不干扰。 那么我们接着来深入了解一下事务的隔离机制，事务之间是相互隔离互不干扰的，那么如果出现了下面的情况，会怎么样呢： 当两个事务同时在执行，并且同时在操作同一个数据，这样很容易出现并发相关的问题，比如一个事务先读取了某条数据，而另一个事务此时修改了此数据，当前一个事务紧接着再次读取时，会导致和前一次读取的数据不一致，这就是一种典型的数据虚读现象。 因此，为了解决这些问题，事务之间实际上是存在一些隔离级别的： ISOLATION_READ_UNCOMMITTED（读未提交）：其他事务会读取当前事务尚未更改的提交（相当于读取的是这个事务暂时缓存的内容，并不是数据库中的内容） ISOLATION_READ_COMMITTED（读已提交）：其他事务会读取当前事务已经提交的数据（也就是直接读取数据库中已经发生更改的内容） ISOLATION_REPEATABLE_READ（可重复读）：其他事务会读取当前事务已经提交的数据并且其他事务执行过程中不允许再进行数据修改（注意这里仅仅是不允许修改数据） ISOLATION_SERIALIZABLE（串行化）：它完全服从ACID原则，一个事务必须等待其他事务结束之后才能开始执行，相当于挨个执行，效率很低 首先是读未提交级别，此级别属于最低级别，相当于各个事务共享一个缓存区域，任何事务的操作都在这里进行。那么它会导致以下问题： 也就是说，事务A最后得到的实际上是一个毫无意义的数据（事务B已经回滚了）我们称此数据为”脏数据”，这种现象称为脏读 我们接着来看读已提交级别，事务只能读取其他事务已经提交的内容，相当于直接从数据中读取数据，这样就可以避免脏读问题了，但是它还是存在以下问题： 这正是我们前面例子中提到的问题，虽然它避免了脏读问题，但是如果事件B修改并提交了数据，那么实际上事务A之前读取到的数据依然不是最新的数据，直接导致两次读取的数据不一致，这种现象称为虚读也可以称为不可重复读 因此，下一个隔离级别可重复读就能够解决这样的问题（MySQL的默认隔离级别），它规定在其他事务执行时，不允许修改数据，这样，就可以有效地避免不可重复读的问题，但是这样就一定安全了吗？这里仅仅是禁止了事务执行过程中的UPDATE操作，但是它并没有禁止INSERT这类操作，因此，如果事务A执行过程中事务B插入了新的数据，那么A这时是毫不知情的，比如： 两个人同时报名一个活动，两个报名的事务同时在进行，但是他们一开始读取到的人数都是5，而这时，它们都会认为报名成功后人数应该变成6，而正常情况下应该是7，因此这个时候就发生了数据的幻读现象。 要解决这种问题，只能使用最后一种隔离级别串行化来实现了，每个事务不能同时进行，直接避免所有并发问题，简单粗暴，但是效率爆减 最后总结三种情况： 脏读：读取到了被回滚的数据，它毫无意义。 虚读（不可重复读）：由于其他事务更新数据，两次读取的数据不一致。 幻读：由于其他事务执行插入删除操作，而又无法感知到表中记录条数发生变化，当下次再读取时会莫名其妙多出或缺失数据，就像产生幻觉一样。 （对于虚读和幻读的区分：虚读是某个数据前后读取不一致，幻读是整个表的记录数量前后读取不一致） 最后这张图： Mybatis对于数据库的事务管理，也有着相应的封装。一个事务无非就是创建、提交、回滚、关闭，因此这些操作被Mybatis抽象为一个接口： 1234567891011public interface Transaction &#123; Connection getConnection() throws SQLException; void commit() throws SQLException; void rollback() throws SQLException; void close() throws SQLException; Integer getTimeout() throws SQLException;&#125; 对于此接口的实现，MyBatis的事务管理分为两种形式： 使用JDBC的事务管理机制：即利用对应数据库的驱动生成的Connection对象完成对事务的提交（commit()）、回滚（rollback()）、关闭（close()）等，对应的实现类为JdbcTransaction 使用MANAGED的事务管理机制：这种机制MyBatis自身不会去实现事务管理，而是让程序的容器（比如Spring）来实现对事务的管理，对应的实现类为ManagedTransaction 而我们之前一直使用的其实就是JDBC的事务，相当于直接使用Connection对象（之前JavaWeb阶段已经讲解过了）在进行事务操作，并没有额外的管理机制，对应的配置为： 1&lt;transactionManager type=&quot;JDBC&quot;/&gt; 那么我们来看看JdbcTransaction是不是像我们上面所说的那样管理事务的，直接上源码： 1234567891011121314151617181920212223242526272829303132333435363738394041public class JdbcTransaction implements Transaction &#123; private static final Log log = LogFactory.getLog(JdbcTransaction.class); protected Connection connection; protected DataSource dataSource; protected TransactionIsolationLevel level; protected boolean autoCommit; public JdbcTransaction(DataSource ds, TransactionIsolationLevel desiredLevel, boolean desiredAutoCommit) &#123; //数据源 this.dataSource = ds; //事务隔离级别，上面已经提到过了 this.level = desiredLevel; //是否自动提交 this.autoCommit = desiredAutoCommit; &#125; //也可以直接给个Connection对象 public JdbcTransaction(Connection connection) &#123; this.connection = connection; &#125; public Connection getConnection() throws SQLException &#123; //没有就通过数据源新开一个Connection if (this.connection == null) &#123; this.openConnection(); &#125; return this.connection; &#125; public void commit() throws SQLException &#123; //连接已经创建并且没开启自动提交才可以使用 if (this.connection != null &amp;&amp; !this.connection.getAutoCommit()) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;Committing JDBC Connection [&quot; + this.connection + &quot;]&quot;); &#125; //实际上使用的是数据库驱动提供的Connection对象进行事务操作 this.connection.commit(); &#125; &#125; 相当于JdbcTransaction只是为数据库驱动提供的Connection对象套了层壳，所有的事务操作实际上是直接调用Connection对象。 接着来看ManagedTransaction的源码： 1234567891011public class ManagedTransaction implements Transaction &#123; ... public void commit() throws SQLException &#123; &#125; public void rollback() throws SQLException &#123; &#125; ...&#125; 大体内容和JdbcTransaction差不多，但是它并没有实现任何的事务操作。也就是说，它希望将实现交给其他的管理框架来完成，而Spring就为Mybatis提供了一个非常好的事务管理实现。 使用Spring事务管理Spring提供的事务管理（Spring事务管理分为编程式事务和声明式事务，但是编程式事务过于复杂并且具有高度耦合性，违背了Spring框架的设计初衷，因此这里只讲解声明式事务）声明式事务是基于AOP实现的。 使用声明式事务非常简单，我们只需要在配置类添加@EnableTransactionManagement注解即可，这样就可以开启Spring的事务支持了。接着，我们只需要把一个事务要做的所有事情封装到Service层的一个方法中即可，首先需要在配置文件中注册一个新的Bean，事务需要执行必须有一个事务管理器： 1234@Beanpublic TransactionManager transactionManager(@Autowired DataSource dataSource)&#123; return new DataSourceTransactionManager(dataSource);&#125; 接着编写Mapper操作： 123456@Mapperpublic interface TestMapper &#123; @Insert(&quot;insert into student(name, sex) values(&#x27;测试&#x27;, &#x27;男&#x27;)&quot;) void insertStudent();&#125; 这样会向数据库中插入一条新的学生信息，接着，假设我们这里有一个业务需要连续插入两条学生信息，首先编写业务层的接口： 1234public interface TestService &#123; void test();&#125; 接着，我们再来编写业务层的实现，我们可以直接将其注册为Bean，交给Spring来进行管理，这样就可以自动将Mapper注入到类中了，并且可以支持事务： 1234567891011121314@Componentpublic class TestServiceImpl implements TestService&#123; @Resource TestMapper mapper; @Transactional @Override public void test() &#123; mapper.insertStudent(); if(true) throw new RuntimeException(&quot;我是测试异常！&quot;); mapper.insertStudent(); &#125;&#125; 我们只需在方法上添加@Transactional注解，即可表示此方法执行的是一个事务操作，在调用此方法时，Spring会通过AOP机制为其进行增强，一旦发现异常，事务会自动回滚。最后我们来调用一下此方法： 123456789@Slf4jpublic class Main &#123; public static void main(String[] args) &#123; log.info(&quot;项目正在启动...&quot;); ApplicationContext context = new AnnotationConfigApplicationContext(TestConfiguration.class); TestService service = context.getBean(TestService.class); service.test(); &#125;&#125; 得到的结果是出现错误： 12345678910111213141516171819202122十二月 08, 2021 3:09:29 下午 com.test.Main main信息: 项目正在启动...十二月 08, 2021 3:09:29 下午 com.zaxxer.hikari.HikariDataSource getConnection信息: HikariPool-1 - Starting...十二月 08, 2021 3:09:29 下午 com.zaxxer.hikari.HikariDataSource getConnection信息: HikariPool-1 - Start completed.Exception in thread &quot;main&quot; java.lang.RuntimeException: 我是测试异常！\tat com.test.service.TestServiceImpl.test(TestServiceImpl.java:22)\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\tat java.lang.reflect.Method.invoke(Method.java:498)\tat org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)\tat org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)\tat org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123)\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388)\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)\tat com.sun.proxy.$Proxy30.test(Unknown Source)\tat com.test.Main.main(Main.java:17) 我们发现，整个栈追踪信息中包含了大量aop包下的相关内容，也就印证了，它确实是通过AOP实现的，那么我们接着来看一下，数据库中的数据是否没有发生变化（出现异常回滚了） 结果显而易见，确实被回滚了，数据库中没有任何的内容。 我们接着来研究一下@Transactional注解的一些参数： 12345678910111213141516171819202122232425262728293031@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Transactional &#123; @AliasFor(&quot;transactionManager&quot;) String value() default &quot;&quot;; @AliasFor(&quot;value&quot;) String transactionManager() default &quot;&quot;; String[] label() default &#123;&#125;; Propagation propagation() default Propagation.REQUIRED; Isolation isolation() default Isolation.DEFAULT; int timeout() default -1; String timeoutString() default &quot;&quot;; boolean readOnly() default false; Class&lt;? extends Throwable&gt;[] rollbackFor() default &#123;&#125;; String[] rollbackForClassName() default &#123;&#125;; Class&lt;? extends Throwable&gt;[] noRollbackFor() default &#123;&#125;; String[] noRollbackForClassName() default &#123;&#125;;&#125; 我们来讲解几个比较关键的信息： transactionManager：指定事务管理器 propagation：事务传播规则，一个事务可以包括N个子事务 isolation：事务隔离级别，不多说了 timeout：事务超时时间 readOnly：是否为只读事务，不同的数据库会根据只读属性进行优化，比如MySQL一旦声明事务为只读，那么久不允许增删改操作了。 rollbackFor和noRollbackFor：发生指定异常时回滚或是不回滚，默认发生任何异常都回滚 除了事务的传播规则，其他的内容其实已经给大家讲解过了，那么我们就来看看事务的传播。事务传播一共有七种级别： Spring默认的传播级别是PROPAGATION_REQUIRED，那么我们来看看，它是如何传播的，现在我们的Service类中一共存在两个事务，而一个事务方法包含了另一个事务方法： 12345678910@Transactionalpublic void test() &#123; test2(); if(true) throw new RuntimeException(&quot;我是测试异常！&quot;); //发生异常时，会回滚另一个事务吗？&#125;@Transactionalpublic void test2() &#123; mapper.insertStudent();&#125; 最后我们得到结果，另一个事务被回滚了，也就是说，相当于另一个事务直接加入到此事务中了，也就是表中所描述的那样。 如果单独执行test2()则会开启一个新的事务，而执行test()则会直接让内部的test2()加入到当前事务中。 12345678910@Transactionalpublic void test() &#123; test2();&#125;@Transactional(propagation = Propagation.SUPPORTS)public void test2() &#123; mapper.insertStudent(); if(true) throw new RuntimeException(&quot;我是测试异常！&quot;);&#125; 现在我们将test2()的传播级别设定为SUPPORTS，那么这时如果单独调用test2()方法，并不会以事务的方式执行，当发生异常时，虽然依然存在AOP增强，但是不会进行回滚操作，而现在再调用test()方法，才会以事务的方式执行。 我们接着来看MANDATORY，它非常严格，如果当前方法并没有在任何事务中进行，会直接出现异常： 12345678910@Transactionalpublic void test() &#123; test2();&#125;@Transactional(propagation = Propagation.MANDATORY)public void test2() &#123; mapper.insertStudent(); if(true) throw new RuntimeException(&quot;我是测试异常！&quot;);&#125; 直接运行test2()方法，报错如下： 123456789Exception in thread &quot;main&quot; org.springframework.transaction.IllegalTransactionStateException: No existing transaction found for transaction marked with propagation &#x27;mandatory&#x27;\tat org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:362)\tat org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:595)\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:382)\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)\tat com.sun.proxy.$Proxy29.test2(Unknown Source)\tat com.test.Main.main(Main.java:17) NESTED级别表示如果存在外层事务，则此方法单独创建一个子事务，回滚只会影响到此子事务，实际上就是利用创建Savepoint，然后回滚到此保存点实现的。NEVER级别表示此方法不应该加入到任何事务中，其余类型适用于同时操作多数据源情况下的分布式事务管理，这里暂时不做介绍。 至此，有关Spring的核心内容就讲解完毕了。 集成JUnit测试既然使用了Spring，那么怎么集成到JUnit中进行测试呢，首先大家能够想到的肯定是： 123456789public class TestMain &#123; @Test public void test()&#123; ApplicationContext context = new AnnotationConfigApplicationContext(TestConfiguration.class); TestService service = context.getBean(TestService.class); service.test(); &#125;&#125; 直接编写一个测试用例即可，但是这样的话，如果我们有很多个测试用例，那么我们不可能每次测试都去创建ApplicationContext吧？我们可以使用@Before添加一个测试前动作来提前配置ApplicationContext，但是这样的话，还是不够简便，能不能有更快速高效的方法呢？ Spring为我们提供了一个Test模块，它会自动集成Junit进行测试，我们可以导入一下依赖： 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt; &lt;version&gt;5.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.3.12&lt;/version&gt;&lt;/dependency&gt; 这里导入的是JUnit5和SpringTest模块依赖，然后直接在我们的测试类上添加两个注解就可以搞定： 123456789101112@ExtendWith(SpringExtension.class)@ContextConfiguration(classes = TestConfiguration.class)public class TestMain &#123; @Autowired TestService service; @Test public void test()&#123; service.test(); &#125;&#125; @ExtendWith是由JUnit提供的注解，等同于旧版本的@RunWith注解，然后使用SpringTest模块提供的@ContextConfiguration注解来表示要加载哪一个配置文件，可以是XML文件也可以是类，我们这里就直接使用类进行加载。 配置完成后，我们可以直接使用@Autowired来进行依赖注入，并且直接在测试方法中使用注入的Bean，现在就非常方便了。 探究Spring原理注意：本版块难度很大，作为选学内容。 如果学习Spring基本内容对你来说已经非常困难了，建议跳过此小节，直接进入MVC阶段的学习，此小节会从源码角度解释Spring的整个运行原理，对初学者来说等同于小学跨越到高中，它并不是必学内容，但是对于个人开发能力的提升极为重要（推荐完成整个SSM阶段的学习并且加以实战之后再来看此部分），如果你还是觉得自己能够跟上节奏继续深入钻研底层原理，那么现在就开始吧。 探究IoC原理首先我们大致了解一下ApplicationContext的加载流程： 我们可以看到，整个过程极为复杂，一句话肯定是无法解释的，所以我们就从ApplicationContext说起吧。 由于Spring的源码极为复杂，因此我们不可能再像了解其他框架那样直接自底向上逐行干源码了（可以自己点开看看，代码量非常之多），我们可以先从一些最基本的接口定义开始讲起，自顶向下逐步瓦解，那么我们来看看ApplicationContext最顶层接口是什么，一直往上，我们会发现有一个AbstractApplicationContext类，我们直接右键生成一个UML类图查看： Support/typora-user-images/image-20211209202503121.png 我们发现最顶层实际上是一个BeanFactory接口，那么我们就从这个接口开始研究起。 我们可以看到此接口中定义了很多的行为： 1234567891011121314151617181920212223242526272829303132333435public interface BeanFactory &#123; String FACTORY_BEAN_PREFIX = &quot;&amp;&quot;; Object getBean(String var1) throws BeansException; &lt;T&gt; T getBean(String var1, Class&lt;T&gt; var2) throws BeansException; Object getBean(String var1, Object... var2) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1, Object... var2) throws BeansException; &lt;T&gt; ObjectProvider&lt;T&gt; getBeanProvider(Class&lt;T&gt; var1); &lt;T&gt; ObjectProvider&lt;T&gt; getBeanProvider(ResolvableType var1); boolean containsBean(String var1); boolean isSingleton(String var1) throws NoSuchBeanDefinitionException; boolean isPrototype(String var1) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String var1, ResolvableType var2) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String var1, Class&lt;?&gt; var2) throws NoSuchBeanDefinitionException; @Nullable Class&lt;?&gt; getType(String var1) throws NoSuchBeanDefinitionException; @Nullable Class&lt;?&gt; getType(String var1, boolean var2) throws NoSuchBeanDefinitionException; String[] getAliases(String var1);&#125; 我们发现，其中最眼熟的就是getBean()方法了，此方法被重载了很多次，可以接受多种参数，因此，我们可以断定，一个IoC容器最基本的行为在此接口中已经被定义好了，也就是说，所有的BeanFactory实现类都应该具备容器管理Bean的基本能力，就像它的名字一样，它就是一个Bean工厂，工厂就是用来生产Bean实例对象的。 我们可以直接找到此接口的一个抽象实现AbstractBeanFactory类，它实现了getBean()方法： 123public Object getBean(String name) throws BeansException &#123; return this.doGetBean(name, (Class)null, (Object[])null, false);&#125; 那么我们doGetBean()接着来看方法里面干了什么： 123456protected &lt;T&gt; T doGetBean(String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; String beanName = this.transformedBeanName(name); Object sharedInstance = this.getSingleton(beanName); Object beanInstance; if (sharedInstance != null &amp;&amp; args == null) &#123; ... 因为所有的Bean默认都是单例模式，对象只会存在一个，因此它会先调用父类的getSingleton()方法来直接获取单例对象，如果有的话，就可以直接拿到Bean的实例。如果没有会进入else代码块，我们接着来看，首先会进行一个判断： 123if (this.isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName);&#125; 这是为了解决循环依赖进行的处理，比如A和B都是以原型模式进行创建，而A中需要注入B，B中需要注入A，这时就会出现A还未创建完成，就需要B，而B这时也没创建完成，因为B需要A，而A等着B，这样就只能无限循环下去了，所以就出现了循环依赖的问题（同理，一个对象，多个对象也会出现这种情况）但是在单例模式下，由于每个Bean只会创建一个实例，Spring完全有机会处理好循环依赖的问题，只需要一个正确的赋值操作实现循环即可。那么单例模式下是如何解决循环依赖问题的呢？ 我们回到getSingleton()方法中，单例模式是可以自动解决循环依赖问题的： 123456789101112131415161718192021222324252627282930@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); //先从第一层列表中拿Bean实例，拿到直接返回 if (singletonObject == null &amp;&amp; this.isSingletonCurrentlyInCreation(beanName)) &#123; //第一层拿不到，并且已经认定为处于循环状态，看看第二层有没有 singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; synchronized(this.singletonObjects) &#123; //加锁再执行一次上述流程 singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null) &#123; //仍然没有获取到实例，只能从singletonFactory中获取了 ObjectFactory&lt;?&gt; singletonFactory = (ObjectFactory)this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); //丢进earlySingletonObjects中，下次就可以直接在第二层拿到了 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; &#125; &#125; return singletonObject;&#125; 看起来很复杂，实际上它使用了三层列表的方式来处理循环依赖的问题。包括： singletonObjects earlySingletonObjects singletonFactories 当第一层拿不到时，会接着判断这个Bean是否处于创建状态isSingletonCurrentlyInCreation()，它会从一个Set集合中查询，这个集合中存储了已经创建但还未注入属性的实例对象，也就是说处于正在创建状态，如果说发现此Bean处于正在创建状态（一定是因为某个Bean需要注入这个Bean的实例），就可以断定它应该是出现了循环依赖的情况。 earlySingletonObjects相当于是专门处理循环依赖的表，一般包含singletonObjects中的全部实例，如果这个里面还是没有，接着往下走，这时会从singletonFactories中获取（所有的Bean初始化完成之后都会被丢进singletonFactories，也就是只创建了，但是还没进行依赖注入的时候）在获取到后，向earlySingletonObjects中丢入此Bean的实例，并将实例从singletonFactories中移除。 我们最后再来梳理一下流程，还是用我们刚才的例子，A依赖于B，B依赖于A： 假如A先载入，那么A首先进入了singletonFactories中，注意这时还没进行依赖注入，A中的B还是null singletonFactories：A earlySingletonObjects： singletonObjects： 接着肯定是注入A的依赖B了，但是B还没初始化，因此现在先把B给载入了，B构造完成后也进了singletonFactories singletonFactories：A，B earlySingletonObjects： singletonObjects： 开始为B注入依赖，发现B依赖于A，这时又得去获取A的实例，根据上面的分析，这时候A还在singletonFactories中，那么它会被丢进earlySingletonObjects，然后从singletonFactories中移除，然后返回A的实例（注意此时A中的B依赖还是null） singletonFactories：B earlySingletonObjects：A singletonObjects： 这时B已经完成依赖注入了，因此可以直接丢进singletonObjects中 singletonFactories： earlySingletonObjects：A singletonObjects：B 然后再将B注入到A中，完成A的依赖注入，A也被丢进singletonObjects中，至此循环依赖完成，A和B完成实例创建 singletonFactories： earlySingletonObjects： singletonObjects：A，B 经过整体过程梳理，关于Spring如何解决单例模式的循环依赖理解起来就非常简单了。 现在让我们回到之前的地方，原型模式下如果出现循环依赖会直接抛出异常，如果不存在会接着向下： 123456789101112131415161718192021222324//BeanFactory存在父子关系BeanFactory parentBeanFactory = this.getParentBeanFactory();//如果存在父BeanFactory，同时当前BeanFactory没有这个Bean的定义if (parentBeanFactory != null &amp;&amp; !this.containsBeanDefinition(beanName)) &#123; //这里是因为Bean可能有别名，找最原始的那个名称 String nameToLookup = this.originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; //向父BeanFactory递归查找 return ((AbstractBeanFactory)parentBeanFactory).doGetBean(nameToLookup, requiredType, args, typeCheckOnly); &#125; if (args != null) &#123; //根据参数查找 return parentBeanFactory.getBean(nameToLookup, args); &#125; if (requiredType != null) &#123; //根据类型查找 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; //各种找 return parentBeanFactory.getBean(nameToLookup);&#125; 也就是说，BeanFactory会先看当前是否存在Bean的定义，如果没有会直接用父BeanFactory各种找。这里出现了一个新的接口BeanDefinition，既然工厂需要生产商品，那么肯定需要拿到商品的原材料以及制作配方，我们的Bean也是这样，Bean工厂需要拿到Bean的信息才可以去生成这个Bean的实例对象，而BeanDefinition就是用于存放Bean的信息的，所有的Bean信息正是从XML配置文件读取或是注解扫描后得到的。 我们接着来看，如果此BeanFactory不存在父BeanFactory或是包含了Bean的定义，那么会接着往下走，这时只能自己创建Bean了，首先会拿到一个RootBeanDefinition对象： 123456try &#123; if (requiredType != null) &#123; beanCreation.tag(&quot;beanType&quot;, requiredType::toString); &#125; RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); 下面的内容就非常复杂了，但是我们可以知道，它一定是根据对应的类型（单例、原型）进行了对应的处理，最后自行创建一个新的对象返回。一个Bean的加载流程为： 首先拿到BeanDefinition定义，选择对应的构造方法，通过反射进行实例化，然后进行属性填充（依赖注入），完成之后再调用初始化方法（init-method），最后如果存在AOP，则会生成一个代理对象，最后返回的才是我们真正得到的Bean对象。 最后让我们回到ApplicationContext中，实际上，它就是一个强化版的BeanFactory，在最基本的Bean管理基础上，还添加了： 国际化（MessageSource） 访问资源，如URL和文件（ResourceLoader） 载入多个（有继承关系）上下文 消息发送、响应机制（ApplicationEventPublisher） AOP机制 我们发现，无论是还是的构造方法中都会调用refresh()方法来刷新应用程序上下文： 12345public AnnotationConfigApplicationContext(Class&lt;?&gt;... componentClasses) &#123; this(); this.register(componentClasses); this.refresh();&#125; 此方法在讲解完AOP原理之后，再进行讲解。综上，有关IoC容器的大部分原理就讲解完毕了。 探究AOP原理前面我们提到了PostProcessor，它其实是Spring提供的一种后置处理机制，它可以让我们能够插手Bean、BeanFactory、BeanDefinition的创建过程，相当于进行一个最终的处理，而最后得到的结果（比如Bean实例、Bean定义等）就是经过后置处理器返回的结果，它是整个加载过程的最后一步。 而AOP机制正是通过它来实现的，我们首先来认识一下第一个接口BeanPostProcessor，它相当于Bean初始化的一个后置动作，我们可以直接实现此接口： 1234567891011121314//注意它后置处理器也要进行注册@Componentpublic class TestBeanProcessor implements BeanPostProcessor &#123; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(beanName); //打印bean的名称 return bean; &#125; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return BeanPostProcessor.super.postProcessBeforeInitialization(bean, beanName); &#125;&#125; 我们发现，此接口中包括两个方法，一个是postProcessAfterInitialization用于在Bean初始化之后进行处理，还有一个postProcessBeforeInitialization用于在Bean初始化之前进行处理，注意这里的初始化不是创建对象，而是调用类的初始化方法，比如： 1234567891011121314@Componentpublic class TestBeanProcessor implements BeanPostProcessor &#123; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;我是之后：&quot;+beanName); return bean; //这里返回的Bean相当于最终的结果了，我们依然能够插手修改，这里返回之后是什么就是什么了 &#125; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;我是之前：&quot;+beanName); return bean; //这里返回的Bean会交给下一个阶段，也就是初始化方法 &#125;&#125; 123456789101112131415161718192021@Componentpublic class TestServiceImpl implements TestService&#123; public TestServiceImpl()&#123; System.out.println(&quot;我是构造方法&quot;); &#125; @PostConstruct public void init()&#123; System.out.println(&quot;我是初始化方法&quot;); &#125; TestMapper mapper; @Autowired public void setMapper(TestMapper mapper) &#123; System.out.println(&quot;我是依赖注入&quot;); this.mapper = mapper; &#125; ... 而TestServiceImpl的加载顺序为： 12345我是构造方法我是依赖注入我是之前：testServiceImpl我是初始化方法我是之后：testServiceImpl 现在我们再来总结一下一个Bean的加载流程： [Bean定义]首先扫描Bean，加载Bean定义 -&gt; [依赖注入]根据Bean定义通过反射创建Bean实例 -&gt; [依赖注入]进行依赖注入（顺便解决循环依赖问题）-&gt; [初始化Bean]BeanPostProcessor的初始化之前方法 -&gt; [初始化Bean]Bean初始化方法 -&gt; [初始化Bean]BeanPostProcessor的初始化之前后方法 -&gt; [完成]最终得到的Bean加载完成的实例 利用这种机制，理解Aop的实现过程就非常简单了，AOP实际上也是通过这种机制实现的，它的实现类是AnnotationAwareAspectJAutoProxyCreator，而它就是在最后对Bean进行了代理，因此最后我们得到的结果实际上就是一个动态代理的对象（有关详细实现过程，这里就不进行列举了，感兴趣的可以继续深入） 那么肯定有人有疑问了，这个类没有被注册啊，那按理说它不应该参与到Bean的初始化流程中的，为什么它直接就被加载了呢？ 还记得@EnableAspectJAutoProxy吗？我们来看看它是如何定义就知道了： 123456789@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;AspectJAutoProxyRegistrar.class&#125;)public @interface EnableAspectJAutoProxy &#123; boolean proxyTargetClass() default false; boolean exposeProxy() default false;&#125; 我们发现它使用了@Import来注册AspectJAutoProxyRegistrar，那么这个类又是什么呢，我们接着来看： 1234567891011121314151617181920class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; AspectJAutoProxyRegistrar() &#123; &#125; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //注册AnnotationAwareAspectJAutoProxyCreator到容器中 AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) &#123; AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; 它实现了接口，这个接口也是Spring提供的一种Bean加载机制，它支持直接向容器中添加Bean定义，容器也会加载这个Bean： ImportBeanDefinitionRegistrar类只能通过其他类@Import的方式来加载，通常是启动类或配置类。 使用@Import，如果括号中的类是ImportBeanDefinitionRegistrar的实现类，则会调用接口中方法（一般用于注册Bean） 实现该接口的类拥有注册bean的能力。 我们可以看到此接口提供了一个BeanDefinitionRegistry正是用于注册Bean的定义的。 因此，当我们打上了@EnableAspectJAutoProxy注解之后，首先会通过@Import加载AspectJAutoProxyRegistrar，然后调用其registerBeanDefinitions方法，然后使用工具类注册AnnotationAwareAspectJAutoProxyCreator到容器中，这样在每个Bean创建之后，如果需要使用AOP，那么就会通过AOP的后置处理器进行处理，最后返回一个代理对象。 我们也可以尝试编写一个自己的ImportBeanDefinitionRegistrar实现，首先编写一个测试Bean： 1234567public class TestBean &#123; @PostConstruct void init()&#123; System.out.println(&quot;我被初始化了！&quot;); &#125;&#125; 12345678public class TestBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; BeanDefinition definition = BeanDefinitionBuilder.rootBeanDefinition(Student.class).getBeanDefinition(); registry.registerBeanDefinition(&quot;lbwnb&quot;, definition); &#125;&#125; 观察控制台输出，成功加载Bean实例。 与BeanPostProcessor差不多的还有BeanFactoryPostProcessor，它和前者一样，也是用于我们自己处理后置动作的，不过这里是用于处理BeanFactory加载的后置动作，BeanDefinitionRegistryPostProcessor直接继承自BeanFactoryPostProcessor，并且还添加了新的动作postProcessBeanDefinitionRegistry，你可以在这里动态添加Bean定义或是修改已经存在的Bean定义，这里我们就直接演示BeanDefinitionRegistryPostProcessor的实现： 1234567891011121314@Componentpublic class TestDefinitionProcessor implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; System.out.println(&quot;我是Bean定义后置处理！&quot;); BeanDefinition definition = BeanDefinitionBuilder.rootBeanDefinition(TestBean.class).getBeanDefinition(); registry.registerBeanDefinition(&quot;lbwnb&quot;, definition); &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory configurableListableBeanFactory) throws BeansException &#123; System.out.println(&quot;我是Bean工厂后置处理！&quot;); &#125;&#125; 在这里注册Bean定义其实和之前那种方法效果一样。 最后，我们再完善一下Bean加载流程（加粗部分是新增的）： [Bean定义]首先扫描Bean，加载Bean定义 -&gt; [Bean定义]Bean定义和Bean工厂后置处理 -&gt; [依赖注入]根据Bean定义通过反射创建Bean实例 -&gt; [依赖注入]进行依赖注入（顺便解决循环依赖问题）-&gt; [初始化Bean]BeanPostProcessor的初始化之前方法 -&gt; [初始化Bean]Bean初始化方法 -&gt; [初始化Bean]BeanPostProcessor的初始化之前后方法 -&gt; [完成]最终得到的Bean加载完成的实例 最后我们再来研究一下ApplicationContext中的refresh()方法： 12345678910111213141516171819202122232425262728293031323334353637383940public void refresh() throws BeansException, IllegalStateException &#123; synchronized(this.startupShutdownMonitor) &#123; StartupStep contextRefresh = this.applicationStartup.start(&quot;spring.context.refresh&quot;); this.prepareRefresh(); ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); //初始化Bean工厂 this.prepareBeanFactory(beanFactory); try &#123; this.postProcessBeanFactory(beanFactory); StartupStep beanPostProcess = this.applicationStartup.start(&quot;spring.context.beans.post-process&quot;); //调用所有的Bean工厂、Bean注册后置处理器 this.invokeBeanFactoryPostProcessors(beanFactory); //注册Bean后置处理器（包括Spring内部的） this.registerBeanPostProcessors(beanFactory); beanPostProcess.end(); //国际化支持 this.initMessageSource(); //监听和事件广播 this.initApplicationEventMulticaster(); this.onRefresh(); this.registerListeners(); //实例化所有的Bean this.finishBeanFactoryInitialization(beanFactory); this.finishRefresh(); &#125; catch (BeansException var10) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt: &quot; + var10); &#125; this.destroyBeans(); this.cancelRefresh(var10); throw var10; &#125; finally &#123; this.resetCommonCaches(); contextRefresh.end(); &#125; &#125;&#125; 我们可以给这些部分分别打上断点来观察一下此方法的整体加载流程。 Mybatis整合原理通过之前的了解，我们再来看Mybatis的@MapperScan是如何实现的，现在理解起来就非常简单了。 我们可以直接打开查看： 12345678910@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Documented@Import(&#123;MapperScannerRegistrar.class&#125;)@Repeatable(MapperScans.class)public @interface MapperScan &#123; String[] value() default &#123;&#125;; String[] basePackages() default &#123;&#125;; ... 我们发现，和Aop一样，它也是通过Registrar机制，通过@Import来进行Bean的注册，我们来看看MapperScannerRegistrar是个什么东西，关键代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354void registerBeanDefinitions(AnnotationMetadata annoMeta, AnnotationAttributes annoAttrs, BeanDefinitionRegistry registry, String beanName) &#123; BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class); builder.addPropertyValue(&quot;processPropertyPlaceHolders&quot;, true); Class&lt;? extends Annotation&gt; annotationClass = annoAttrs.getClass(&quot;annotationClass&quot;); if (!Annotation.class.equals(annotationClass)) &#123; builder.addPropertyValue(&quot;annotationClass&quot;, annotationClass); &#125; Class&lt;?&gt; markerInterface = annoAttrs.getClass(&quot;markerInterface&quot;); if (!Class.class.equals(markerInterface)) &#123; builder.addPropertyValue(&quot;markerInterface&quot;, markerInterface); &#125; Class&lt;? extends BeanNameGenerator&gt; generatorClass = annoAttrs.getClass(&quot;nameGenerator&quot;); if (!BeanNameGenerator.class.equals(generatorClass)) &#123; builder.addPropertyValue(&quot;nameGenerator&quot;, BeanUtils.instantiateClass(generatorClass)); &#125; Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = annoAttrs.getClass(&quot;factoryBean&quot;); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) &#123; builder.addPropertyValue(&quot;mapperFactoryBeanClass&quot;, mapperFactoryBeanClass); &#125; String sqlSessionTemplateRef = annoAttrs.getString(&quot;sqlSessionTemplateRef&quot;); if (StringUtils.hasText(sqlSessionTemplateRef)) &#123; builder.addPropertyValue(&quot;sqlSessionTemplateBeanName&quot;, annoAttrs.getString(&quot;sqlSessionTemplateRef&quot;)); &#125; String sqlSessionFactoryRef = annoAttrs.getString(&quot;sqlSessionFactoryRef&quot;); if (StringUtils.hasText(sqlSessionFactoryRef)) &#123; builder.addPropertyValue(&quot;sqlSessionFactoryBeanName&quot;, annoAttrs.getString(&quot;sqlSessionFactoryRef&quot;)); &#125; List&lt;String&gt; basePackages = new ArrayList(); basePackages.addAll((Collection)Arrays.stream(annoAttrs.getStringArray(&quot;value&quot;)).filter(StringUtils::hasText).collect(Collectors.toList())); basePackages.addAll((Collection)Arrays.stream(annoAttrs.getStringArray(&quot;basePackages&quot;)).filter(StringUtils::hasText).collect(Collectors.toList())); basePackages.addAll((Collection)Arrays.stream(annoAttrs.getClassArray(&quot;basePackageClasses&quot;)).map(ClassUtils::getPackageName).collect(Collectors.toList())); if (basePackages.isEmpty()) &#123; basePackages.add(getDefaultBasePackage(annoMeta)); &#125; String lazyInitialization = annoAttrs.getString(&quot;lazyInitialization&quot;); if (StringUtils.hasText(lazyInitialization)) &#123; builder.addPropertyValue(&quot;lazyInitialization&quot;, lazyInitialization); &#125; String defaultScope = annoAttrs.getString(&quot;defaultScope&quot;); if (!&quot;&quot;.equals(defaultScope)) &#123; builder.addPropertyValue(&quot;defaultScope&quot;, defaultScope); &#125; builder.addPropertyValue(&quot;basePackage&quot;, StringUtils.collectionToCommaDelimitedString(basePackages)); registry.registerBeanDefinition(beanName, builder.getBeanDefinition());&#125; 虽然很长很多，但是这些代码都是在添加一些Bean定义的属性，而最关键的则是最上方的MapperScannerConfigurer，Mybatis将其Bean信息注册到了容器中，那么这个类又是干嘛的呢？ 12public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware &#123; private String basePackage; 它实现了BeanDefinitionRegistryPostProcessor，也就是说它为Bean信息加载提供了后置处理，我们接着来看看它在Bean信息后置处理中做了什么： 12345678910111213141516171819202122232425262728293031public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; if (this.processPropertyPlaceHolders) &#123; this.processPropertyPlaceHolders(); &#125; //初始化类路径Mapper扫描器，它相当于是一个工具类，可以快速扫描出整个包下的类定义信息 //ClassPathMapperScanner是Mybatis自己实现的一个扫描器，修改了一些扫描规则 ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass); if (StringUtils.hasText(this.lazyInitialization)) &#123; scanner.setLazyInitialization(Boolean.valueOf(this.lazyInitialization)); &#125; if (StringUtils.hasText(this.defaultScope)) &#123; scanner.setDefaultScope(this.defaultScope); &#125; //添加过滤器，这里会配置为所有的接口都能被扫描（因此即使你不添加@Mapper注解都能够被扫描并加载） scanner.registerFilters(); //开始扫描 scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, &quot;,; \\t &quot;));&#125; 开始扫描后，会调用doScan()方法，我们接着来看（这是ClassPathMapperScanner中的扫描方法）： 123456789101112131415public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); //首先从包中扫描所有的Bean定义 if (beanDefinitions.isEmpty()) &#123; LOGGER.warn(() -&gt; &#123; return &quot;No MyBatis mapper was found in &#x27;&quot; + Arrays.toString(basePackages) + &quot;&#x27; package. Please check your configuration.&quot;; &#125;); &#125; else &#123; //处理所有的Bean定义，实际上就是生成对应Mapper的代理对象，并注册到容器中 this.processBeanDefinitions(beanDefinitions); &#125; //最后返回所有的Bean定义集合 return beanDefinitions;&#125; 通过断点我们发现，最后处理得到的Bean定义发现此Bean是一个MapperFactoryBean，它不同于普通的Bean，FactoryBean相当于为普通的Bean添加了一层外壳，它并不是依靠Spring直接通过反射创建，而是使用接口中的方法： 12345678910111213public interface FactoryBean&lt;T&gt; &#123; String OBJECT_TYPE_ATTRIBUTE = &quot;factoryBeanObjectType&quot;; @Nullable T getObject() throws Exception; @Nullable Class&lt;?&gt; getObjectType(); default boolean isSingleton() &#123; return true; &#125;&#125; 通过getObject()方法，就可以获取到Bean的实例了。 注意这里一定要区分FactoryBean和BeanFactory的概念： BeanFactory是个Factory，也就是 IOC 容器或对象工厂，所有的 Bean 都是由 BeanFactory( 也就是 IOC 容器 ) 来进行管理。 FactoryBean是一个能生产或者修饰生成对象的工厂Bean(本质上也是一个Bean)，可以在BeanFactory（IOC容器）中被管理，所以它并不是一个简单的Bean。当使用容器中factory bean的时候，该容器不会返回factory bean本身，而是返回其生成的对象。要想获取FactoryBean的实现类本身，得在getBean(String BeanName)中的BeanName之前加上&amp;,写成getBean(String &amp;BeanName)。 我们也可以自己编写一个实现： 12345678910111213@Component(&quot;test&quot;)public class TestFb implements FactoryBean&lt;Student&gt; &#123; @Override public Student getObject() throws Exception &#123; System.out.println(&quot;获取了学生&quot;); return new Student(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Student.class; &#125;&#125; 123456public static void main(String[] args) &#123; log.info(&quot;项目正在启动...&quot;); ApplicationContext context = new AnnotationConfigApplicationContext(TestConfiguration.class); System.out.println(context.getBean(&quot;&amp;test&quot;)); //得到FactoryBean本身（得加个&amp;搞得像C语言指针一样） System.out.println(context.getBean(&quot;test&quot;)); //得到FactoryBean调用getObject()之后的结果&#125; 因此，实际上我们的Mapper最终就以FactoryBean的形式，被注册到容器中进行加载了： 123public T getObject() throws Exception &#123; return this.getSqlSession().getMapper(this.mapperInterface);&#125; 这样，整个Mybatis的@MapperScan的原理就全部解释完毕了。 在了解完了Spring的底层原理之后，我们其实已经完全可以根据这些实现原理来手写一个Spring框架了。","tags":["Spring"],"categories":["Java","Spring"]}]